"""
–≠—Ç–∞–ø: –ü—Ä–µ–¥–≤–∞—Ä–∏—Ç–µ–ª—å–Ω–∞—è –∑–∞–≥—Ä—É–∑–∫–∞ –¥–∞–Ω–Ω—ã—Ö Yandex Direct –≤ —Ñ–æ–Ω–µ.

–ó–∞–ø—É—Å–∫–∞–µ—Ç—Å—è —Å—Ä–∞–∑—É –ø–æ—Å–ª–µ preprocessing, –∑–∞–≥—Ä—É–∂–∞–µ—Ç –¥–∞–Ω–Ω—ã–µ –¥–ª—è –≤—Å–µ—Ö –∑–∞–ø—Ä–æ—Å–æ–≤
–ø–æ–∫–∞ –≤—ã–ø–æ–ª–Ω—è—é—Ç—Å—è –¥—Ä—É–≥–∏–µ —ç—Ç–∞–ø—ã (SERP, –∫–ª–∞—Å—Ç–µ—Ä–∏–∑–∞—Ü–∏—è, –º–µ—Ç—Ä–∏–∫–∏).
"""

from seo_analyzer.analysis import YandexDirectPreloader
from seo_analyzer.core.yandex_direct_auto_auth import ensure_yandex_direct_token


def _should_run_yandex_direct() -> tuple[bool, dict]:
    """
    –ü—Ä–æ–≤–µ—Ä–∏—Ç—å –Ω—É–∂–Ω–æ –ª–∏ –∑–∞–ø—É—Å–∫–∞—Ç—å Yandex Direct
    
    Returns:
        (should_run, config_dict)
    """
    try:
        from config_local import (
            YANDEX_DIRECT_ENABLED,
            YANDEX_DIRECT_TOKEN,
            YANDEX_DIRECT_CLIENT_ID,
            YANDEX_DIRECT_CLIENT_SECRET,
            YANDEX_DIRECT_USE_SANDBOX
        )
        
        # GEO_ID —Å –¥–µ—Ñ–æ–ª—Ç–Ω—ã–º –∑–Ω–∞—á–µ–Ω–∏–µ–º
        try:
            from config_local import YANDEX_DIRECT_GEO_ID
        except ImportError:
            YANDEX_DIRECT_GEO_ID = 213
            
        if not YANDEX_DIRECT_ENABLED:
            return False, {}
            
        if not YANDEX_DIRECT_CLIENT_ID or not YANDEX_DIRECT_CLIENT_SECRET:
            return False, {}
            
        return True, {
            'token': YANDEX_DIRECT_TOKEN,
            'client_id': YANDEX_DIRECT_CLIENT_ID,
            'client_secret': YANDEX_DIRECT_CLIENT_SECRET,
            'use_sandbox': YANDEX_DIRECT_USE_SANDBOX,
            'geo_id': YANDEX_DIRECT_GEO_ID
        }
    except ImportError:
        return False, {}


async def preload_yandex_direct_stage(args, analyzer):
    """
    –ü—Ä–µ–¥–≤–∞—Ä–∏—Ç–µ–ª—å–Ω–∞—è –∑–∞–≥—Ä—É–∑–∫–∞ –¥–∞–Ω–Ω—ã—Ö Yandex Direct.
    
    –ó–∞–≥—Ä—É–∂–∞–µ—Ç –¥–∞–Ω–Ω—ã–µ –¥–ª—è –∑–∞–ø—Ä–æ—Å–æ–≤, –∫–æ—Ç–æ—Ä—ã—Ö –Ω–µ—Ç –≤ –∫—ç—à–µ,
    –ø–æ–∫–∞ –≤—ã–ø–æ–ª–Ω—è—é—Ç—Å—è –¥—Ä—É–≥–∏–µ —ç—Ç–∞–ø—ã –∞–Ω–∞–ª–∏–∑–∞.
    
    Args:
        args: –ê—Ä–≥—É–º–µ–Ω—Ç—ã –∫–æ–º–∞–Ω–¥–Ω–æ–π —Å—Ç—Ä–æ–∫–∏
        analyzer: –≠–∫–∑–µ–º–ø–ª—è—Ä SEOAnalyzer
        
    Returns:
        None (–¥–∞–Ω–Ω—ã–µ —Å–æ—Ö—Ä–∞–Ω—è—é—Ç—Å—è –≤ –∫—ç—à)
    """
    # –ü—Ä–æ–≤–µ—Ä—è–µ–º –Ω—É–∂–Ω–æ –ª–∏ –∑–∞–ø—É—Å–∫–∞—Ç—å
    should_run, config = _should_run_yandex_direct()
    if not should_run:
        return
    
    # –ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∞—è –ø—Ä–æ–≤–µ—Ä–∫–∞ –∏ –ø–æ–ª—É—á–µ–Ω–∏–µ —Ç–æ–∫–µ–Ω–∞ –µ—Å–ª–∏ –Ω—É–∂–Ω–æ
    token = ensure_yandex_direct_token(
        client_id=config['client_id'],
        client_secret=config['client_secret'],
        current_token=config['token']
    )
    
    if not token:
        # –ü–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å –æ—Ç–∫–∞–∑–∞–ª—Å—è - —Ç–∏—Ö–æ –ø—Ä–æ–ø—É—Å–∫–∞–µ–º
        return
    
    print("üöÄ –§–û–ù–û–í–ê–Ø –ó–ê–î–ê–ß–ê: –ü—Ä–µ–¥–∑–∞–≥—Ä—É–∑–∫–∞ –¥–∞–Ω–Ω—ã—Ö Yandex Direct")
    print("-" * 80)
    
    # –û–ø—Ä–µ–¥–µ–ª—è–µ–º –Ω–∞–∑–≤–∞–Ω–∏–µ —Ä–µ–≥–∏–æ–Ω–∞
    region_names = {
        213: "–ú–æ—Å–∫–≤–∞",
        1: "–ú–æ—Å–∫–≤–∞ –∏ –æ–±–ª–∞—Å—Ç—å",
        2: "–°–∞–Ω–∫—Ç-–ü–µ—Ç–µ—Ä–±—É—Ä–≥",
        225: "–†–æ—Å—Å–∏—è",
        187: "–£–∫—Ä–∞–∏–Ω–∞",
        149: "–ë–µ–ª–∞—Ä—É—Å—å",
        159: "–ö–∞–∑–∞—Ö—Å—Ç–∞–Ω"
    }
    region_name = region_names.get(config['geo_id'], f"GeoID {config['geo_id']}")
    
    print(f"üìç –†–µ–≥–∏–æ–Ω: {region_name} (GeoID: {config['geo_id']})")
    print(f"üîß –†–µ–∂–∏–º: {'Sandbox' if config['use_sandbox'] else 'Production'}")
    
    # –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è preloader
    preloader = YandexDirectPreloader(
        token=token,
        use_sandbox=config['use_sandbox'],
        geo_id=config['geo_id']
    )
    
    # –ü–æ–ª—É—á–∞–µ–º —Å–ø–∏—Å–æ–∫ –∑–∞–ø—Ä–æ—Å–æ–≤
    if analyzer.df is None or analyzer.df.empty:
        print("‚ö†Ô∏è  DataFrame –ø—É—Å—Ç–æ–π, –ø—Ä–µ–¥–∑–∞–≥—Ä—É–∑–∫–∞ –ø—Ä–æ–ø—É—â–µ–Ω–∞")
        return
    
    if 'keyword' not in analyzer.df.columns:
        print("‚ö†Ô∏è  –ö–æ–ª–æ–Ω–∫–∞ 'keyword' –Ω–µ –Ω–∞–π–¥–µ–Ω–∞, –ø—Ä–µ–¥–∑–∞–≥—Ä—É–∑–∫–∞ –ø—Ä–æ–ø—É—â–µ–Ω–∞")
        return
    
    queries = analyzer.df['keyword'].unique().tolist()
    total_queries = len(queries)
    
    print(f"üì¶ –í—Å–µ–≥–æ –∑–∞–ø—Ä–æ—Å–æ–≤: {total_queries}")
    
    # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Å–∫–æ–ª—å–∫–æ —É–∂–µ –≤ –∫—ç—à–µ
    missing = preloader.get_missing_queries(queries)
    cached_count = total_queries - len(missing)
    
    if not missing:
        print(f"‚úÖ –í—Å–µ –∑–∞–ø—Ä–æ—Å—ã —É–∂–µ –≤ –∫—ç—à–µ ({cached_count}), –∑–∞–≥—Ä—É–∑–∫–∞ –Ω–µ —Ç—Ä–µ–±—É–µ—Ç—Å—è")
        print()
        return
    
    print(f"  ‚úì –í –∫—ç—à–µ: {cached_count}")
    print(f"  üì• –ó–∞–≥—Ä—É–∂–∞–µ–º: {len(missing)}")
    print()
    
    # –ó–∞–≥—Ä—É–∂–∞–µ–º –¥–∞–Ω–Ω—ã–µ
    stats = preloader.preload_queries(missing, show_progress=True)
    
    print()
    print(f"‚úÖ –ü—Ä–µ–¥–∑–∞–≥—Ä—É–∑–∫–∞ –∑–∞–≤–µ—Ä—à–µ–Ω–∞:")
    print(f"  ‚Ä¢ –ó–∞–≥—Ä—É–∂–µ–Ω–æ: {stats['loaded']}")
    print(f"  ‚Ä¢ –ò–∑ –∫—ç—à–∞: {stats['from_cache']}")
    if stats.get('skipped_long', 0) > 0:
        print(f"  ‚Ä¢ –ü—Ä–æ–ø—É—â–µ–Ω–æ (>6 —Å–ª–æ–≤): {stats['skipped_long']}")
    if stats['failed'] > 0:
        print(f"  ‚Ä¢ –û—à–∏–±–∫–∏: {stats['failed']}")
    print()

