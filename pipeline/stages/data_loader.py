"""–≠—Ç–∞–ø 1: –ó–∞–≥—Ä—É–∑–∫–∞ –¥–∞–Ω–Ω—ã—Ö"""

from pathlib import Path
from seo_analyzer.core.helpers import load_all_data, load_csv_data, normalize_dataframe_columns, load_intent_weights
from seo_analyzer.core.query_groups import QueryGroupManager
from .stage_logger import get_group_prefix, print_stage


async def load_data_stage(args, analyzer):
    """
    –ó–∞–≥—Ä—É–∑–∫–∞ –≤—Å–µ—Ö –¥–∞–Ω–Ω—ã—Ö
    
    Args:
        args: –ê—Ä–≥—É–º–µ–Ω—Ç—ã –∫–æ–º–∞–Ω–¥–Ω–æ–π —Å—Ç—Ä–æ–∫–∏
        analyzer: –≠–∫–∑–µ–º–ø–ª—è—Ä SEOAnalyzer
        
    Returns:
        None (–¥–∞–Ω–Ω—ã–µ —Å–æ—Ö—Ä–∞–Ω—è—é—Ç—Å—è –≤ analyzer)
    """
    prefix = get_group_prefix(analyzer)
    print(f"{prefix}üìö –≠–¢–ê–ü 1: –ó–∞–≥—Ä—É–∑–∫–∞ –¥–∞–Ω–Ω—ã—Ö")
    print(f"{prefix}{'-' * 80}")
    
    # –ó–∞–≥—Ä—É–∂–∞–µ–º —Å–ª–æ–≤–∞—Ä–∏
    analyzer.keyword_dicts, analyzer.geo_dicts, analyzer.stopwords = await load_all_data()
    
    # –ó–∞–≥—Ä—É–∂–∞–µ–º –≤–µ—Å–∞ –∏–Ω—Ç–µ–Ω—Ç–æ–≤
    analyzer.intent_weights = await load_intent_weights()
    
    # –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –º–µ–Ω–µ–¥–∂–µ—Ä–∞ –≥—Ä—É–ø–ø
    group_manager = QueryGroupManager()
    group_manager.discover_groups()
    
    # –ü—Ä–æ–≤–µ—Ä—è–µ–º: —Ä–∞–±–æ—Ç–∞ —Å –≥—Ä—É–ø–ø–∞–º–∏ –∏–ª–∏ –æ–±—ã—á–Ω—ã–π —Ä–µ–∂–∏–º
    if hasattr(args, 'group') and args.group:
        # –†–µ–∂–∏–º —Ä–∞–±–æ—Ç—ã —Å –≥—Ä—É–ø–ø–æ–π
        print_stage(analyzer, f"üìÅ –†–∞–±–æ—Ç–∞ —Å –≥—Ä—É–ø–ø–æ–π: {args.group}")
        group = group_manager.get_group(args.group)
        
        if not group:
            raise ValueError(f"–ì—Ä—É–ø–ø–∞ '{args.group}' –Ω–µ –Ω–∞–π–¥–µ–Ω–∞ –≤ semantika/")
        
        analyzer.current_group = group
        analyzer.group_manager = group_manager
        
        print_stage(analyzer, f"‚úì –ì—Ä—É–ø–ø–∞: {group.name}")
        print_stage(analyzer, f"‚úì –§–∞–π–ª: {group.input_file}")
        print_stage(analyzer, f"‚úì Output: {group.output_dir}")
        
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º –∫—ç—à –≤ Master DB (–µ–¥–∏–Ω—Å—Ç–≤–µ–Ω–Ω—ã–π –∏—Å—Ç–æ—á–Ω–∏–∫ –¥–∞–Ω–Ω—ã—Ö)
        if not getattr(args, 'force_refresh', False):
            # –ü—Ä–æ–±—É–µ–º –∑–∞–≥—Ä—É–∑–∏—Ç—å –∏–∑ Master DB
            try:
                from seo_analyzer.core.cache.master_query_db import MasterQueryDatabase
                master_db = MasterQueryDatabase()
                
                if master_db.group_exists(group.name):
                    # –ü–æ–ª—É—á–∞–µ–º —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É –∏–∑ Master DB –æ–¥–∏–Ω —Ä–∞–∑
                    master_db_stats = master_db.get_statistics(group.name)
                    master_db_queries_count = master_db_stats['total_queries']
                    
                    # –ü—Ä–æ–≤–µ—Ä—è–µ–º –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –∑–∞–ø—Ä–æ—Å–æ–≤ –≤ CSV –ø–µ—Ä–µ–¥ –∑–∞–≥—Ä—É–∑–∫–æ–π –∏–∑ Master DB
                    csv_has_more_queries = False
                    
                    if group.input_file and group.input_file.exists():
                        # –ë—ã—Å—Ç—Ä–æ –∑–∞–≥—Ä—É–∂–∞–µ–º CSV —Ç–æ–ª—å–∫–æ –¥–ª—è –ø–æ–¥—Å—á—ë—Ç–∞ –∑–∞–ø—Ä–æ—Å–æ–≤
                        import pandas as pd
                        import asyncio
                        
                        def count_csv_queries(csv_path):
                            """–ë—ã—Å—Ç—Ä–æ –ø–æ–¥—Å—á–∏—Ç—ã–≤–∞–µ—Ç –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –∑–∞–ø—Ä–æ—Å–æ–≤ –≤ CSV"""
                            try:
                                # –ü—Ä–æ–±—É–µ–º —Ä–∞–∑–Ω—ã–µ –∫–æ–¥–∏—Ä–æ–≤–∫–∏ –∏ —Ä–∞–∑–¥–µ–ª–∏—Ç–µ–ª–∏
                                for encoding in ['utf-8-sig', 'utf-8', 'cp1251', 'windows-1251']:
                                    for delimiter in [',', ';', '\t']:
                                        try:
                                            df = pd.read_csv(csv_path, delimiter=delimiter, encoding=encoding, nrows=0)
                                            if len(df.columns) > 1:
                                                # –û–ø—Ä–µ–¥–µ–ª–∏–ª–∏ —Ñ–æ—Ä–º–∞—Ç, —Ç–µ–ø–µ—Ä—å —á–∏—Ç–∞–µ–º –ø–æ–ª–Ω–æ—Å—Ç—å—é
                                                df = pd.read_csv(csv_path, delimiter=delimiter, encoding=encoding)
                                                # –û–ø—Ä–µ–¥–µ–ª—è–µ–º –∫–æ–ª–æ–Ω–∫—É —Å –∑–∞–ø—Ä–æ—Å–∞–º–∏ (–æ–±—ã—á–Ω–æ 'keyword' –∏–ª–∏ –ø–µ—Ä–≤–∞—è)
                                                keyword_col = 'keyword' if 'keyword' in df.columns else df.columns[0]
                                                # –°—á–∏—Ç–∞–µ–º —É–Ω–∏–∫–∞–ª—å–Ω—ã–µ –∑–∞–ø—Ä–æ—Å—ã
                                                return df[keyword_col].nunique() if keyword_col in df.columns else len(df)
                                        except (UnicodeDecodeError, pd.errors.ParserError):
                                            continue
                                return 0
                            except Exception:
                                return 0
                        
                        csv_queries_count = await asyncio.to_thread(count_csv_queries, group.input_file)
                        
                        if csv_queries_count > master_db_queries_count:
                            csv_has_more_queries = True
                            print_stage(analyzer, f"üîÑ –í CSV —Ñ–∞–π–ª–µ –±–æ–ª—å—à–µ –∑–∞–ø—Ä–æ—Å–æ–≤ ({csv_queries_count} > {master_db_queries_count}), –∑–∞–≥—Ä—É–∑–∫–∞ –∏–∑ CSV...")
                    
                    if not csv_has_more_queries:
                        print_stage(analyzer, f"üöÄ –ó–∞–≥—Ä—É–∑–∫–∞ –∏–∑ Master DB (–≤—Å–µ –¥–∞–Ω–Ω—ã–µ –≤–∫–ª—é—á–∞—è SERP + –∏–Ω—Ç–µ–Ω—Ç)...")
                        master_df = master_db.load_queries(group.name, include_serp_urls=True)
                        
                        if master_df is not None and not master_df.empty:
                            # –ò—Å–ø–æ–ª—å–∑—É–µ–º —É–∂–µ –ø–æ–ª—É—á–µ–Ω–Ω—É—é —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É
                            stats = master_db_stats
                            
                            # –ü—Ä–æ–≤–µ—Ä—è–µ–º —á—Ç–æ –≤ Master DB –µ—Å—Ç—å –¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ –¥–∞–Ω–Ω—ã—Ö
                            total = stats['total_queries']
                            has_enough_data = (stats['with_intent'] > total * 0.5) or (stats['with_serp'] > total * 0.5)
                            
                            if has_enough_data:
                                # –î–∞–Ω–Ω—ã–µ –≤ Master DB –ø–æ–ª–Ω—ã–µ - –∏—Å–ø–æ–ª—å–∑—É–µ–º –∏—Ö
                                raw_df = master_df
                                analyzer.loaded_from_cache = True
                                analyzer.loaded_from_master_db = True
                                
                                print_stage(analyzer, f"  ‚úì –ó–∞–ø—Ä–æ—Å–æ–≤: {total:,}")
                                print_stage(analyzer, f"  ‚úì –° –∏–Ω—Ç–µ–Ω—Ç–æ–º: {stats['with_intent']:,}")
                                print_stage(analyzer, f"  ‚úì –° SERP: {stats['with_serp']:,}")
                                print_stage(analyzer, f"  üí° –ú–æ–∂–Ω–æ —Å—Ä–∞–∑—É —ç–∫—Å–ø–µ—Ä–∏–º–µ–Ω—Ç–∏—Ä–æ–≤–∞—Ç—å —Å –∫–ª–∞—Å—Ç–µ—Ä–∏–∑–∞—Ü–∏–µ–π!")
                            else:
                                # Master DB –ø—É—Å—Ç–∞—è –∏–ª–∏ –Ω–µ–ø–æ–ª–Ω–∞—è - –∑–∞–≥—Ä—É–∂–∞–µ–º –∏–∑ CSV
                                print_stage(analyzer, f"‚ö†Ô∏è  Master DB –Ω–µ–ø–æ–ª–Ω–∞—è (–∏–Ω—Ç–µ–Ω—Ç: {stats['with_intent']}/{total}, SERP: {stats['with_serp']}/{total})")
                                print_stage(analyzer, f"üîÑ –ó–∞–≥—Ä—É–∑–∫–∞ –∏–∑ CSV...")
                                import asyncio
                                raw_df = await asyncio.to_thread(group_manager.load_queries, group)
                                analyzer.loaded_from_cache = False
                                analyzer.loaded_from_master_db = False
                        else:
                            # Master DB –≤–µ—Ä–Ω—É–ª –ø—É—Å—Ç–æ–π DataFrame - –∑–∞–≥—Ä—É–∂–∞–µ–º –∏–∑ CSV
                            print_stage(analyzer, f"‚ö†Ô∏è  Master DB –≤–µ—Ä–Ω—É–ª –ø—É—Å—Ç–æ–π DataFrame, –∑–∞–≥—Ä—É–∑–∫–∞ –∏–∑ CSV...")
                            import asyncio
                            raw_df = await asyncio.to_thread(group_manager.load_queries, group)
                            analyzer.loaded_from_cache = False
                            analyzer.loaded_from_master_db = False
                    else:
                        # –í CSV –±–æ–ª—å—à–µ –∑–∞–ø—Ä–æ—Å–æ–≤ - –∑–∞–≥—Ä—É–∂–∞–µ–º –∏–∑ CSV
                        import asyncio
                        raw_df = await asyncio.to_thread(group_manager.load_queries, group)
                        analyzer.loaded_from_cache = False
                        analyzer.loaded_from_master_db = False
                else:
                    # –ì—Ä—É–ø–ø—ã –Ω–µ—Ç –≤ Master DB - –∑–∞–≥—Ä—É–∂–∞–µ–º –∏–∑ CSV
                    print_stage(analyzer, f"üîÑ –ì—Ä—É–ø–ø–∞ –Ω–µ –Ω–∞–π–¥–µ–Ω–∞ –≤ Master DB, –∑–∞–≥—Ä—É–∑–∫–∞ –∏–∑ CSV...")
                    import asyncio
                    raw_df = await asyncio.to_thread(group_manager.load_queries, group)
                    analyzer.loaded_from_cache = False
                    analyzer.loaded_from_master_db = False
                    
            except Exception as e:
                # Master DB –Ω–µ–¥–æ—Å—Ç—É–ø–µ–Ω - –∑–∞–≥—Ä—É–∂–∞–µ–º –∏–∑ CSV
                print_stage(analyzer, f"‚ö†Ô∏è  Master DB –Ω–µ–¥–æ—Å—Ç—É–ø–µ–Ω ({e}), –∑–∞–≥—Ä—É–∑–∫–∞ –∏–∑ CSV...")
                import asyncio
                raw_df = await asyncio.to_thread(group_manager.load_queries, group)
                analyzer.loaded_from_cache = False
                analyzer.loaded_from_master_db = False
        else:
            # –ü—Ä–∏–Ω—É–¥–∏—Ç–µ–ª—å–Ω–æ–µ –æ–±–Ω–æ–≤–ª–µ–Ω–∏–µ - –∑–∞–≥—Ä—É–∂–∞–µ–º –∏–∑ CSV
            print_stage(analyzer, f"üîÑ –ü—Ä–∏–Ω—É–¥–∏—Ç–µ–ª—å–Ω–æ–µ –æ–±–Ω–æ–≤–ª–µ–Ω–∏–µ, –∑–∞–≥—Ä—É–∑–∫–∞ –∏–∑ CSV...")
            import asyncio
            raw_df = await asyncio.to_thread(group_manager.load_queries, group)
            analyzer.loaded_from_cache = False
            analyzer.loaded_from_master_db = False
        
    elif args.input_file:
        # –û–±—ã—á–Ω—ã–π —Ä–µ–∂–∏–º (–æ–¥–∏–Ω —Ñ–∞–π–ª –ø–æ –ø—É—Ç–∏)
        csv_path = Path(args.input_file)
        if not csv_path.is_absolute():
            csv_path = Path.cwd() / csv_path
        
        # –ß–∏—Ç–∞–µ–º CSV –≤ –æ—Ç–¥–µ–ª—å–Ω–æ–º –ø–æ—Ç–æ–∫–µ —á—Ç–æ–±—ã –Ω–µ –±–ª–æ–∫–∏—Ä–æ–≤–∞—Ç—å event loop
        import asyncio
        raw_df = await asyncio.to_thread(load_csv_data, csv_path)
        
        analyzer.current_group = None
        analyzer.group_manager = None
    else:
        raise ValueError("–ù–µ —É–∫–∞–∑–∞–Ω —Ñ–∞–π–ª –¥–ª—è –æ–±—Ä–∞–±–æ—Ç–∫–∏")
    
    if raw_df.empty:
        raise ValueError("–ù–µ —É–¥–∞–ª–æ—Å—å –∑–∞–≥—Ä—É–∑–∏—Ç—å –¥–∞–Ω–Ω—ã–µ –∏–∑ CSV")
    
    # –ù–æ—Ä–º–∞–ª–∏–∑—É–µ–º –∫–æ–ª–æ–Ω–∫–∏ –¢–û–õ–¨–ö–û –µ—Å–ª–∏ –¥–∞–Ω–Ω—ã–µ –∑–∞–≥—Ä—É–∂–µ–Ω—ã –∏–∑ CSV
    # –ï—Å–ª–∏ –∏–∑ –∫—ç—à–∞ - —Ç–∞–º —É–∂–µ –≤—Å–µ –∫–æ–ª–æ–Ω–∫–∏ –Ω–æ—Ä–º–∞–ª–∏–∑–æ–≤–∞–Ω—ã –∏ –≥–æ—Ç–æ–≤—ã –∫ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—é
    if getattr(analyzer, 'loaded_from_cache', False):
        # –î–∞–Ω–Ω—ã–µ –∏–∑ –∫—ç—à–∞ —É–∂–µ —Å–æ–¥–µ—Ä–∂–∞—Ç –≤—Å–µ –Ω—É–∂–Ω—ã–µ –∫–æ–ª–æ–Ω–∫–∏
        analyzer.df = raw_df
        print_stage(analyzer, f"‚úì –ó–∞–≥—Ä—É–∂–µ–Ω–æ {len(analyzer.df)} –∑–∞–ø—Ä–æ—Å–æ–≤ (—Å –∫–æ–ª–æ–Ω–∫–∞–º–∏ –∏–∑ –∫—ç—à–∞)")
    else:
        # –î–∞–Ω–Ω—ã–µ –∏–∑ CSV - –Ω—É–∂–Ω–æ –Ω–æ—Ä–º–∞–ª–∏–∑–æ–≤–∞—Ç—å –∫–æ–ª–æ–Ω–∫–∏
        analyzer.df = normalize_dataframe_columns(raw_df)
        print_stage(analyzer, f"‚úì –ó–∞–≥—Ä—É–∂–µ–Ω–æ {len(analyzer.df)} –∑–∞–ø—Ä–æ—Å–æ–≤")
    
    print_stage(analyzer, f"üîç DEBUG data_loader: –ö–æ–ª–æ–Ω–∫–∏ –ø–æ—Å–ª–µ –∑–∞–≥—Ä—É–∑–∫–∏ = {list(analyzer.df.columns)[:10]}...")
    print_stage(analyzer, f"üîç DEBUG data_loader: loaded_from_cache = {getattr(analyzer, 'loaded_from_cache', '–Ω–µ —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–æ')}")
    print()

