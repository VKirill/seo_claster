"""–ü–æ—Å—Ç-–æ–±—Ä–∞–±–æ—Ç–∫–∞ –∫–ª–∞—Å—Ç–µ—Ä–æ–≤: –¥–µ–ª–∏–º –∫—Ä—É–ø–Ω—ã–µ –∏ –ø—Ä–∏–∫—Ä–µ–ø–ª—è–µ–º –æ–¥–∏–Ω–æ—á–∫–∏."""

from seo_analyzer.clustering.cluster_postprocessor import ClusterPostprocessor
from seo_analyzer.core.config import CLUSTERING_CONFIG
from .stage_logger import get_group_prefix, print_stage



async def postprocess_clusters_stage(args, analyzer):
    """
    –î–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã–π —à–∞–≥ –ø–æ—Å–ª–µ –æ—Å–Ω–æ–≤–Ω–æ–π –∫–ª–∞—Å—Ç–µ—Ä–∏–∑–∞—Ü–∏–∏.

    –î–µ–ª–∏—Ç –∫–ª–∞—Å—Ç–µ—Ä—ã > max_cluster_size, –ø–æ–≤—ã—à–∞—è –ø–æ—Ä–æ–≥ –æ–±—â–∏—Ö URL, –∏
    –ø–æ–≤—Ç–æ—Ä–Ω–æ –ø—Ä–∏–∫—Ä–µ–ø–ª—è–µ—Ç –æ–¥–∏–Ω–æ—á–Ω—ã–µ –∑–∞–ø—Ä–æ—Å—ã, –µ—Å–ª–∏ –Ω–∞–π–¥–µ–Ω—ã —Å–æ–≤–ø–∞–¥–µ–Ω–∏—è.
    
    –í maxmin —Ä–µ–∂–∏–º–µ –¥–µ–ª–µ–Ω–∏–µ –±–æ–ª—å—à–∏—Ö –∫–ª–∞—Å—Ç–µ—Ä–æ–≤ –æ—Ç–∫–ª—é—á–µ–Ω–æ (max_cluster_size=10000),
    —Ç–∞–∫ –∫–∞–∫ IterativeSERPClusterer —É–∂–µ –∫–æ–Ω—Ç—Ä–æ–ª–∏—Ä—É–µ—Ç —Ä–∞–∑–º–µ—Ä –∫–ª–∞—Å—Ç–µ—Ä–æ–≤.
    """
    prefix = get_group_prefix(analyzer)
    # –ü—Ä–æ–≤–µ—Ä—è–µ–º —á—Ç–æ DataFrame –Ω–µ –ø—É—Å—Ç–æ–π
    if len(analyzer.df) == 0:
        print_stage(analyzer, "üîß –ü–æ—Å—Ç-–æ–±—Ä–∞–±–æ—Ç–∫–∞ –∫–ª–∞—Å—Ç–µ—Ä–æ–≤ (–¥–µ–ª–µ–Ω–∏–µ –±–æ–ª—å—à–∏—Ö –≥—Ä—É–ø–ø)...")
        print_stage(analyzer, "‚ö†Ô∏è  DataFrame –ø—É—Å—Ç–æ–π, –ø—Ä–æ–ø—É—Å–∫–∞–µ–º –ø–æ—Å—Ç-–æ–±—Ä–∞–±–æ—Ç–∫—É")
        print()
        return
    
    serp_cfg = CLUSTERING_CONFIG.get("serp_advanced", {})
    postprocess_cfg = CLUSTERING_CONFIG.get("postprocess", {})
    
    # –ü—Ä–æ–≤–µ—Ä—è–µ–º, –∏—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è –ª–∏ maxmin —Ä–µ–∂–∏–º
    use_maxmin = getattr(args, 'maxmin', False)
    
    base_threshold = getattr(args, "serp_similarity_threshold", serp_cfg.get("min_common_urls", 7))
    top_positions = getattr(args, "serp_top_positions", serp_cfg.get("top_positions", 30))
    # –ò—Å–ø–æ–ª—å–∑—É–µ–º max_cluster_size –∏–∑ CLI –∞—Ä–≥—É–º–µ–Ω—Ç–æ–≤, –µ—Å–ª–∏ –Ω–µ —É–∫–∞–∑–∞–Ω - –±–µ—Ä–µ–º –∏–∑ –∫–æ–Ω—Ñ–∏–≥–∞ –ø–æ—Å—Ç–æ–±—Ä–∞–±–æ—Ç–∫–∏
    # –í maxmin —Ä–µ–∂–∏–º–µ —É—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞–µ–º –æ—á–µ–Ω—å –±–æ–ª—å—à–æ–π —Ä–∞–∑–º–µ—Ä, —á—Ç–æ–±—ã –Ω–µ –¥–µ–ª–∏—Ç—å –∫–ª–∞—Å—Ç–µ—Ä—ã
    if use_maxmin:
        max_cluster_size = 10000  # –û—á–µ–Ω—å –±–æ–ª—å—à–æ–π —Ä–∞–∑–º–µ—Ä - –¥–µ–ª–µ–Ω–∏–µ –Ω–µ –ø—Ä–æ–∏–∑–æ–π–¥–µ—Ç
    else:
        max_cluster_size = getattr(args, "max_cluster_size", postprocess_cfg.get("max_cluster_size", 12))
    threshold_step = getattr(args, "post_threshold_step", postprocess_cfg.get("threshold_step", 1))
    skip_singleton_reattach = getattr(args, "skip_singleton_reattach", False)

    if use_maxmin:
        print_stage(analyzer, "üîß –ü–æ—Å—Ç-–æ–±—Ä–∞–±–æ—Ç–∫–∞ –∫–ª–∞—Å—Ç–µ—Ä–æ–≤ (–±–µ–∑ –¥–µ–ª–µ–Ω–∏—è –±–æ–ª—å—à–∏—Ö –≥—Ä—É–ø–ø, maxmin —Ä–µ–∂–∏–º)...")
    else:
        print_stage(analyzer, "üîß –ü–æ—Å—Ç-–æ–±—Ä–∞–±–æ—Ç–∫–∞ –∫–ª–∞—Å—Ç–µ—Ä–æ–≤ (–¥–µ–ª–µ–Ω–∏–µ –±–æ–ª—å—à–∏—Ö –≥—Ä—É–ø–ø)...")
    post = ClusterPostprocessor(
        base_threshold=base_threshold,
        top_positions=top_positions,
        max_cluster_size=max_cluster_size,
        threshold_step=threshold_step,
        geo_dicts=analyzer.geo_dicts,  # üåç –ü–µ—Ä–µ–¥–∞–µ–º –≥–µ–æ-—Å–ª–æ–≤–∞—Ä–∏ –¥–ª—è –ø—Ä–æ–≤–µ—Ä–∫–∏ –≥–µ–æ–≥—Ä–∞—Ñ–∏–∏
        skip_singleton_reattach=skip_singleton_reattach,  # ‚ö° –£—Å–∫–æ—Ä–µ–Ω–∏–µ: –ø—Ä–æ–ø—É—Å–∫–∞–µ–º –ø—Ä–∏–∫—Ä–µ–ø–ª–µ–Ω–∏–µ –æ–¥–∏–Ω–æ—á–µ–∫
    )
    analyzer.df = post.process(analyzer.df)
    stats = post.get_stats()
    if stats:
        print(
            f"  ‚Ä¢ –ö–ª–∞—Å—Ç–µ—Ä–æ–≤ –ø–æ—Å–ª–µ –ø–æ—Å—Ç-–æ–±—Ä–∞–±–æ—Ç–∫–∏: {stats['total_clusters']}, "
            f"–º–∞–∫—Å. —Ä–∞–∑–º–µ—Ä: {stats['max_cluster_size']}, "
            f"–æ–¥–∏–Ω–æ—á–µ–∫: {stats['singleton_clusters']}"
        )
    print()

