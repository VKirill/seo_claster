"""
–û–±—Ä–∞–±–æ—Ç–∫–∞ –∫—ç—à–∏—Ä–æ–≤–∞–Ω–∏—è –∏ —Å–∏–Ω—Ö—Ä–æ–Ω–∏–∑–∞—Ü–∏–∏ CSV
"""

from pathlib import Path
from seo_analyzer.export.csv import save_filtered_queries


class CacheHandler:
    """–û–±—Ä–∞–±–æ—Ç—á–∏–∫ –∫—ç—à–∏—Ä–æ–≤–∞–Ω–∏—è"""
    
    @staticmethod
    def sync_csv_from_cache_if_needed(args, analyzer, print_stage):
        """
        –°–∏–Ω—Ö—Ä–æ–Ω–∏–∑–∏—Ä—É–µ—Ç CSV —Ñ–∞–π–ª —Å –¥–∞–Ω–Ω—ã–º–∏ –∏–∑ –∫—ç—à–∞ –µ—Å–ª–∏ —ç—Ç–æ —Ç—Ä–µ–±—É–µ—Ç—Å—è
        
        Args:
            args: –ê—Ä–≥—É–º–µ–Ω—Ç—ã –∫–æ–º–∞–Ω–¥–Ω–æ–π —Å—Ç—Ä–æ–∫–∏
            analyzer: –≠–∫–∑–µ–º–ø–ª—è—Ä SEOAnalyzer
            print_stage: –§—É–Ω–∫—Ü–∏—è –¥–ª—è –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏—è
        """
        input_file = None
        
        if hasattr(analyzer, 'current_group') and analyzer.current_group:
            input_file = analyzer.current_group.input_file
        elif hasattr(args, 'input_file') and args.input_file:
            input_file = Path(args.input_file)
            if not input_file.is_absolute():
                input_file = Path.cwd() / input_file
        
        if not input_file or not input_file.exists():
            return
        
        try:
            import pandas as pd
            original_df = pd.read_csv(input_file, encoding='utf-8-sig')
            original_count = len(original_df)
            cached_count = len(analyzer.df)
            
            if original_count > cached_count:
                duplicates_in_csv = original_count - cached_count
                
                print_stage(f"\n‚ö†Ô∏è  –û–±–Ω–∞—Ä—É–∂–µ–Ω–æ —Ä–∞—Å—Ö–æ–∂–¥–µ–Ω–∏–µ:")
                print_stage(f"   üìÑ –í CSV —Ñ–∞–π–ª–µ: {original_count} –∑–∞–ø—Ä–æ—Å–æ–≤")
                print_stage(f"   üíæ –í –∫—ç—à–µ: {cached_count} –∑–∞–ø—Ä–æ—Å–æ–≤ (–±–µ–∑ –¥—É–±–ª–µ–π)")
                print_stage(f"   üóëÔ∏è  –î—É–±–ª–∏–∫–∞—Ç–æ–≤ –≤ CSV: {duplicates_in_csv}")
                print_stage(f"\nüíæ –ü–µ—Ä–µ–∑–∞–ø–∏—Å—å CSV —Å –æ—á–∏—â–µ–Ω–Ω—ã–º–∏ –¥–∞–Ω–Ω—ã–º–∏...")
                
                success = save_filtered_queries(
                    analyzer.df,
                    input_file,
                    backup=True
                )
                
                if success:
                    print_stage(f"‚úì CSV —Ñ–∞–π–ª —Å–∏–Ω—Ö—Ä–æ–Ω–∏–∑–∏—Ä–æ–≤–∞–Ω —Å –∫—ç—à–µ–º")
                    print_stage(f"‚úì –£–¥–∞–ª–µ–Ω–æ {duplicates_in_csv} –¥—É–±–ª–µ–π –∏–∑ –∏—Å—Ö–æ–¥–Ω–æ–≥–æ —Ñ–∞–π–ª–∞")
                else:
                    print_stage(f"‚ùå –ù–µ —É–¥–∞–ª–æ—Å—å —Å–∏–Ω—Ö—Ä–æ–Ω–∏–∑–∏—Ä–æ–≤–∞—Ç—å CSV —Ñ–∞–π–ª")
        
        except Exception:
            pass
    
    @staticmethod
    def save_to_cache(analyzer, total_duplicates, print_stage):
        """
        –°–æ—Ö—Ä–∞–Ω–∏—Ç—å –¥–∞–Ω–Ω—ã–µ –≤ –∫—ç—à
        
        Args:
            analyzer: –≠–∫–∑–µ–º–ø–ª—è—Ä SEOAnalyzer
            total_duplicates: –û–±—â–µ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ —É–¥–∞–ª–µ–Ω–Ω—ã—Ö –¥—É–±–ª–µ–π
            print_stage: –§—É–Ω–∫—Ü–∏—è –¥–ª—è –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏—è
        """
        if hasattr(analyzer, 'query_cache') and hasattr(analyzer, 'current_group') and analyzer.current_group:
            print_stage("\nüíæ –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –æ–±—Ä–∞–±–æ—Ç–∞–Ω–Ω—ã—Ö –∑–∞–ø—Ä–æ—Å–æ–≤ –≤ –∫—ç—à...")
            
            analyzer.query_cache.save_queries(
                group_name=analyzer.current_group.name,
                csv_path=analyzer.current_group.input_file,
                df=analyzer.df,
                duplicates_removed=total_duplicates
            )
            
            print_stage(f"  ‚ö° –°–ª–µ–¥—É—é—â–∏–π –∑–∞–ø—É—Å–∫ –±—É–¥–µ—Ç –º–≥–Ω–æ–≤–µ–Ω–Ω—ã–º (–±–µ–∑ –ø—Ä–µ–¥–æ–±—Ä–∞–±–æ—Ç–∫–∏)")
            print_stage(f"  üí° CSV –æ–±–Ω–æ–≤–ª—ë–Ω, –∫—ç—à —Å–∏–Ω—Ö—Ä–æ–Ω–∏–∑–∏—Ä–æ–≤–∞–Ω")
    
    @staticmethod
    def save_filtered_to_csv(args, analyzer, print_stage):
        """
        –°–æ—Ö—Ä–∞–Ω–∏—Ç—å –æ—Ç—Ñ–∏–ª—å—Ç—Ä–æ–≤–∞–Ω–Ω—ã–µ –∑–∞–ø—Ä–æ—Å—ã –≤ CSV
        
        Args:
            args: –ê—Ä–≥—É–º–µ–Ω—Ç—ã –∫–æ–º–∞–Ω–¥–Ω–æ–π —Å—Ç—Ä–æ–∫–∏
            analyzer: –≠–∫–∑–µ–º–ø–ª—è—Ä SEOAnalyzer
            print_stage: –§—É–Ω–∫—Ü–∏—è –¥–ª—è –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏—è
        """
        input_file = None
        
        if hasattr(analyzer, 'current_group') and analyzer.current_group:
            input_file = analyzer.current_group.input_file
        elif hasattr(args, 'input_file') and args.input_file:
            input_file = Path(args.input_file)
            if not input_file.is_absolute():
                input_file = Path.cwd() / input_file
        
        if input_file:
            success = save_filtered_queries(
                analyzer.df,
                input_file,
                backup=True
            )
            
            if success:
                print_stage(f"‚úì –ò—Å—Ö–æ–¥–Ω—ã–π —Ñ–∞–π–ª –æ–±–Ω–æ–≤–ª–µ–Ω (–±–µ–∑ –¥—É–±–ª–µ–π, —Ç–æ–ª—å–∫–æ —Ü–µ–ª–µ–≤—ã–µ –∑–∞–ø—Ä–æ—Å—ã)")
            else:
                print_stage(f"‚ö†Ô∏è  –ù–µ —É–¥–∞–ª–æ—Å—å –æ–±–Ω–æ–≤–∏—Ç—å –∏—Å—Ö–æ–¥–Ω—ã–π —Ñ–∞–π–ª")
        else:
            print_stage(f"‚ö†Ô∏è  –ù–µ —É–¥–∞–ª–æ—Å—å –æ–ø—Ä–µ–¥–µ–ª–∏—Ç—å –ø—É—Ç—å –∫ –∏—Å—Ö–æ–¥–Ω–æ–º—É —Ñ–∞–π–ª—É")

