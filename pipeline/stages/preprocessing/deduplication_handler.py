"""
–û–±—Ä–∞–±–æ—Ç–∫–∞ –¥–µ–¥—É–ø–ª–∏–∫–∞—Ü–∏–∏ –∑–∞–ø—Ä–æ—Å–æ–≤
"""

from pathlib import Path
from seo_analyzer.clustering.deduplicator import QueryDeduplicator
from seo_analyzer.clustering.advanced_deduplicator import AdvancedDeduplicator, load_stopwords_from_file


class DeduplicationHandler:
    """–û–±—Ä–∞–±–æ—Ç—á–∏–∫ –¥–µ–¥—É–ø–ª–∏–∫–∞—Ü–∏–∏"""
    
    def __init__(self):
        """–ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –æ–±—Ä–∞–±–æ—Ç—á–∏–∫–∞"""
        self.deduplicator = None
        self.advanced_deduplicator = None
        self.removed_implicit_duplicates = None
    
    def deduplicate_exact(self, df, print_stage):
        """
        –°—Ç–∞–Ω–¥–∞—Ä—Ç–Ω–∞—è –¥–µ–¥—É–ø–ª–∏–∫–∞—Ü–∏—è (—Ç–æ—á–Ω—ã–µ –¥—É–±–ª–∏)
        
        Args:
            df: DataFrame
            print_stage: –§—É–Ω–∫—Ü–∏—è –¥–ª—è –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏—è
            
        Returns:
            DataFrame –±–µ–∑ –¥—É–±–ª–µ–π
        """
        print_stage("üîÑ –î–µ–¥—É–ø–ª–∏–∫–∞—Ü–∏—è (—Ç–æ—á–Ω—ã–µ –¥—É–±–ª–∏)...")
        self.deduplicator = QueryDeduplicator()
        df = self.deduplicator.deduplicate(
            df,
            normalized_column='normalized',
            original_column='keyword',
            freq_column='frequency_exact'
        )
        
        stats = self.deduplicator.get_deduplication_stats()
        print_stage(f"‚úì –£–¥–∞–ª–µ–Ω–æ —Ç–æ—á–Ω—ã—Ö –¥—É–±–ª–µ–π: {stats['total_duplicates_removed']}")
        return df, stats
    
    def deduplicate_advanced(self, df, print_stage):
        """
        –ü—Ä–æ–¥–≤–∏–Ω—É—Ç–∞—è –¥–µ–¥—É–ø–ª–∏–∫–∞—Ü–∏—è (–Ω–µ—è–≤–Ω—ã–µ –¥—É–±–ª–∏)
        
        Args:
            df: DataFrame
            print_stage: –§—É–Ω–∫—Ü–∏—è –¥–ª—è –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏—è
            
        Returns:
            DataFrame –±–µ–∑ –¥—É–±–ª–µ–π –∏ —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞
        """
        print_stage("üîÑ –ü–æ–∏—Å–∫ –Ω–µ—è–≤–Ω—ã—Ö –¥—É–±–ª–µ–π...")
        stopwords_file = Path('keywords_settings/stop_keywords.txt')
        dedup_stopwords = load_stopwords_from_file(stopwords_file) if stopwords_file.exists() else set()
        
        self.advanced_deduplicator = AdvancedDeduplicator(stopwords=dedup_stopwords)
        df, removed_df = self.advanced_deduplicator.remove_duplicates(
            df,
            keyword_column='keyword',
            freq_column='frequency_world'
        )
        
        adv_stats = self.advanced_deduplicator.get_deduplication_stats()
        print_stage(f"‚úì –£–¥–∞–ª–µ–Ω–æ –Ω–µ—è–≤–Ω—ã—Ö –¥—É–±–ª–µ–π: {adv_stats['total_duplicates_removed']} ({adv_stats['duplicate_groups']} –≥—Ä—É–ø–ø)")
        print_stage(f"‚úì –£–Ω–∏–∫–∞–ª—å–Ω—ã—Ö –∑–∞–ø—Ä–æ—Å–æ–≤: {adv_stats['unique_queries']}")
        
        self.removed_implicit_duplicates = removed_df
        return df, adv_stats

