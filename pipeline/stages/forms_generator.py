"""–≠—Ç–∞–ø 5: –ì–µ–Ω–µ—Ä–∞—Ü–∏—è –ø–∞–¥–µ–∂–Ω—ã—Ö —Ñ–æ—Ä–º"""

from seo_analyzer.core.forms_generator import FormsGenerator


async def generate_forms_stage(args, analyzer):
    """
    –ì–µ–Ω–µ—Ä–∞—Ü–∏—è –ø–∞–¥–µ–∂–Ω—ã—Ö —Ñ–æ—Ä–º
    
    Args:
        args: –ê—Ä–≥—É–º–µ–Ω—Ç—ã –∫–æ–º–∞–Ω–¥–Ω–æ–π —Å—Ç—Ä–æ–∫–∏
        analyzer: –≠–∫–∑–µ–º–ø–ª—è—Ä SEOAnalyzer
        
    Returns:
        None (–¥–∞–Ω–Ω—ã–µ —Å–æ—Ö—Ä–∞–Ω—è—é—Ç—Å—è –≤ analyzer)
    """
    print("üìù –≠–¢–ê–ü 8: –ì–µ–Ω–µ—Ä–∞—Ü–∏—è —Å–ª–æ–≤–æ—Ñ–æ—Ä–º")
    print("-" * 80)
    
    # –ü—Ä–æ–≤–µ—Ä—è–µ–º —á—Ç–æ DataFrame –Ω–µ –ø—É—Å—Ç–æ–π
    if len(analyzer.df) == 0:
        print("‚ö†Ô∏è  DataFrame –ø—É—Å—Ç–æ–π, –ø—Ä–æ–ø—É—Å–∫–∞–µ–º –≥–µ–Ω–µ—Ä–∞—Ü–∏—é —Å–ª–æ–≤–æ—Ñ–æ—Ä–º")
        print()
        return
    
    print("üîÑ –ì–µ–Ω–µ—Ä–∞—Ü–∏—è –ø–∞–¥–µ–∂–Ω—ã—Ö —Ñ–æ—Ä–º (—ç—Ç–æ –º–æ–∂–µ—Ç –∑–∞–Ω—è—Ç—å –≤—Ä–µ–º—è)...")
    
    analyzer.forms_generator = FormsGenerator()
    
    # –ì–µ–Ω–µ—Ä–∏—Ä—É–µ–º —Ñ–æ—Ä–º—ã –¥–ª—è —Ç–æ–ø –∑–∞–ø—Ä–æ—Å–æ–≤ (–¥–ª—è —ç–∫–æ–Ω–æ–º–∏–∏ –≤—Ä–µ–º–µ–Ω–∏)
    top_n = min(1000, len(analyzer.df))
    top_queries = analyzer.df.nlargest(top_n, 'frequency_world')['keyword'].tolist()
    
    forms_results = analyzer.forms_generator.generate_forms_batch(top_queries)
    
    # –°–æ–∑–¥–∞–µ–º —Å–ª–æ–≤–∞—Ä—å –¥–ª—è –±—ã—Å—Ç—Ä–æ–≥–æ –ø–æ–∏—Å–∫–∞
    forms_dict = {r['original']: r['forms'] for r in forms_results}
    
    # –î–æ–±–∞–≤–ª—è–µ–º —Ñ–æ—Ä–º—ã –≤ DataFrame
    for case_name in ['nominative', 'genitive', 'dative', 'accusative', 
                      'instrumental', 'prepositional']:
        analyzer.df[f'form_{case_name}'] = analyzer.df['keyword'].map(
            lambda x: forms_dict.get(x, {}).get(case_name, x)
        )
    
    print(f"‚úì –§–æ—Ä–º—ã —Å–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞–Ω—ã –¥–ª—è {len(forms_dict)} –∑–∞–ø—Ä–æ—Å–æ–≤")
    print()

