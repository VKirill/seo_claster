"""–≠—Ç–∞–ø 6: –≠–∫—Å–ø–æ—Ä—Ç –≤—Å–µ—Ö —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤"""

import os
import pandas as pd
from seo_analyzer.export.csv_exporter import CSVExporter
from seo_analyzer.export.json_exporter import JSONExporter
from seo_analyzer.export.graph_exporter import GraphExporter
# –û–¢–ö–õ–Æ–ß–ï–ù–û: from seo_analyzer.export.html_visualizer import HTMLVisualizer
from seo_analyzer.export.excel_exporter import ExcelExporter
from seo_analyzer.core.config import EXCEL_CONFIG, HIERARCHY_CONFIG, PROJECT_ROOT
# –û–¢–ö–õ–Æ–ß–ï–ù–û: from seo_analyzer.analysis import HierarchyBuilder
# –û–¢–ö–õ–Æ–ß–ï–ù–û: –ê–Ω–∞–ª–∏–∑ —Å–≤—è–∑–µ–π –º–µ–∂–¥—É –∫–ª–∞—Å—Ç–µ—Ä–∞–º–∏
# from seo_analyzer.analysis.cluster_relationship_analyzer import ClusterRelationshipAnalyzer
# from seo_analyzer.analysis.cluster_relationship_applier import apply_cluster_relationships


def get_deepseek_api_key():
    """
    –ü–æ–ª—É—á–∏—Ç—å DeepSeek API –∫–ª—é—á –∏–∑ —Ä–∞–∑–Ω—ã—Ö –∏—Å—Ç–æ—á–Ω–∏–∫–æ–≤
    
    Returns:
        API –∫–ª—é—á –∏–ª–∏ None
    """
    # 1. –ü–æ–ø—Ä–æ–±–æ–≤–∞—Ç—å config_local.py
    try:
        import config_local
        api_key = getattr(config_local, 'DEEPSEEK_API_KEY', None)
        if api_key and api_key != "":
            print("‚úì DeepSeek API –∫–ª—é—á –∑–∞–≥—Ä—É–∂–µ–Ω –∏–∑ config_local.py")
            return api_key
    except ImportError:
        pass
    
    # 2. –ü–æ–ø—Ä–æ–±–æ–≤–∞—Ç—å –ø–µ—Ä–µ–º–µ–Ω–Ω—É—é –æ–∫—Ä—É–∂–µ–Ω–∏—è
    api_key = os.getenv('DEEPSEEK_API_KEY')
    if api_key:
        print("‚úì DeepSeek API –∫–ª—é—á –∑–∞–≥—Ä—É–∂–µ–Ω –∏–∑ –ø–µ—Ä–µ–º–µ–Ω–Ω–æ–π –æ–∫—Ä—É–∂–µ–Ω–∏—è")
        return api_key
    
    # 3. –ü–æ–ø—Ä–æ–±–æ–≤–∞—Ç—å –∏–∑ –∫–æ–Ω—Ñ–∏–≥–∞
    api_key = HIERARCHY_CONFIG.get('deepseek_api_key', '')
    if api_key and api_key != "":
        return api_key
    
    return None


def is_hierarchy_enabled():
    """
    –ü—Ä–æ–≤–µ—Ä–∏—Ç—å –≤–∫–ª—é—á–µ–Ω –ª–∏ –∞–Ω–∞–ª–∏–∑ –∏–µ—Ä–∞—Ä—Ö–∏–∏
    
    Returns:
        True –µ—Å–ª–∏ –≤–∫–ª—é—á–µ–Ω
    """
    # 1. –ü–æ–ø—Ä–æ–±–æ–≤–∞—Ç—å config_local.py
    try:
        import config_local
        enabled = getattr(config_local, 'ENABLE_HIERARCHY_ANALYSIS', None)
        if enabled is not None:
            return enabled
    except ImportError:
        pass
    
    # 2. –ü–æ–ø—Ä–æ–±–æ–≤–∞—Ç—å –ø–µ—Ä–µ–º–µ–Ω–Ω—É—é –æ–∫—Ä—É–∂–µ–Ω–∏—è
    env_enabled = os.getenv('ENABLE_HIERARCHY_ANALYSIS')
    if env_enabled is not None:
        return env_enabled.lower() in ['true', '1', 'yes']
    
    # 3. –ò–∑ –∫–æ–Ω—Ñ–∏–≥–∞
    return HIERARCHY_CONFIG.get('enabled', False)


async def export_results_stage(args, analyzer):
    """
    –≠–∫—Å–ø–æ—Ä—Ç –≤—Å–µ—Ö —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤
    
    Args:
        args: –ê—Ä–≥—É–º–µ–Ω—Ç—ã –∫–æ–º–∞–Ω–¥–Ω–æ–π —Å—Ç—Ä–æ–∫–∏
        analyzer: –≠–∫–∑–µ–º–ø–ª—è—Ä SEOAnalyzer
        
    Returns:
        None (—Ñ–∞–π–ª—ã —Å–æ—Ö—Ä–∞–Ω—è—é—Ç—Å—è –≤ output_dir)
    """
    print("üíæ –≠–¢–ê–ü 9: –≠–∫—Å–ø–æ—Ä—Ç —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤")
    print("-" * 80)
    
    # –ü—Ä–æ–≤–µ—Ä—è–µ–º —á—Ç–æ DataFrame –Ω–µ –ø—É—Å—Ç–æ–π
    if len(analyzer.df) == 0:
        print("‚ö†Ô∏è  DataFrame –ø—É—Å—Ç–æ–π –ø–æ—Å–ª–µ —Ñ–∏–ª—å—Ç—Ä–∞—Ü–∏–∏")
        print("‚ö†Ô∏è  –ù–µ—Ç –¥–∞–Ω–Ω—ã—Ö –¥–ª—è —ç–∫—Å–ø–æ—Ä—Ç–∞. –≠–∫—Å–ø–æ—Ä—Ç –ø—Ä–æ–ø—É—â–µ–Ω.")
        print()
        return
    
    # –û–¢–ö–õ–Æ–ß–ï–ù–û: –ê–Ω–∞–ª–∏–∑ —Å–≤—è–∑–µ–π –º–µ–∂–¥—É –∫–ª–∞—Å—Ç–µ—Ä–∞–º–∏ –¥–ª—è –ø–µ—Ä–µ–ª–∏–Ω–∫–æ–≤–∫–∏
    relationships = {}
    # if 'semantic_cluster_id' in analyzer.df.columns:
    #     relationship_analyzer = ClusterRelationshipAnalyzer(
    #         min_url_overlap=3,      # –ú–∏–Ω–∏–º—É–º 3 –æ–±—â–∏—Ö URL
    #         min_word_overlap=2,     # –ú–∏–Ω–∏–º—É–º 2 –æ–±—â–∏—Ö –∫–ª—é—á–µ–≤—ã—Ö —Å–ª–æ–≤–∞
    #         max_related_clusters=5  # –ú–∞–∫—Å–∏–º—É–º 5 —Å–≤—è–∑–∞–Ω–Ω—ã—Ö –∫–ª–∞—Å—Ç–µ—Ä–æ–≤
    #     )
    #     relationships = relationship_analyzer.analyze_relationships(analyzer.df)
    #     
    #     # –î–æ–±–∞–≤–ª—è–µ–º –∫–æ–ª–æ–Ω–∫—É related_clusters –≤ DataFrame
    #     analyzer.df = apply_cluster_relationships(
    #         analyzer.df,
    #         relationships,
    #         cluster_column='semantic_cluster_id'
    #     )
    
    # –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä—É–µ–º —ç–∫—Å–ø–æ—Ä—Ç–µ—Ä—ã (–ø–µ—Ä–µ–¥–∞—ë–º relationships –≤ JSON —ç–∫—Å–ø–æ—Ä—Ç–µ—Ä)
    analyzer.csv_exporter = CSVExporter()
    analyzer.json_exporter = JSONExporter(relationships=relationships)
    analyzer.graph_exporter = GraphExporter()
    # –û–¢–ö–õ–Æ–ß–ï–ù–û: analyzer.html_visualizer = HTMLVisualizer()
    
    # –ì–µ–Ω–µ—Ä–∏—Ä—É–µ–º —Å—É—Ñ—Ñ–∏–∫—Å –¥–ª—è —Ñ–∞–π–ª–æ–≤ –Ω–∞ –æ—Å–Ω–æ–≤–µ –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤ –∫–ª–∞—Å—Ç–µ—Ä–∏–∑–∞—Ü–∏–∏
    clustering_threshold = getattr(args, 'clustering_threshold', None)
    max_cluster_size_param = getattr(args, 'max_cluster_size_param', None)
    
    if clustering_threshold is not None:
        if max_cluster_size_param is not None:
            # –û–±–∞ –ø–∞—Ä–∞–º–µ—Ç—Ä–∞ —É–∫–∞–∑–∞–Ω—ã: "6_0" –∏–ª–∏ "6_50"
            file_suffix = f"_{clustering_threshold}_{max_cluster_size_param}"
        else:
            # –¢–æ–ª—å–∫–æ threshold: "6"
            file_suffix = f"_{clustering_threshold}"
    else:
        file_suffix = ""
    
    # CSV —ç–∫—Å–ø–æ—Ä—Ç
    csv_path = analyzer.output_dir / f"seo_analysis_full{file_suffix}.csv"
    analyzer.csv_exporter.export_full_results(analyzer.df, csv_path)
    
    # –¢–æ–ø –∑–∞–ø—Ä–æ—Å—ã (–û–¢–ö–õ–Æ–ß–ï–ù–û: –Ω–µ –∏—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è)
    # top_csv = analyzer.output_dir / "seo_analysis_top1000.csv"
    # analyzer.csv_exporter.export_top_queries(analyzer.df, top_csv, top_n=1000)
    
    # –°–≤–æ–¥–∫–∞ –∫–ª–∞—Å—Ç–µ—Ä–æ–≤ (–û–¢–ö–õ–Æ–ß–ï–ù–û: –Ω–µ –∏—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è)
    # –ö–ª–∞—Å—Ç–µ—Ä—ã (—Ç–æ–ª—å–∫–æ –µ—Å–ª–∏ –µ—Å—Ç—å semantic_cluster_id)
    if 'semantic_cluster_id' in analyzer.df.columns:
        # clusters_csv = analyzer.output_dir / "clusters_summary.csv"
        # analyzer.csv_exporter.export_clusters_summary(analyzer.df, clusters_csv)
        
        # JSON —ç–∫—Å–ø–æ—Ä—Ç
        json_path = analyzer.output_dir / f"seo_analysis_hierarchy{file_suffix}.json"
        clustering_params = getattr(args, 'clustering_params', None)
        analyzer.json_exporter.export_hierarchical(analyzer.df, json_path, clustering_params=clustering_params)
    else:
        print("‚ÑπÔ∏è  –ü—Ä–æ–ø—É—Å–∫–∞–µ–º —ç–∫—Å–ø–æ—Ä—Ç –∫–ª–∞—Å—Ç–µ—Ä–æ–≤ (–≠–¢–ê–ü 4 –æ—Ç–∫–ª—é—á–µ–Ω)")
    
    # –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞
    stats_path = analyzer.output_dir / f"statistics{file_suffix}.json"
    analyzer.json_exporter.export_statistics(analyzer.df, stats_path)
    
    # –ì—Ä–∞—Ñ (–µ—Å–ª–∏ –ø–æ—Å—Ç—Ä–æ–µ–Ω)
    if analyzer.graph_builder and analyzer.graph_builder.graph:
        graphml_path = analyzer.output_dir / f"queries_graph{file_suffix}.graphml"
        analyzer.graph_exporter.export_graphml(
            analyzer.graph_builder.graph,
            graphml_path,
            analyzer.graph_builder.communities,
            analyzer.graph_builder.pagerank_scores
        )
        
        gexf_path = analyzer.output_dir / f"queries_graph{file_suffix}.gexf"
        analyzer.graph_exporter.export_gexf(
            analyzer.graph_builder.graph,
            gexf_path,
            analyzer.graph_builder.communities,
            analyzer.graph_builder.pagerank_scores
        )
    
    # HTML –¥–∞—à–±–æ—Ä–¥ (–û–¢–ö–õ–Æ–ß–ï–ù–û: –Ω–µ –∏—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è)
    # html_path = analyzer.output_dir / "dashboard.html"
    # analyzer.html_visualizer.generate_dashboard(analyzer.df, html_path)
    
    # Excel —ç–∫—Å–ø–æ—Ä—Ç (–µ—Å–ª–∏ –Ω–µ –ø—Ä–æ–ø—É—â–µ–Ω)
    if not args.skip_excel:
        analyzer.excel_exporter = ExcelExporter()
        excel_path = analyzer.output_dir / f"seo_analysis{file_suffix}.xlsx"
        
        print(f"üíæ –≠–∫—Å–ø–æ—Ä—Ç –≤ Excel: seo_analysis{file_suffix}.xlsx...")
        include_charts = args.excel_with_charts or EXCEL_CONFIG['include_charts']
        
        # –û–¢–ö–õ–Æ–ß–ï–ù–û: –ü–æ—Å—Ç—Ä–æ–µ–Ω–∏–µ –∏–µ—Ä–∞—Ä—Ö–∏–∏ (–µ—Å–ª–∏ –≤–∫–ª—é—á–µ–Ω–æ)
        # hierarchy_df = None
        # if is_hierarchy_enabled() and 'serp_urls' in analyzer.df.columns:
        #     api_key = get_deepseek_api_key()
        #     
        #     if api_key:
        #         try:
        #             print("üèóÔ∏è  –ü–æ—Å—Ç—Ä–æ–µ–Ω–∏–µ –∏–µ—Ä–∞—Ä—Ö–∏–∏ –ø—Ä–æ–µ–∫—Ç–∞...")
        #             
        #             # –ü—É—Ç–∏ –∫ –ë–î –∏ —Å—Ç–æ–ø-–¥–æ–º–µ–Ω–∞–º
        #             db_path = analyzer.output_dir / "page_content.db"
        #             stop_domains_file = PROJECT_ROOT / "keywords_stop" / "domain_stop.txt"
        #             
        #             hierarchy_builder = HierarchyBuilder(
        #                 deepseek_api_key=api_key,
        #                 max_urls_per_query=HIERARCHY_CONFIG.get('max_urls_per_query', 3),
        #                 db_path=db_path,
        #                 stop_domains_file=stop_domains_file,
        #                 collect_breadcrumbs=HIERARCHY_CONFIG.get('collect_breadcrumbs', False),
        #                 use_breadcrumbs=HIERARCHY_CONFIG.get('use_breadcrumbs', False)
        #             )
        #             
        #             hierarchy_result = hierarchy_builder.build_hierarchy_from_dataframe(
        #                 analyzer.df,
        #                 use_clusters=HIERARCHY_CONFIG.get('use_clusters', True)
        #             )
        #             
        #             if hierarchy_result.get('success'):
        #                 hierarchy_df = hierarchy_builder.format_for_excel(hierarchy_result)
        #                 print(f"‚úì –ò–µ—Ä–∞—Ä—Ö–∏—è –ø–æ—Å—Ç—Ä–æ–µ–Ω–∞: {len(hierarchy_df)} –∑–∞–ø–∏—Å–µ–π")
        #             else:
        #                 print(f"‚ö†Ô∏è  –ù–µ —É–¥–∞–ª–æ—Å—å –ø–æ—Å—Ç—Ä–æ–∏—Ç—å –∏–µ—Ä–∞—Ä—Ö–∏—é: {hierarchy_result.get('error')}")
        #         
        #         except Exception as e:
        #             print(f"‚ö†Ô∏è  –û—à–∏–±–∫–∞ –ø–æ—Å—Ç—Ä–æ–µ–Ω–∏—è –∏–µ—Ä–∞—Ä—Ö–∏–∏: {e}")
        #     else:
        #         print("‚ÑπÔ∏è  API –∫–ª—é—á DeepSeek –Ω–µ –Ω–∞—Å—Ç—Ä–æ–µ–Ω, –∏–µ—Ä–∞—Ä—Ö–∏—è –Ω–µ –±—É–¥–µ—Ç –ø–æ—Å—Ç—Ä–æ–µ–Ω–∞")
        # 
        # # –£—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞–µ–º –¥–∞–Ω–Ω—ã–µ –∏–µ—Ä–∞—Ä—Ö–∏–∏ –≤ —ç–∫—Å–ø–æ—Ä—Ç–µ—Ä
        # if hierarchy_df is not None and not hierarchy_df.empty:
        #     analyzer.excel_exporter.set_hierarchy_data(hierarchy_df)
        
        analyzer.excel_exporter.export_to_excel(
            analyzer.df,
            excel_path,
            include_charts=include_charts,
            group_by_clusters=EXCEL_CONFIG['group_by_clusters']
        )
        
        print(f"‚úì Excel —Ñ–∞–π–ª —Å–æ–∑–¥–∞–Ω: {excel_path}")
    
    # –≠–∫—Å–ø–æ—Ä—Ç –±—Ä–µ–Ω–¥–æ–≤ (–∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏)
    if analyzer.brand_detector:
        print("üíæ –≠–∫—Å–ø–æ—Ä—Ç –±—Ä–µ–Ω–¥–æ–≤: brands.csv...")
        
        # –ü–æ–ª—É—á–∞–µ–º –≤—Å–µ –Ω–∞–π–¥–µ–Ω–Ω—ã–µ –±—Ä–µ–Ω–¥—ã
        all_brands = analyzer.brand_detector.get_top_brands(1000)  # –¢–æ–ø-1000
        
        if all_brands:
            brands_df = pd.DataFrame(all_brands, columns=['brand', 'count'])
            
            # –ü–æ–ª–Ω–∞—è —Ç–∞–±–ª–∏—Ü–∞ –±—Ä–µ–Ω–¥–æ–≤
            brands_path = analyzer.output_dir / f"brands{file_suffix}.csv"
            brands_df.to_csv(brands_path, index=False, encoding='utf-8-sig')
            
            # –¢–æ–ø-100 –±—Ä–µ–Ω–¥–æ–≤
            top_brands_path = analyzer.output_dir / f"brands_top100{file_suffix}.csv"
            brands_df.head(100).to_csv(top_brands_path, index=False, encoding='utf-8-sig')
            
            print(f"‚úì –≠–∫—Å–ø–æ—Ä—Ç–∏—Ä–æ–≤–∞–Ω–æ {len(brands_df)} –±—Ä–µ–Ω–¥–æ–≤")
            print(f"  - {brands_path.name} (–≤—Å–µ –±—Ä–µ–Ω–¥—ã)")
            print(f"  - {top_brands_path.name} (—Ç–æ–ø-100)")
            
            # –î–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω–æ: —ç–∫—Å–ø–æ—Ä—Ç –∑–∞–ø—Ä–æ—Å–æ–≤ —Å –±—Ä–µ–Ω–¥–∞–º–∏
            if 'is_brand' in analyzer.df.columns:
                branded_queries = analyzer.df[analyzer.df['is_brand'] == True].copy()
                if len(branded_queries) > 0:
                    branded_path = analyzer.output_dir / f"branded_queries{file_suffix}.csv"
                    branded_queries.to_csv(branded_path, index=False, encoding='utf-8-sig')
                    print(f"  - {branded_path.name} ({len(branded_queries)} –±—Ä–µ–Ω–¥–æ–≤—ã—Ö –∑–∞–ø—Ä–æ—Å–æ–≤)")
        else:
            print("  ‚ÑπÔ∏è  –ë—Ä–µ–Ω–¥—ã –Ω–µ –Ω–∞–π–¥–µ–Ω—ã")
    
    # –≠–∫—Å–ø–æ—Ä—Ç –∑–∞–±–ª–æ–∫–∏—Ä–æ–≤–∞–Ω–Ω—ã—Ö —Å—Ç–æ–ø-—Å–ª–æ–≤–∞–º–∏ –∑–∞–ø—Ä–æ—Å–æ–≤
    if hasattr(analyzer, 'stopwords_filter') and analyzer.stopwords_filter.blocked_queries:
        print("üíæ –≠–∫—Å–ø–æ—Ä—Ç –∑–∞–ø—Ä–æ—Å–æ–≤ —Å–æ —Å—Ç–æ–ø-—Å–ª–æ–≤–∞–º–∏: stopwords_blocked.csv...")
        blocked_df = pd.DataFrame(analyzer.stopwords_filter.blocked_queries)
        blocked_path = analyzer.output_dir / f"stopwords_blocked{file_suffix}.csv"
        blocked_df.to_csv(blocked_path, index=False, encoding='utf-8-sig')
        print(f"‚úì –≠–∫—Å–ø–æ—Ä—Ç–∏—Ä–æ–≤–∞–Ω–æ {len(blocked_df)} –∑–∞–±–ª–æ–∫–∏—Ä–æ–≤–∞–Ω–Ω—ã—Ö –∑–∞–ø—Ä–æ—Å–æ–≤")
    
    # –≠–∫—Å–ø–æ—Ä—Ç —É–¥–∞–ª–µ–Ω–Ω—ã—Ö –Ω–µ—è–≤–Ω—ã—Ö –¥—É–±–ª–µ–π
    if hasattr(analyzer, 'removed_implicit_duplicates') and not analyzer.removed_implicit_duplicates.empty:
        print("üíæ –≠–∫—Å–ø–æ—Ä—Ç –Ω–µ—è–≤–Ω—ã—Ö –¥—É–±–ª–µ–π: implicit_duplicates_removed.csv...")
        removed_path = analyzer.output_dir / f"implicit_duplicates_removed{file_suffix}.csv"
        analyzer.removed_implicit_duplicates.to_csv(removed_path, index=False, encoding='utf-8-sig')
        print(f"‚úì –≠–∫—Å–ø–æ—Ä—Ç–∏—Ä–æ–≤–∞–Ω–æ {len(analyzer.removed_implicit_duplicates)} —É–¥–∞–ª–µ–Ω–Ω—ã—Ö –¥—É–±–ª–µ–π")
    
    # –≠–∫—Å–ø–æ—Ä—Ç –≥—Ä—É–ø–ø –¥—É–±–ª–µ–π –¥–ª—è –ø—Ä–æ–≤–µ—Ä–∫–∏
    if hasattr(analyzer, 'advanced_deduplicator') and analyzer.advanced_deduplicator.duplicate_groups:
        print("üíæ –≠–∫—Å–ø–æ—Ä—Ç –≥—Ä—É–ø–ø –¥—É–±–ª–µ–π: implicit_duplicates_groups.csv...")
        groups_path = analyzer.output_dir / f"implicit_duplicates_groups{file_suffix}.csv"
        analyzer.advanced_deduplicator.export_duplicate_groups(groups_path)
    
    print()

