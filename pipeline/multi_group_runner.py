"""
Multi-Group Runner
–ó–∞–ø—É—Å–∫ –∞–Ω–∞–ª–∏–∑–∞ –¥–ª—è –Ω–µ—Å–∫–æ–ª—å–∫–∏—Ö –≥—Ä—É–ø–ø –∑–∞–ø—Ä–æ—Å–æ–≤
"""

import asyncio
from pathlib import Path
from typing import List

from .analyzer import SEOAnalyzer
from seo_analyzer.core.query_groups import QueryGroupManager


class MultiGroupRunner:
    """–ó–∞–ø—É—Å–∫ –∞–Ω–∞–ª–∏–∑–∞ –¥–ª—è –Ω–µ—Å–∫–æ–ª—å–∫–∏—Ö –≥—Ä—É–ø–ø"""
    
    def __init__(self, args):
        """
        –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è runner'–∞
        
        Args:
            args: –ê—Ä–≥—É–º–µ–Ω—Ç—ã –∫–æ–º–∞–Ω–¥–Ω–æ–π —Å—Ç—Ä–æ–∫–∏
        """
        self.args = args
        self.group_manager = QueryGroupManager()
        self.group_manager.discover_groups()
    
    async def run_all_groups(self, parallel: bool = True, unified_serp: bool = True):
        """
        –ó–∞–ø—É—Å–∫ –∞–Ω–∞–ª–∏–∑–∞ –¥–ª—è –≤—Å–µ—Ö –≥—Ä—É–ø–ø
        
        Args:
            parallel: True –¥–ª—è –ø–∞—Ä–∞–ª–ª–µ–ª—å–Ω–æ–π –æ–±—Ä–∞–±–æ—Ç–∫–∏ (—Ä–µ–∫–æ–º–µ–Ω–¥—É–µ—Ç—Å—è)
            unified_serp: True –¥–ª—è –æ–±—ä–µ–¥–∏–Ω–µ–Ω–Ω–æ–π –æ–±—Ä–∞–±–æ—Ç–∫–∏ SERP –≤—Å–µ—Ö –≥—Ä—É–ø–ø (–≤—Å–µ –∑–∞–ø—Ä–æ—Å—ã –≤–º–µ—Å—Ç–µ)
        """
        groups = self.group_manager.groups
        
        if not groups:
            print("‚ö†Ô∏è  –ì—Ä—É–ø–ø—ã –Ω–µ –Ω–∞–π–¥–µ–Ω—ã –≤ semantika/")
            return
        
        print("=" * 80)
        print(f"üöÄ MULTI-GROUP ANALYSIS - –û–±—Ä–∞–±–æ—Ç–∫–∞ {len(groups)} –≥—Ä—É–ø–ø")
        if unified_serp and len(groups) > 1:
            print("‚ö° –†–µ–∂–∏–º: –û–ë–™–ï–î–ò–ù–ï–ù–ù–ê–Ø –æ–±—Ä–∞–±–æ—Ç–∫–∞ SERP (–≤—Å–µ –∑–∞–ø—Ä–æ—Å—ã –∏–∑ –≤—Å–µ—Ö –≥—Ä—É–ø–ø –≤–º–µ—Å—Ç–µ)")
            print("   –í—Å–µ –∑–∞–ø—Ä–æ—Å—ã —Ä–∞—Å–ø—Ä–µ–¥–µ–ª—è—é—Ç—Å—è –ø–æ –ø—Ä–æ–∫—Å–∏ –∏ –æ–±—Ä–∞–±–∞—Ç—ã–≤–∞—é—Ç—Å—è –æ–¥–Ω–æ–≤—Ä–µ–º–µ–Ω–Ω–æ")
        elif parallel and len(groups) > 1:
            print("‚ö° –†–µ–∂–∏–º: –ü–ê–†–ê–õ–õ–ï–õ–¨–ù–ê–Ø –æ–±—Ä–∞–±–æ—Ç–∫–∞ (–±—ã—Å—Ç—Ä–µ–µ –±–ª–∞–≥–æ–¥–∞—Ä—è SERP –∫—ç—à—É)")
        else:
            print("‚ö° –†–µ–∂–∏–º: –ü–û–°–õ–ï–î–û–í–ê–¢–ï–õ–¨–ù–ê–Ø –æ–±—Ä–∞–±–æ—Ç–∫–∞")
        print("=" * 80)
        print()
        
        if unified_serp and len(groups) > 1:
            # –û–±—ä–µ–¥–∏–Ω–µ–Ω–Ω–∞—è –æ–±—Ä–∞–±–æ—Ç–∫–∞ SERP - –≤—Å–µ –∑–∞–ø—Ä–æ—Å—ã –∏–∑ –≤—Å–µ—Ö –≥—Ä—É–ø–ø –≤–º–µ—Å—Ç–µ
            await self._run_groups_unified_serp(groups)
        elif parallel and len(groups) > 1:
            # –ü–∞—Ä–∞–ª–ª–µ–ª—å–Ω–∞—è –æ–±—Ä–∞–±–æ—Ç–∫–∞
            await self._run_groups_parallel(groups)
        else:
            # –ü–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω–∞—è –æ–±—Ä–∞–±–æ—Ç–∫–∞
            await self._run_groups_sequential(groups)
        
        print("\n" + "=" * 80)
        print("‚úÖ –í–°–ï –ì–†–£–ü–ü–´ –û–ë–†–ê–ë–û–¢–ê–ù–´")
        print("=" * 80)
        
        # –§–∏–Ω–∞–ª—å–Ω–∞—è —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞
        self._print_summary()
    
    async def _run_groups_sequential(self, groups):
        """–ü–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω–∞—è –æ–±—Ä–∞–±–æ—Ç–∫–∞ –≥—Ä—É–ø–ø"""
        for i, group in enumerate(groups, 1):
            print(f"\n{'=' * 80}")
            print(f"üìä –ì–†–£–ü–ü–ê {i}/{len(groups)}: {group.name}")
            print(f"{'=' * 80}\n")
            
            try:
                await self._run_single_group(group)
                print(f"\n‚úÖ –ì—Ä—É–ø–ø–∞ '{group.name}' –æ–±—Ä–∞–±–æ—Ç–∞–Ω–∞ —É—Å–ø–µ—à–Ω–æ")
                
            except Exception as e:
                print(f"\n‚ùå –û—à–∏–±–∫–∞ –æ–±—Ä–∞–±–æ—Ç–∫–∏ –≥—Ä—É–ø–ø—ã '{group.name}': {e}")
                continue
    
    async def _run_groups_parallel(self, groups):
        """
        –ü–∞—Ä–∞–ª–ª–µ–ª—å–Ω–∞—è –æ–±—Ä–∞–±–æ—Ç–∫–∞ –≥—Ä—É–ø–ø
        
        –ü—Ä–µ–∏–º—É—â–µ—Å—Ç–≤–∞:
        - –ï—Å–ª–∏ SERP –¥–∞–Ω–Ω—ã–µ —É–∂–µ –≤ –ë–î, –≥—Ä—É–ø–ø–∞ –æ–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ—Ç—Å—è —Å—Ä–∞–∑—É
        - –ü–æ–∫–∞ –æ–¥–Ω–∞ –≥—Ä—É–ø–ø–∞ –∂–¥–µ—Ç API, –¥—Ä—É–≥–∏–µ –∏—Å–ø–æ–ª—å–∑—É—é—Ç –∫—ç—à
        - –ó–Ω–∞—á–∏—Ç–µ–ª—å–Ω–æ –±—ã—Å—Ç—Ä–µ–µ –ø—Ä–∏ –Ω–∞–ª–∏—á–∏–∏ –∫—ç—à–∞
        """
        # –°–æ–∑–¥–∞–µ–º –∑–∞–¥–∞—á–∏ –¥–ª—è –≤—Å–µ—Ö –≥—Ä—É–ø–ø
        tasks = []
        for i, group in enumerate(groups, 1):
            task = asyncio.create_task(
                self._run_single_group_safe(group, i, len(groups))
            )
            tasks.append(task)
        
        # –ó–∞–ø—É—Å–∫–∞–µ–º –≤—Å–µ –∑–∞–¥–∞—á–∏ –ø–∞—Ä–∞–ª–ª–µ–ª—å–Ω–æ
        results = await asyncio.gather(*tasks, return_exceptions=True)
        
        # –û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã
        for i, (group, result) in enumerate(zip(groups, results), 1):
            if isinstance(result, Exception):
                print(f"\n‚ùå –ì—Ä—É–ø–ø–∞ '{group.name}': –û—à–∏–±–∫–∞ - {result}")
            else:
                print(f"‚úÖ –ì—Ä—É–ø–ø–∞ '{group.name}': –ó–∞–≤–µ—Ä—à–µ–Ω–∞")
    
    async def _run_single_group(self, group):
        """–ó–∞–ø—É—Å–∫ –∞–Ω–∞–ª–∏–∑–∞ –¥–ª—è –æ–¥–Ω–æ–π –≥—Ä—É–ø–ø—ã"""
        # –°–æ–∑–¥–∞–µ–º –∫–æ–ø–∏—é –∞—Ä–≥—É–º–µ–Ω—Ç–æ–≤ –¥–ª—è –≥—Ä—É–ø–ø—ã
        group_args = self._prepare_group_args(group)
        
        # –ó–∞–ø—É—Å–∫–∞–µ–º –∞–Ω–∞–ª–∏–∑–∞—Ç–æ—Ä
        analyzer = SEOAnalyzer(group_args)
        analyzer.current_group = group
        analyzer.group_manager = self.group_manager
        
        await analyzer.run()
    
    async def _run_single_group_safe(self, group, index: int, total: int):
        """
        –ë–µ–∑–æ–ø–∞—Å–Ω—ã–π –∑–∞–ø—É—Å–∫ –∞–Ω–∞–ª–∏–∑–∞ –≥—Ä—É–ø–ø—ã (–¥–ª—è –ø–∞—Ä–∞–ª–ª–µ–ª—å–Ω–æ–π –æ–±—Ä–∞–±–æ—Ç–∫–∏)
        
        Args:
            group: QueryGroup
            index: –ù–æ–º–µ—Ä –≥—Ä—É–ø–ø—ã
            total: –í—Å–µ–≥–æ –≥—Ä—É–ø–ø
        """
        print(f"\n{'=' * 80}")
        print(f"üìä –ì–†–£–ü–ü–ê {index}/{total}: {group.name} - –°–¢–ê–†–¢")
        print(f"{'=' * 80}\n")
        
        try:
            await self._run_single_group(group)
            print(f"\n‚úÖ –ì—Ä—É–ø–ø–∞ '{group.name}' –æ–±—Ä–∞–±–æ—Ç–∞–Ω–∞ —É—Å–ø–µ—à–Ω–æ")
            return True
            
        except Exception as e:
            print(f"\n‚ùå –û—à–∏–±–∫–∞ –æ–±—Ä–∞–±–æ—Ç–∫–∏ –≥—Ä—É–ø–ø—ã '{group.name}': {e}")
            import traceback
            traceback.print_exc()
            return False
    
    def _prepare_group_args(self, group):
        """–ü–æ–¥–≥–æ—Ç–æ–≤–∫–∞ –∞—Ä–≥—É–º–µ–Ω—Ç–æ–≤ –¥–ª—è –≥—Ä—É–ø–ø—ã"""
        import copy
        group_args = copy.copy(self.args)
        
        # –£—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞–µ–º –ø—É—Ç—å –∫ —Ñ–∞–π–ª—É –≥—Ä—É–ø–ø—ã
        group_args.input_file = str(group.input_file)
        group_args.group = group.name
        
        return group_args
    
    async def _run_groups_unified_serp(self, groups):
        """
        –û–±—ä–µ–¥–∏–Ω–µ–Ω–Ω–∞—è –æ–±—Ä–∞–±–æ—Ç–∫–∞ SERP –¥–ª—è –≤—Å–µ—Ö –≥—Ä—É–ø–ø
        
        –í—Å–µ –∑–∞–ø—Ä–æ—Å—ã –∏–∑ –≤—Å–µ—Ö –≥—Ä—É–ø–ø —Å–æ–±–∏—Ä–∞—é—Ç—Å—è –≤ –æ–¥–∏–Ω —Å–ø–∏—Å–æ–∫ –∏ –æ–±—Ä–∞–±–∞—Ç—ã–≤–∞—é—Ç—Å—è –≤–º–µ—Å—Ç–µ,
        —Ä–∞—Å–ø—Ä–µ–¥–µ–ª—è—è—Å—å –ø–æ –ø—Ä–æ–∫—Å–∏. –≠—Ç–æ –ø–æ–∑–≤–æ–ª—è–µ—Ç –º–∞–∫—Å–∏–º–∞–ª—å–Ω–æ —ç—Ñ—Ñ–µ–∫—Ç–∏–≤–Ω–æ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å
        –≤—Å–µ –¥–æ—Å—Ç—É–ø–Ω—ã–µ –ø—Ä–æ–∫—Å–∏ –∏ –æ–±—Ä–∞–±–∞—Ç—ã–≤–∞—Ç—å –∑–∞–ø—Ä–æ—Å—ã –ø–∞—Ä–∞–ª–ª–µ–ª—å–Ω–æ.
        """
        print("=" * 80)
        print("üîÑ –û–ë–™–ï–î–ò–ù–ï–ù–ù–ê–Ø –û–ë–†–ê–ë–û–¢–ö–ê SERP - –°–±–æ—Ä –≤—Å–µ—Ö –∑–∞–ø—Ä–æ—Å–æ–≤ –∏–∑ –≤—Å–µ—Ö –≥—Ä—É–ø–ø")
        print("=" * 80)
        print()
        
        # –°–æ–±–∏—Ä–∞–µ–º –≤—Å–µ –∑–∞–ø—Ä–æ—Å—ã –∏–∑ –≤—Å–µ—Ö –≥—Ä—É–ø–ø
        all_queries = []
        query_to_group_map = {}  # –°–ª–æ–≤–∞—Ä—å –¥–ª—è —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è group_name –ø—Ä–∏ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏–∏
        
        for group in groups:
            print(f"üìÅ –ó–∞–≥—Ä—É–∂–∞–µ–º –≥—Ä—É–ø–ø—É: {group.name}")
            try:
                # –ó–∞–≥—Ä—É–∂–∞–µ–º –¥–∞–Ω–Ω—ã–µ –≥—Ä—É–ø–ø—ã
                group_args = self._prepare_group_args(group)
                analyzer = SEOAnalyzer(group_args)
                analyzer.current_group = group
                analyzer.group_manager = self.group_manager
                
                # –ó–∞–≥—Ä—É–∂–∞–µ–º –¥–∞–Ω–Ω—ã–µ (—Ç–æ–ª—å–∫–æ –∑–∞–≥—Ä—É–∑–∫–∞, –±–µ–∑ –æ–±—Ä–∞–±–æ—Ç–∫–∏)
                from pipeline.stages.data_loader import load_data_stage
                await load_data_stage(group_args, analyzer)
                
                # –°–æ–±–∏—Ä–∞–µ–º –∑–∞–ø—Ä–æ—Å—ã –∏–∑ –≥—Ä—É–ø–ø—ã
                group_queries = analyzer.df['keyword'].tolist() if not analyzer.df.empty else []
                all_queries.extend(group_queries)
                
                # –°–æ—Ö—Ä–∞–Ω—è–µ–º —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤–∏–µ –∑–∞–ø—Ä–æ—Å -> –≥—Ä—É–ø–ø–∞
                for query in group_queries:
                    query_to_group_map[query] = group.name
                
                print(f"   ‚úì –ó–∞–≥—Ä—É–∂–µ–Ω–æ {len(group_queries)} –∑–∞–ø—Ä–æ—Å–æ–≤ –∏–∑ –≥—Ä—É–ø–ø—ã '{group.name}'")
                
            except Exception as e:
                print(f"   ‚ùå –û—à–∏–±–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏ –≥—Ä—É–ø–ø—ã '{group.name}': {e}")
                continue
        
        if not all_queries:
            print("‚ö†Ô∏è  –ù–µ –Ω–∞–π–¥–µ–Ω–æ –∑–∞–ø—Ä–æ—Å–æ–≤ –¥–ª—è –æ–±—Ä–∞–±–æ—Ç–∫–∏")
            return
        
        print()
        print(f"üìä –í–°–ï–ì–û –ó–ê–ü–†–û–°–û–í –î–õ–Ø –û–ë–†–ê–ë–û–¢–ö–ò: {len(all_queries)}")
        print(f"   –ò–∑ {len(groups)} –≥—Ä—É–ø–ø")
        print()
        
        # –û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º –≤—Å–µ –∑–∞–ø—Ä–æ—Å—ã –≤–º–µ—Å—Ç–µ —á–µ—Ä–µ–∑ –ø–µ—Ä–≤—É—é –≥—Ä—É–ø–ø—É (–¥–ª—è –ø–æ–ª—É—á–µ–Ω–∏—è –Ω–∞—Å—Ç—Ä–æ–µ–∫)
        first_group = groups[0]
        group_args = self._prepare_group_args(first_group)
        
        # –°–æ–∑–¥–∞–µ–º –≤—Ä–µ–º–µ–Ω–Ω—ã–π –∞–Ω–∞–ª–∏–∑–∞—Ç–æ—Ä –¥–ª—è –æ–±—Ä–∞–±–æ—Ç–∫–∏ SERP
        analyzer = SEOAnalyzer(group_args)
        analyzer.current_group = first_group
        analyzer.group_manager = self.group_manager
        
        # –ó–∞–≥—Ä—É–∂–∞–µ–º –¥–∞–Ω–Ω—ã–µ –ø–µ—Ä–≤–æ–π –≥—Ä—É–ø–ø—ã (–¥–ª—è –ø–æ–ª—É—á–µ–Ω–∏—è –Ω–∞—Å—Ç—Ä–æ–µ–∫)
        # –ù–û: –ø—Ä–æ–ø—É—Å–∫–∞–µ–º –∑–∞–≥—Ä—É–∑–∫—É –∏–∑ CSV, —Ç–∞–∫ –∫–∞–∫ –º—ã —É–∂–µ —Å–æ–±—Ä–∞–ª–∏ –≤—Å–µ –∑–∞–ø—Ä–æ—Å—ã
        # –ü—Ä–æ—Å—Ç–æ —Å–æ–∑–¥–∞–µ–º DataFrame —Å–æ –≤—Å–µ–º–∏ –∑–∞–ø—Ä–æ—Å–∞–º–∏
        import pandas as pd
        analyzer.df = pd.DataFrame({'keyword': all_queries})
        
        # –£—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞–µ–º —Ñ–ª–∞–≥–∏ —á—Ç–æ–±—ã –Ω–µ –ø—ã—Ç–∞—Ç—å—Å—è –∑–∞–≥—Ä—É–∂–∞—Ç—å –∏–∑ CSV
        analyzer.loaded_from_cache = False
        analyzer.loaded_from_master_db = False
        
        # –ó–∞–≥—Ä—É–∂–∞–µ–º —Ç–æ–ª—å–∫–æ —Å–ª–æ–≤–∞—Ä–∏ –∏ –Ω–∞—Å—Ç—Ä–æ–π–∫–∏ (–±–µ–∑ –¥–∞–Ω–Ω—ã—Ö)
        from seo_analyzer.core.helpers import load_all_data, load_intent_weights
        analyzer.keyword_dicts, analyzer.geo_dicts, analyzer.stopwords = await load_all_data()
        analyzer.intent_weights = await load_intent_weights()
        
        # –û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º SERP –¥–ª—è –≤—Å–µ—Ö –∑–∞–ø—Ä–æ—Å–æ–≤ –≤–º–µ—Å—Ç–µ
        from pipeline.stages.serp_analyzer import analyze_serp_stage
        
        # –ü–µ—Ä–µ–¥–∞–µ–º query_to_group_map —á–µ—Ä–µ–∑ analyzer
        analyzer.query_to_group_map = query_to_group_map
        
        print("=" * 80)
        print("üöÄ –ù–ê–ß–ê–õ–û –û–ë–™–ï–î–ò–ù–ï–ù–ù–û–ô –û–ë–†–ê–ë–û–¢–ö–ò SERP")
        print("=" * 80)
        print()
        
        await analyze_serp_stage(group_args, analyzer)
        
        # –ü–æ—Å–ª–µ –æ–±—Ä–∞–±–æ—Ç–∫–∏ SERP –∑–∞–ø—É—Å–∫–∞–µ–º –æ—Å—Ç–∞–ª—å–Ω—ã–µ —ç—Ç–∞–ø—ã –¥–ª—è –∫–∞–∂–¥–æ–π –≥—Ä—É–ø–ø—ã –æ—Ç–¥–µ–ª—å–Ω–æ
        print()
        print("=" * 80)
        print("üîÑ –ó–ê–í–ï–†–®–ï–ù–ò–ï –û–ë–†–ê–ë–û–¢–ö–ò –û–°–¢–ê–õ–¨–ù–´–• –≠–¢–ê–ü–û–í –î–õ–Ø –ö–ê–ñ–î–û–ô –ì–†–£–ü–ü–´")
        print("=" * 80)
        print()
        
        for i, group in enumerate(groups, 1):
            print(f"\n{'=' * 80}")
            print(f"üìä –ì–†–£–ü–ü–ê {i}/{len(groups)}: {group.name} - –ó–ê–í–ï–†–®–ï–ù–ò–ï")
            print(f"{'=' * 80}\n")
            
            try:
                await self._run_single_group(group)
                print(f"\n‚úÖ –ì—Ä—É–ø–ø–∞ '{group.name}' –æ–±—Ä–∞–±–æ—Ç–∞–Ω–∞ —É—Å–ø–µ—à–Ω–æ")
                
            except Exception as e:
                print(f"\n‚ùå –û—à–∏–±–∫–∞ –æ–±—Ä–∞–±–æ—Ç–∫–∏ –≥—Ä—É–ø–ø—ã '{group.name}': {e}")
                continue
    
    def _print_summary(self):
        """–í—ã–≤–æ–¥ —Ñ–∏–Ω–∞–ª—å–Ω–æ–π —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∏"""
        print(f"\nüìä –§–∏–Ω–∞–ª—å–Ω–∞—è —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞:")
        print(f"  –í—Å–µ–≥–æ –≥—Ä—É–ø–ø: {len(self.group_manager.groups)}")
        
        for group in self.group_manager.groups:
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º –Ω–∞–ª–∏—á–∏–µ output –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏–∏ –≤–º–µ—Å—Ç–æ –ë–î (–ë–î —Ç–µ–ø–µ—Ä—å –æ–±—â–∞—è)
            status = "‚úÖ" if group.output_dir.exists() else "‚ùå"
            print(f"  {status} {group.name}: {group.output_dir}")

