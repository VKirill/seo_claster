"""–ê–Ω–∞–ª–∏–∑ –≥—Ä–∞—Ñ–∞ –∏ –≤—ã—á–∏—Å–ª–µ–Ω–∏–µ –º–µ—Ç—Ä–∏–∫"""

from typing import Dict, List, Tuple
from collections import defaultdict
import numpy as np
import pandas as pd
import networkx as nx


def calculate_pagerank(
    graph: nx.Graph,
    alpha: float = 0.85,
    max_iter: int = 100
) -> Dict[int, float]:
    """
    –í—ã—á–∏—Å–ª—è–µ—Ç PageRank –¥–ª—è —É–∑–ª–æ–≤
    
    Args:
        graph: –ì—Ä–∞—Ñ NetworkX
        alpha: Damping factor
        max_iter: –ú–∞–∫—Å–∏–º—É–º –∏—Ç–µ—Ä–∞—Ü–∏–π
        
    Returns:
        –°–ª–æ–≤–∞—Ä—å {node_id: pagerank_score}
    """
    print("üîÑ –í—ã—á–∏—Å–ª–µ–Ω–∏–µ PageRank...")
    
    pagerank_scores = nx.pagerank(
        graph,
        alpha=alpha,
        max_iter=max_iter,
        weight='weight'
    )
    
    print("‚úì PageRank –≤—ã—á–∏—Å–ª–µ–Ω")
    
    return pagerank_scores


def get_hub_nodes(
    pagerank_scores: Dict[int, float],
    top_n: int = 50
) -> List[Tuple[int, float]]:
    """
    –í–æ–∑–≤—Ä–∞—â–∞–µ—Ç —Ç–æ–ø —Ö–∞–±-—É–∑–ª–æ–≤ –ø–æ PageRank
    
    Args:
        pagerank_scores: –°–ª–æ–≤–∞—Ä—å PageRank —Å–∫–æ—Ä–æ–≤
        top_n: –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ —É–∑–ª–æ–≤
        
    Returns:
        –°–ø–∏—Å–æ–∫ (node_id, pagerank_score)
    """
    sorted_nodes = sorted(
        pagerank_scores.items(),
        key=lambda x: x[1],
        reverse=True
    )
    
    return sorted_nodes[:top_n]


def get_community_info(
    communities: Dict[int, int],
    queries: List[str],
    pagerank_scores: Dict[int, float] = None
) -> Dict[int, Dict]:
    """
    –í–æ–∑–≤—Ä–∞—â–∞–µ—Ç –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –æ —Å–æ–æ–±—â–µ—Å—Ç–≤–∞—Ö
    
    Args:
        communities: –°–ª–æ–≤–∞—Ä—å {node_id: community_id}
        queries: –°–ø–∏—Å–æ–∫ –∑–∞–ø—Ä–æ—Å–æ–≤
        pagerank_scores: –°–ª–æ–≤–∞—Ä—å PageRank —Å–∫–æ—Ä–æ–≤ (–æ–ø—Ü–∏–æ–Ω–∞–ª—å–Ω–æ)
        
    Returns:
        –°–ª–æ–≤–∞—Ä—å —Å –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–µ–π –æ —Å–æ–æ–±—â–µ—Å—Ç–≤–∞—Ö
    """
    community_info = {}
    
    # –ì—Ä—É–ø–ø–∏—Ä—É–µ–º —É–∑–ª—ã –ø–æ —Å–æ–æ–±—â–µ—Å—Ç–≤–∞–º
    comm_nodes = defaultdict(list)
    
    for node_id, comm_id in communities.items():
        comm_nodes[comm_id].append(node_id)
    
    # –°–æ–±–∏—Ä–∞–µ–º –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –æ –∫–∞–∂–¥–æ–º —Å–æ–æ–±—â–µ—Å—Ç–≤–µ
    for comm_id, nodes in comm_nodes.items():
        # –ó–∞–ø—Ä–æ—Å—ã –≤ —Å–æ–æ–±—â–µ—Å—Ç–≤–µ
        community_queries = [queries[node_id] for node_id in nodes]
        
        # –°—Ä–µ–¥–Ω–∏–π PageRank
        if pagerank_scores:
            avg_pagerank = np.mean([pagerank_scores.get(node_id, 0) for node_id in nodes])
        else:
            avg_pagerank = 0
        
        community_info[comm_id] = {
            'community_id': comm_id,
            'size': len(nodes),
            'queries': community_queries[:10],  # –ü–µ—Ä–≤—ã–µ 10
            'avg_pagerank': avg_pagerank,
            'node_ids': nodes,
        }
    
    return community_info


def add_graph_features_to_dataframe(
    df: pd.DataFrame,
    communities: Dict[int, int],
    pagerank_scores: Dict[int, float] = None,
    graph: nx.Graph = None
) -> pd.DataFrame:
    """
    –î–æ–±–∞–≤–ª—è–µ—Ç –≥—Ä–∞—Ñ–æ–≤—ã–µ —Ñ–∏—á–∏ –≤ DataFrame
    
    Args:
        df: DataFrame —Å –∑–∞–ø—Ä–æ—Å–∞–º–∏
        communities: –°–ª–æ–≤–∞—Ä—å —Å–æ–æ–±—â–µ—Å—Ç–≤
        pagerank_scores: –°–ª–æ–≤–∞—Ä—å PageRank —Å–∫–æ—Ä–æ–≤ (–æ–ø—Ü–∏–æ–Ω–∞–ª—å–Ω–æ)
        graph: –ì—Ä–∞—Ñ NetworkX (–æ–ø—Ü–∏–æ–Ω–∞–ª—å–Ω–æ)
        
    Returns:
        DataFrame —Å –¥–æ–±–∞–≤–ª–µ–Ω–Ω—ã–º–∏ –∫–æ–ª–æ–Ω–∫–∞–º–∏
    """
    print("üîÑ –î–æ–±–∞–≤–ª–µ–Ω–∏–µ –≥—Ä–∞—Ñ–æ–≤—ã—Ö —Ñ–∏—á–µ–π...")
    
    # –î–æ–±–∞–≤–ª—è–µ–º ID —Å–æ–æ–±—â–µ—Å—Ç–≤–∞
    df['graph_community_id'] = df.index.map(lambda x: communities.get(x, -1))
    
    # –î–æ–±–∞–≤–ª—è–µ–º PageRank
    if pagerank_scores:
        df['pagerank_score'] = df.index.map(lambda x: pagerank_scores.get(x, 0))
    
    # –î–æ–±–∞–≤–ª—è–µ–º —Å—Ç–µ–ø–µ–Ω—å —É–∑–ª–∞ (–∫–æ–ª–∏—á–µ—Å—Ç–≤–æ —Å–≤—è–∑–µ–π)
    if graph:
        degrees = dict(graph.degree())
        df['node_degree'] = df.index.map(lambda x: degrees.get(x, 0))
    
    print("‚úì –ì—Ä–∞—Ñ–æ–≤—ã–µ —Ñ–∏—á–∏ –¥–æ–±–∞–≤–ª–µ–Ω—ã")
    
    return df


def export_graph_data(
    graph: nx.Graph,
    communities: Dict[int, int] = None,
    pagerank_scores: Dict[int, float] = None
) -> Dict[str, any]:
    """
    –≠–∫—Å–ø–æ—Ä—Ç–∏—Ä—É–µ—Ç –¥–∞–Ω–Ω—ã–µ –≥—Ä–∞—Ñ–∞ –¥–ª—è –≤–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏–∏
    
    Args:
        graph: –ì—Ä–∞—Ñ NetworkX
        communities: –°–ª–æ–≤–∞—Ä—å —Å–æ–æ–±—â–µ—Å—Ç–≤ (–æ–ø—Ü–∏–æ–Ω–∞–ª—å–Ω–æ)
        pagerank_scores: –°–ª–æ–≤–∞—Ä—å PageRank —Å–∫–æ—Ä–æ–≤ (–æ–ø—Ü–∏–æ–Ω–∞–ª—å–Ω–æ)
        
    Returns:
        –°–ª–æ–≤–∞—Ä—å —Å –¥–∞–Ω–Ω—ã–º–∏ –≥—Ä–∞—Ñ–∞
    """
    nodes_data = []
    for node_id in graph.nodes():
        node_data = {
            'id': int(node_id),
            'query': graph.nodes[node_id].get('query', ''),
            'community': communities.get(node_id, -1) if communities else -1,
            'pagerank': pagerank_scores.get(node_id, 0) if pagerank_scores else 0,
            'degree': graph.degree(node_id),
        }
        nodes_data.append(node_data)
    
    edges_data = []
    for source, target, data in graph.edges(data=True):
        edge_data = {
            'source': int(source),
            'target': int(target),
            'weight': data.get('weight', 1.0),
        }
        edges_data.append(edge_data)
    
    return {
        'nodes': nodes_data,
        'edges': edges_data,
        'n_nodes': len(nodes_data),
        'n_edges': len(edges_data),
        'n_communities': len(set(communities.values())) if communities else 0,
    }


def get_graph_statistics(graph: nx.Graph, communities: Dict[int, int] = None) -> Dict[str, any]:
    """
    –í–æ–∑–≤—Ä–∞—â–∞–µ—Ç —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É –≥—Ä–∞—Ñ–∞
    
    Args:
        graph: –ì—Ä–∞—Ñ NetworkX
        communities: –°–ª–æ–≤–∞—Ä—å —Å–æ–æ–±—â–µ—Å—Ç–≤ (–æ–ø—Ü–∏–æ–Ω–∞–ª—å–Ω–æ)
        
    Returns:
        –°–ª–æ–≤–∞—Ä—å —Å–æ —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–æ–π
    """
    stats = {
        'n_nodes': graph.number_of_nodes(),
        'n_edges': graph.number_of_edges(),
        'density': nx.density(graph),
        'avg_degree': sum(dict(graph.degree()).values()) / graph.number_of_nodes(),
    }
    
    # –ö–æ–º–ø–æ–Ω–µ–Ω—Ç—ã —Å–≤—è–∑–Ω–æ—Å—Ç–∏
    if not nx.is_connected(graph):
        stats['n_connected_components'] = nx.number_connected_components(graph)
        stats['largest_component_size'] = len(max(nx.connected_components(graph), key=len))
    else:
        stats['n_connected_components'] = 1
        stats['largest_component_size'] = stats['n_nodes']
    
    # –°–æ–æ–±—â–µ—Å—Ç–≤–∞
    if communities:
        stats['n_communities'] = len(set(communities.values()))
    
    return stats

