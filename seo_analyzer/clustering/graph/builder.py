"""–ü–æ—Å—Ç—Ä–æ–µ–Ω–∏–µ –≥—Ä–∞—Ñ–∞ —Å–≤—è–∑–µ–π"""

from typing import Dict, List
import numpy as np
import networkx as nx
from sklearn.metrics.pairwise import cosine_similarity
from tqdm import tqdm


def build_graph_from_similarity(
    embeddings: np.ndarray,
    queries: List[str],
    similarity_threshold: float = 0.5,
    min_edge_weight: float = 0.3
) -> nx.Graph:
    """
    –°—Ç—Ä–æ–∏—Ç –≥—Ä–∞—Ñ –Ω–∞ –æ—Å–Ω–æ–≤–µ –º–∞—Ç—Ä–∏—Ü—ã —Å—Ö–æ–∂–µ—Å—Ç–∏
    
    Args:
        embeddings: –í–µ–∫—Ç–æ—Ä–Ω—ã–µ –ø—Ä–µ–¥—Å—Ç–∞–≤–ª–µ–Ω–∏—è –∑–∞–ø—Ä–æ—Å–æ–≤
        queries: –°–ø–∏—Å–æ–∫ –∑–∞–ø—Ä–æ—Å–æ–≤
        similarity_threshold: –ú–∏–Ω–∏–º–∞–ª—å–Ω–∞—è —Å—Ö–æ–∂–µ—Å—Ç—å –¥–ª—è —Ä–µ–±—Ä–∞
        min_edge_weight: –ú–∏–Ω–∏–º–∞–ª—å–Ω—ã–π –≤–µ—Å —Ä–µ–±—Ä–∞
        
    Returns:
        –ì—Ä–∞—Ñ NetworkX
    """
    print(f"üîÑ –ü–æ—Å—Ç—Ä–æ–µ–Ω–∏–µ –≥—Ä–∞—Ñ–∞ (–ø–æ—Ä–æ–≥ —Å—Ö–æ–∂–µ—Å—Ç–∏={similarity_threshold})...")
    
    # –°–æ–∑–¥–∞–µ–º –≥—Ä–∞—Ñ
    graph = nx.Graph()
    
    # –î–æ–±–∞–≤–ª—è–µ–º —É–∑–ª—ã
    for i, query in enumerate(queries):
        graph.add_node(i, query=query)
    
    # –í—ã—á–∏—Å–ª—è–µ–º –º–∞—Ç—Ä–∏—Ü—É —Å—Ö–æ–∂–µ—Å—Ç–∏
    print("  –í—ã—á–∏—Å–ª–µ–Ω–∏–µ –º–∞—Ç—Ä–∏—Ü—ã —Å—Ö–æ–∂–µ—Å—Ç–∏...")
    similarity_matrix = cosine_similarity(embeddings)
    
    # –î–æ–±–∞–≤–ª—è–µ–º —Ä–µ–±—Ä–∞
    print("  –î–æ–±–∞–≤–ª–µ–Ω–∏–µ —Ä–µ–±–µ—Ä...")
    edges_added = 0
    
    for i in tqdm(range(len(queries)), desc="–ü–æ—Å—Ç—Ä–æ–µ–Ω–∏–µ —Ä–µ–±–µ—Ä"):
        for j in range(i + 1, len(queries)):
            similarity = similarity_matrix[i, j]
            
            if similarity >= similarity_threshold and similarity >= min_edge_weight:
                graph.add_edge(i, j, weight=similarity)
                edges_added += 1
    
    print(f"‚úì –ì—Ä–∞—Ñ –ø–æ—Å—Ç—Ä–æ–µ–Ω: {len(graph.nodes)} —É–∑–ª–æ–≤, {edges_added} —Ä–µ–±–µ—Ä")
    
    return graph

