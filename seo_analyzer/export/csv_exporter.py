"""–≠–∫—Å–ø–æ—Ä—Ç —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ –≤ CSV"""

from pathlib import Path
from typing import Dict, Optional
import pandas as pd


class CSVExporter:
    """–≠–∫—Å–ø–æ—Ä—Ç–µ—Ä —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ –≤ CSV"""
    
    def __init__(self, encoding: str = 'utf-8-sig'):
        """
        –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è
        
        Args:
            encoding: –ö–æ–¥–∏—Ä–æ–≤–∫–∞ —Ñ–∞–π–ª–∞
        """
        self.encoding = encoding
    
    def export_full_results(
        self,
        df: pd.DataFrame,
        output_path: Path,
        include_forms: bool = True
    ) -> bool:
        """
        –≠–∫—Å–ø–æ—Ä—Ç–∏—Ä—É–µ—Ç –ø–æ–ª–Ω—ã–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã –∞–Ω–∞–ª–∏–∑–∞
        
        Args:
            df: DataFrame —Å —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞–º–∏
            output_path: –ü—É—Ç—å –¥–ª—è —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è
            include_forms: –í–∫–ª—é—á–∞—Ç—å –ª–∏ –ø–∞–¥–µ–∂–Ω—ã–µ —Ñ–æ—Ä–º—ã
            
        Returns:
            True –µ—Å–ª–∏ —É—Å–ø–µ—à–Ω–æ
        """
        try:
            print(f"üíæ –≠–∫—Å–ø–æ—Ä—Ç –≤ CSV: {output_path.name}...")
            
            # –û–ø—Ä–µ–¥–µ–ª—è–µ–º –∫–æ–ª–æ–Ω–∫–∏ –¥–ª—è —ç–∫—Å–ø–æ—Ä—Ç–∞
            columns_to_export = self._get_export_columns(df, include_forms)
            
            # –§–∏–ª—å—Ç—Ä—É–µ–º —Ç–æ–ª—å–∫–æ —Å—É—â–µ—Å—Ç–≤—É—é—â–∏–µ –∫–æ–ª–æ–Ω–∫–∏
            available_columns = [col for col in columns_to_export if col in df.columns]
            
            export_df = df[available_columns].copy()
            
            # –ö–æ–Ω–≤–µ—Ä—Ç–∏—Ä—É–µ–º —Å–ø–∏—Å–∫–∏ –≤ —Å—Ç—Ä–æ–∫–∏ –¥–ª—è CSV
            if 'serp_urls' in export_df.columns:
                export_df['serp_urls'] = export_df['serp_urls'].apply(
                    lambda x: ', '.join(x[:30]) if isinstance(x, list) and x else ''  # –í—Å–µ 30 URL
                )
            if 'lsi_phrases' in export_df.columns:
                export_df['lsi_phrases'] = export_df['lsi_phrases'].apply(
                    lambda x: ', '.join(x[:20]) if isinstance(x, list) and x else ''
                )
            
            # –°–æ—Ö—Ä–∞–Ω—è–µ–º —Å –∫–∞–≤—ã—á–∫–∞–º–∏ –¥–ª—è –≤—Å–µ—Ö –ø–æ–ª–µ–π
            export_df.to_csv(
                output_path, 
                index=False, 
                encoding=self.encoding,
                sep=';',  # –ò—Å–ø–æ–ª—å–∑—É–µ–º —Ç–æ—á–∫—É —Å –∑–∞–ø—è—Ç–æ–π –∫–∞–∫ —Ä–∞–∑–¥–µ–ª–∏—Ç–µ–ª—å
                quoting=1,  # QUOTE_ALL - –≤—Å–µ –ø–æ–ª—è –≤ –∫–∞–≤—ã—á–∫–∞—Ö
                quotechar='"'  # –î–≤–æ–π–Ω—ã–µ –∫–∞–≤—ã—á–∫–∏
            )
            
            print(f"‚úì –≠–∫—Å–ø–æ—Ä—Ç–∏—Ä–æ–≤–∞–Ω–æ {len(export_df)} –∑–∞–ø—Ä–æ—Å–æ–≤ –≤ {output_path}")
            return True
            
        except Exception as e:
            print(f"‚ö†Ô∏è –û—à–∏–±–∫–∞ —ç–∫—Å–ø–æ—Ä—Ç–∞ CSV: {e}")
            return False
    
    def _get_export_columns(self, df: pd.DataFrame, include_forms: bool = True) -> list:
        """
        –í–æ–∑–≤—Ä–∞—â–∞–µ—Ç —Å–ø–∏—Å–æ–∫ –∫–æ–ª–æ–Ω–æ–∫ –¥–ª—è —ç–∫—Å–ø–æ—Ä—Ç–∞
        
        Args:
            df: DataFrame
            include_forms: –í–∫–ª—é—á–∞—Ç—å –ª–∏ –ø–∞–¥–µ–∂–Ω—ã–µ —Ñ–æ—Ä–º—ã
            
        Returns:
            –°–ø–∏—Å–æ–∫ –Ω–∞–∑–≤–∞–Ω–∏–π –∫–æ–ª–æ–Ω–æ–∫
        """
        base_columns = [
            # === –°–ê–ú–û–ï –í–ê–ñ–ù–û–ï –¥–ª—è —Ä–∞–±–æ—Ç—ã ===
            'keyword',                      # –ò—Å—Ö–æ–¥–Ω—ã–π –∑–∞–ø—Ä–æ—Å
            'frequency_world',              # –ß–∞—Å—Ç–æ—Ç–Ω–æ—Å—Ç—å
            'frequency_exact',              # –¢–æ—á–Ω–∞—è —á–∞—Å—Ç–æ—Ç–Ω–æ—Å—Ç—å
            
            # === –ö–õ–ê–°–¢–ï–†–ò–ó–ê–¶–ò–Ø ===
            'semantic_cluster_id',          # –ì—Ä—É–ø–ø–∞/–∫–ª–∞—Å—Ç–µ—Ä (—Å–µ–º–∞–Ω—Ç–∏—á–µ—Å–∫–∏–π)
            'cluster_name',                 # –ù–∞–∑–≤–∞–Ω–∏–µ –≥—Ä—É–ø–ø—ã
            'related_clusters',             # –°–≤—è–∑–∞–Ω–Ω—ã–µ –∫–ª–∞—Å—Ç–µ—Ä—ã (–¥–ª—è –ø–µ—Ä–µ–ª–∏–Ω–∫–æ–≤–∫–∏)
            'word_match_cluster_id',        # –ì—Ä—É–ø–ø–∞ –ø–æ —Å–æ–≤–ø–∞–¥–µ–Ω–∏—è–º —Å–ª–æ–≤
            'word_match_cluster_name',      # –ù–∞–∑–≤–∞–Ω–∏–µ –≥—Ä—É–ø–ø—ã (KeyCollector)
            'topic_id',                     # –¢–µ–º–∞
            'topic_name',                   # –ù–∞–∑–≤–∞–Ω–∏–µ —Ç–µ–º—ã
            
            # === –ò–ù–¢–ï–ù–¢ –ò –¢–ò–ü ===
            'main_intent',                  # –ò–Ω—Ç–µ–Ω—Ç (commercial/info/...)
            'funnel_stage',                 # –≠—Ç–∞–ø –≤–æ—Ä–æ–Ω–∫–∏
            'target_page_type',             # –¢–∏–ø —Å—Ç—Ä–∞–Ω–∏—Ü—ã
            
            # === –ë–†–ï–ù–î–´ ===
            'detected_brand',               # –ù–∞–π–¥–µ–Ω–Ω—ã–π –±—Ä–µ–Ω–¥
            'is_brand_query',               # –ë—Ä–µ–Ω–¥–æ–≤—ã–π?
            
            # === –ì–ï–û ===
            'has_geo',                      # –ï—Å—Ç—å –≥–µ–æ?
            'geo_type',                     # –¢–∏–ø (city/address/region)
            'geo_city',                     # –ì–æ—Ä–æ–¥
            'geo_country',                  # –°—Ç—Ä–∞–Ω–∞
            'geo_street',                   # –£–ª–∏—Ü–∞ (–¥–ª—è –∞–¥—Ä–µ—Å–æ–≤)
            'geo_house',                    # –î–æ–º (–¥–ª—è –∞–¥—Ä–µ—Å–æ–≤)
            'geo_full_address',             # –ü–æ–ª–Ω—ã–π –∞–¥—Ä–µ—Å
            
            # === –î–û–ü–û–õ–ù–ò–¢–ï–õ–¨–ù–û ===
            'lemmatized',                   # –õ–µ–º–º–∞—Ç–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω—ã–π
            'words_count',                  # –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ —Å–ª–æ–≤
            'difficulty_score',             # –°–ª–æ–∂–Ω–æ—Å—Ç—å –ø—Ä–æ–¥–≤–∏–∂–µ–Ω–∏—è
            'suggested_url',                # –ü—Ä–µ–¥–ª–∞–≥–∞–µ–º—ã–π URL
            
            # === KEI –ú–ï–¢–†–ò–ö–ò ===
            'priority_score',               # –ü—Ä–∏–æ—Ä–∏—Ç–µ—Ç–Ω—ã–π —Å–∫–æ—Ä
            'kei_effectiveness',            # KEI —ç—Ñ—Ñ–µ–∫—Ç–∏–≤–Ω–æ—Å—Ç—å
            'kei_standard',                 # –°—Ç–∞–Ω–¥–∞—Ä—Ç–Ω—ã–π KEI
            'kei_competition',              # KEI –∫–æ–Ω–∫—É—Ä–µ–Ω—Ü–∏—è
            'kei_coefficient',              # KEI –∫–æ—ç—Ñ—Ñ–∏—Ü–∏–µ–Ω—Ç
            'kei_popularity',               # KEI –ø–æ–ø—É–ª—è—Ä–Ω–æ—Å—Ç—å
            'kei_potential_traffic',        # KEI –ø–æ—Ç–µ–Ω—Ü–∏–∞–ª —Ç—Ä–∞—Ñ–∏–∫–∞
            # kei_cost_per_visit - –ù–ï –¥–æ–±–∞–≤–ª—è–µ–º (–Ω–µ—Ç —Ç–æ—á–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö –±–µ–∑ Direct)
            'kei_synergy',                  # –°–∏–Ω–µ—Ä–≥–∏—è
            'kei_yandex_relevance',         # Yandex —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω–æ—Å—Ç—å
            'kei_effectiveness_coefficient', # KEI –ö–æ—ç—Ñ—Ñ–∏—Ü–∏–µ–Ω—Ç —ç—Ñ—Ñ–µ–∫—Ç–∏–≤–Ω–æ—Å—Ç–∏
            'kei_standard_normalized',      # KEI Standard –Ω–æ—Ä–º–∞–ª–∏–∑–æ–≤–∞–Ω–Ω—ã–π
            'ctr_potential',                # CTR –ø–æ—Ç–µ–Ω—Ü–∏–∞–ª
            'commercial_value',             # –ö–æ–º–º–µ—Ä—á–µ—Å–∫–∞—è —Ü–µ–Ω–Ω–æ—Å—Ç—å
            'traffic_potential',            # –ü–æ—Ç–µ–Ω—Ü–∏–∞–ª —Ç—Ä–∞—Ñ–∏–∫–∞
            
            # === SERP –ú–ï–¢–†–ò–ö–ò ===
            'serp_docs_count',              # –ù–∞–π–¥–µ–Ω–æ –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤
            'serp_main_pages',              # –ì–ª–∞–≤–Ω—ã—Ö —Å—Ç—Ä–∞–Ω–∏—Ü
            'serp_titles_count',            # Title —Å –ö–°
            'serp_commercial_domains',      # –ö–æ–º–º–µ—Ä—á–µ—Å–∫–∏—Ö –¥–æ–º–µ–Ω–æ–≤
            'serp_info_domains',            # –ò–Ω—Ñ–æ—Ä–º–∞—Ü–∏–æ–Ω–Ω—ã—Ö –¥–æ–º–µ–Ω–æ–≤
            
            # === LSI –§–†–ê–ó–´ –ò SERP URL ===
            'cluster_lsi_phrases_str',      # LSI —Ñ—Ä–∞–∑—ã –∫–ª–∞—Å—Ç–µ—Ä–∞ (—Ç–æ–ø-30, —Å—Ç—Ä–æ–∫–∞)
            'serp_urls',                    # SERP URL –∫–æ–Ω–∫—Ä–µ—Ç–Ω–æ–≥–æ –∑–∞–ø—Ä–æ—Å–∞ (–∏–Ω–¥–∏–≤–∏–¥—É–∞–ª—å–Ω—ã–µ)
            'cluster_common_urls',          # –û–±—â–∏–µ SERP URL –∫–ª–∞—Å—Ç–µ—Ä–∞ (—Ç–æ–ø-10)
            'all_topics_str',               # –í—Å–µ —Ç–µ–º—ã (soft clustering)
            
            # === –î–ï–¢–ê–õ–¨–ù–´–ï –§–õ–ê–ì–ò (–æ–ø—Ü–∏–æ–Ω–∞–ª—å–Ω–æ) ===
            'commercial_score',
            'is_commercial',
            'is_wholesale',
            'is_urgent',
            'query_pattern',
            
            # === –ò–ï–†–ê–†–•–ò–Ø (–µ—Å–ª–∏ –µ—Å—Ç—å) ===
            'hierarchical_level1',
            'hierarchical_level2',
            'hierarchical_level3',
            'difficulty_level',
            'difficulty_cluster',
            
            # –ì—Ä–∞—Ñ
            'pagerank_score',
            'node_degree',
        ]
        
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º –Ω–∞–ª–∏—á–∏–µ –¥–∞–Ω–Ω—ã—Ö Direct
        has_direct_data = 'direct_shows' in df.columns and (df['direct_shows'] > 0).any()
        
        # Yandex Direct –∫–æ–ª–æ–Ω–∫–∏ - —Ç–æ–ª—å–∫–æ –µ—Å–ª–∏ –µ—Å—Ç—å –¥–∞–Ω–Ω—ã–µ
        if has_direct_data:
            base_columns.extend([
                # –î–∞–Ω–Ω—ã–µ Direct
                'direct_shows',
                'direct_clicks',
                'direct_ctr',
                'premium_ctr',
                'direct_avg_cpc',
                'direct_min_cpc',
                'direct_max_cpc',
                'direct_recommended_cpc',
                'direct_competition',
                'direct_first_place_bid',
                
                # KEI –º–µ—Ç—Ä–∏–∫–∏ —Å Direct
                'kei_direct_traffic_potential',
                'kei_direct_budget_required',
                
                # –ë—é–¥–∂–µ—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ Direct
                'direct_monthly_budget',
            ])
        
        if include_forms:
            form_columns = [
                'form_nominative',
                'form_genitive',
                'form_dative',
                'form_accusative',
                'form_instrumental',
                'form_prepositional',
            ]
            base_columns.extend(form_columns)
        
        return base_columns
    
    def export_clusters_summary(
        self,
        df: pd.DataFrame,
        output_path: Path,
        cluster_column: str = 'semantic_cluster_id'
    ) -> bool:
        """
        –≠–∫—Å–ø–æ—Ä—Ç–∏—Ä—É–µ—Ç —Å–≤–æ–¥–∫—É –ø–æ –∫–ª–∞—Å—Ç–µ—Ä–∞–º
        
        Args:
            df: DataFrame —Å —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞–º–∏
            output_path: –ü—É—Ç—å –¥–ª—è —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è
            cluster_column: –ö–æ–ª–æ–Ω–∫–∞ —Å ID –∫–ª–∞—Å—Ç–µ—Ä–∞
            
        Returns:
            True –µ—Å–ª–∏ —É—Å–ø–µ—à–Ω–æ
        """
        try:
            print(f"üíæ –≠–∫—Å–ø–æ—Ä—Ç —Å–≤–æ–¥–∫–∏ –∫–ª–∞—Å—Ç–µ—Ä–æ–≤: {output_path.name}...")
            
            # –ì—Ä—É–ø–ø–∏—Ä—É–µ–º –ø–æ –∫–ª–∞—Å—Ç–µ—Ä–∞–º
            agg_dict = {
                'keyword': ['count', lambda x: x.iloc[0]],  # –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –∏ –ø—Ä–∏–º–µ—Ä
                'frequency_world': 'sum',
            }
            
            # –î–æ–±–∞–≤–ª—è–µ–º difficulty_score —Ç–æ–ª—å–∫–æ –µ—Å–ª–∏ –µ—Å—Ç—å
            if 'difficulty_score' in df.columns:
                agg_dict['difficulty_score'] = 'mean'
            
            cluster_summary = df.groupby(cluster_column).agg(agg_dict).reset_index()
            
            # –ù–∞–∑–≤–∞–Ω–∏—è –∫–æ–ª–æ–Ω–æ–∫
            columns = ['cluster_id', 'queries_count', 'example_query', 'total_frequency']
            if 'difficulty_score' in df.columns:
                columns.append('avg_difficulty')
            
            cluster_summary.columns = columns
            
            # –°–æ—Ö—Ä–∞–Ω—è–µ–º
            cluster_summary.to_csv(output_path, index=False, encoding=self.encoding)
            
            print(f"‚úì –≠–∫—Å–ø–æ—Ä—Ç–∏—Ä–æ–≤–∞–Ω–æ {len(cluster_summary)} –∫–ª–∞—Å—Ç–µ—Ä–æ–≤")
            return True
            
        except Exception as e:
            print(f"‚ö†Ô∏è –û—à–∏–±–∫–∞ —ç–∫—Å–ø–æ—Ä—Ç–∞ —Å–≤–æ–¥–∫–∏: {e}")
            return False
    
    def export_top_queries(
        self,
        df: pd.DataFrame,
        output_path: Path,
        top_n: int = 1000,
        sort_by: str = 'frequency_world'
    ) -> bool:
        """
        –≠–∫—Å–ø–æ—Ä—Ç–∏—Ä—É–µ—Ç —Ç–æ–ø –∑–∞–ø—Ä–æ—Å–æ–≤
        
        Args:
            df: DataFrame —Å —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞–º–∏
            output_path: –ü—É—Ç—å –¥–ª—è —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è
            top_n: –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –∑–∞–ø—Ä–æ—Å–æ–≤
            sort_by: –ö–æ–ª–æ–Ω–∫–∞ –¥–ª—è —Å–æ—Ä—Ç–∏—Ä–æ–≤–∫–∏
            
        Returns:
            True –µ—Å–ª–∏ —É—Å–ø–µ—à–Ω–æ
        """
        try:
            print(f"üíæ –≠–∫—Å–ø–æ—Ä—Ç —Ç–æ–ø-{top_n} –∑–∞–ø—Ä–æ—Å–æ–≤: {output_path.name}...")
            
            if sort_by in df.columns:
                top_df = df.nlargest(top_n, sort_by)
            else:
                top_df = df.head(top_n)
            
            top_df.to_csv(output_path, index=False, encoding=self.encoding)
            
            print(f"‚úì –≠–∫—Å–ø–æ—Ä—Ç–∏—Ä–æ–≤–∞–Ω–æ {len(top_df)} –∑–∞–ø—Ä–æ—Å–æ–≤")
            return True
            
        except Exception as e:
            print(f"‚ö†Ô∏è –û—à–∏–±–∫–∞ —ç–∫—Å–ø–æ—Ä—Ç–∞ —Ç–æ–ø–∞: {e}")
            return False

