"""
–ó–∞–≥—Ä—É–∑–∫–∞ –∑–∞–ø—Ä–æ—Å–æ–≤ –∏–∑ Master DB
"""

import sqlite3
import json
import pandas as pd
from pathlib import Path
from typing import Optional

from seo_analyzer.core.serp.serp_data_normalizer import SERPDataNormalizer


class QueryLoader:
    """–ó–∞–≥—Ä—É–∑—á–∏–∫ –∑–∞–ø—Ä–æ—Å–æ–≤ –∏–∑ Master DB"""
    
    def __init__(self, db_path: Path):
        """
        Args:
            db_path: –ü—É—Ç—å –∫ –±–∞–∑–µ –¥–∞–Ω–Ω—ã—Ö
        """
        self.db_path = db_path
    
    def load_queries(
        self,
        group_name: str,
        include_serp_urls: bool = True
    ) -> Optional[pd.DataFrame]:
        """
        –ó–∞–≥—Ä—É–∂–∞–µ—Ç –í–°–ï –¥–∞–Ω–Ω—ã–µ –ø–æ –∑–∞–ø—Ä–æ—Å–∞–º –∏–∑ –º–∞—Å—Ç–µ—Ä-—Ç–∞–±–ª–∏—Ü—ã
        
        Args:
            group_name: –ù–∞–∑–≤–∞–Ω–∏–µ –≥—Ä—É–ø–ø—ã
            include_serp_urls: –í–∫–ª—é—á–∞—Ç—å –ª–∏ serp_top_urls (–±–æ–ª—å—à–∏–µ –¥–∞–Ω–Ω—ã–µ)
            
        Returns:
            DataFrame —Å–æ –≤—Å–µ–º–∏ –ø–æ–ª—è–º–∏ –∏–ª–∏ None
        """
        conn = sqlite3.connect(self.db_path)
        
        # –í—ã–±–∏—Ä–∞–µ–º –≤—Å–µ –∫–æ–ª–æ–Ω–∫–∏ –∫—Ä–æ–º–µ id –∏ timestamps
        columns = """
            keyword, frequency_world, frequency_exact,
            normalized, lemmatized, words_count, main_words, key_phrase,
            ner_entities, ner_locations,
            has_geo, geo_type, geo_country, geo_city,
            main_intent, commercial_score, informational_score, navigational_score,
            is_commercial, is_wholesale, is_urgent, is_diy, is_review, is_brand_query,
            serp_query_hash, serp_found_docs, serp_main_pages_count, serp_titles_with_keyword,
            serp_commercial_domains, serp_info_domains, serp_created_at,
            serp_intent, serp_confidence, serp_docs_with_offers, serp_total_docs, serp_offer_ratio,
            serp_avg_price, serp_min_price, serp_max_price, serp_median_price, serp_currency,
            serp_offers_count, serp_offers_with_discount, serp_avg_discount_percent,
            {serp_urls}
            serp_lsi_phrases,
            direct_shows, direct_clicks, direct_ctr, direct_min_cpc, direct_avg_cpc,
            direct_max_cpc, direct_recommended_cpc, direct_competition_level,
            direct_first_place_bid, direct_first_place_price,
            kei, difficulty, competition_score, potential_traffic, expected_ctr,
            detected_brand, brand_confidence,
            funnel_stage, funnel_priority
        """.format(serp_urls='serp_top_urls,' if include_serp_urls else '')
        
        query = f'''
            SELECT {columns}
            FROM master_queries
            WHERE group_name = ?
            ORDER BY frequency_world DESC
        '''
        
        df = pd.read_sql_query(query, conn, params=(group_name,))
        conn.close()
        
        if df.empty:
            return None
        
        # –î–æ–±–∞–≤–ª—è–µ–º –∞–ª–∏–∞—Å—ã –¥–ª—è —Å–æ–≤–º–µ—Å—Ç–∏–º–æ—Å—Ç–∏ —Å –∫–æ–¥–æ–º
        if 'serp_found_docs' in df.columns:
            df['serp_docs_count'] = df['serp_found_docs']
        if 'serp_main_pages_count' in df.columns:
            df['serp_main_pages'] = df['serp_main_pages_count']
            df['serp_internal_pages_count'] = (
                df['serp_docs_count'] - df['serp_main_pages_count']
            ).fillna(0).clip(lower=0).astype(int)
        if 'serp_titles_with_keyword' in df.columns:
            df['serp_titles_count'] = df['serp_titles_with_keyword']
        
        # –ù–æ—Ä–º–∞–ª–∏–∑—É–µ–º serp_top_urls –≤ –µ–¥–∏–Ω—ã–π —Ñ–æ—Ä–º–∞—Ç
        if 'serp_top_urls' in df.columns:
            def normalize_serp_urls(val):
                """–ù–æ—Ä–º–∞–ª–∏–∑—É–µ—Ç SERP URLs –≤ –µ–¥–∏–Ω—ã–π —Ñ–æ—Ä–º–∞—Ç"""
                # –û–±—Ä–∞–±–æ—Ç–∫–∞ NULL/NaN –∑–Ω–∞—á–µ–Ω–∏–π
                if pd.isna(val) or val is None:
                    return []
                if isinstance(val, str) and (val.strip() == '' or val.strip().lower() == 'null'):
                    return []
                normalized = SERPDataNormalizer.normalize_serp_urls(val)
                return normalized
            
            df['serp_top_urls'] = df['serp_top_urls'].apply(normalize_serp_urls)
            
            # –î–∏–∞–≥–Ω–æ—Å—Ç–∏–∫–∞ –Ω–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏–∏
            serp_with_urls = df['serp_top_urls'].apply(lambda x: isinstance(x, list) and len(x) > 0).sum()
            serp_empty = len(df) - serp_with_urls
            serp_null_count = df['serp_top_urls'].isna().sum() if 'serp_top_urls' in df.columns else 0
            print(f"   ‚úì SERP URLs: {serp_with_urls} –∑–∞–ø—Ä–æ—Å–æ–≤ —Å URL, {serp_empty} –±–µ–∑ URL")
            if serp_null_count > 0:
                print(f"   ‚ö†Ô∏è  NULL –∑–Ω–∞—á–µ–Ω–∏–π: {serp_null_count}")
        
        # –ü—Ä–µ–æ–±—Ä–∞–∑—É–µ–º serp_lsi_phrases –≤ lsi_phrases –µ—Å–ª–∏ –Ω—É–∂–Ω–æ
        if 'serp_lsi_phrases' in df.columns and 'lsi_phrases' not in df.columns:
            def parse_lsi_phrases(val):
                if pd.isna(val) or val is None or val == '':
                    return []
                if isinstance(val, str):
                    try:
                        parsed = json.loads(val)
                        if isinstance(parsed, list):
                            result = []
                            for item in parsed:
                                if isinstance(item, str):
                                    result.append({'phrase': item, 'frequency': 1, 'source': 'unknown'})
                                elif isinstance(item, dict):
                                    result.append(item)
                            return result
                        return parsed if isinstance(parsed, list) else []
                    except (json.JSONDecodeError, TypeError):
                        return []
                elif isinstance(val, list):
                    return val
                return []
            
            df['lsi_phrases'] = df['serp_lsi_phrases'].apply(parse_lsi_phrases)
            
            # –î–∏–∞–≥–Ω–æ—Å—Ç–∏–∫–∞ LSI —Ñ—Ä–∞–∑
            lsi_non_empty = df['lsi_phrases'].apply(lambda x: isinstance(x, list) and len(x) > 0).sum()
            lsi_empty = len(df) - lsi_non_empty
            print(f"   ‚úì LSI —Ñ—Ä–∞–∑—ã: {lsi_non_empty} –∑–∞–ø—Ä–æ—Å–æ–≤ —Å LSI, {lsi_empty} –±–µ–∑ LSI")
        
        print(f"üì¶ Master DB: –∑–∞–≥—Ä—É–∂–µ–Ω–æ {len(df)} –∑–∞–ø—Ä–æ—Å–æ–≤ –¥–ª—è –≥—Ä—É–ø–ø—ã '{group_name}'")
        print(f"   ‚úì –ò–Ω—Ç–µ–Ω—Ç: {df['main_intent'].notna().sum()} –∑–∞–ø–∏—Å–µ–π")
        print(f"   ‚úì SERP: {df['serp_found_docs'].notna().sum()} –∑–∞–ø–∏—Å–µ–π")
        print(f"   ‚úì Direct: {df['direct_shows'].notna().sum()} –∑–∞–ø–∏—Å–µ–π")
        
        # –î–∏–∞–≥–Ω–æ—Å—Ç–∏–∫–∞ —á–∞—Å—Ç–æ—Ç –ø—Ä–∏ –∑–∞–≥—Ä—É–∑–∫–µ –∏–∑ –ë–î
        if 'frequency_world' in df.columns:
            non_zero_freq_world = (df['frequency_world'] > 0).sum()
            total_rows = len(df)
            print(f"   ‚úì –ß–∞—Å—Ç–æ—Ç–∞ (–º–∏—Ä): {non_zero_freq_world} –∏–∑ {total_rows} –∑–∞–ø—Ä–æ—Å–æ–≤ —Å –Ω–µ–Ω—É–ª–µ–≤–æ–π —á–∞—Å—Ç–æ—Ç–æ–π")
            if non_zero_freq_world == 0 and total_rows > 0:
                print(f"   ‚ö†Ô∏è  –í–ù–ò–ú–ê–ù–ò–ï: –í—Å–µ —á–∞—Å—Ç–æ—Ç—ã (–º–∏—Ä) —Ä–∞–≤–Ω—ã –Ω—É–ª—é –≤ –ë–î!")
                # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Ç–∏–ø—ã –¥–∞–Ω–Ω—ã—Ö
                print(f"   ‚ÑπÔ∏è  –¢–∏–ø –¥–∞–Ω–Ω—ã—Ö frequency_world: {df['frequency_world'].dtype}")
                print(f"   ‚ÑπÔ∏è  –ü—Ä–∏–º–µ—Ä—ã –∑–Ω–∞—á–µ–Ω–∏–π: {df['frequency_world'].head(10).tolist()}")
        
        if 'frequency_exact' in df.columns:
            non_zero_freq_exact = (df['frequency_exact'] > 0).sum()
            total_rows = len(df)
            print(f"   ‚úì –ß–∞—Å—Ç–æ—Ç–∞ (—Ç–æ—á–Ω–∞—è): {non_zero_freq_exact} –∏–∑ {total_rows} –∑–∞–ø—Ä–æ—Å–æ–≤ —Å –Ω–µ–Ω—É–ª–µ–≤–æ–π —á–∞—Å—Ç–æ—Ç–æ–π")
            if non_zero_freq_exact == 0 and total_rows > 0:
                print(f"   ‚ö†Ô∏è  –í–ù–ò–ú–ê–ù–ò–ï: –í—Å–µ —á–∞—Å—Ç–æ—Ç—ã (—Ç–æ—á–Ω–∞—è) —Ä–∞–≤–Ω—ã –Ω—É–ª—é –≤ –ë–î!")
                # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Ç–∏–ø—ã –¥–∞–Ω–Ω—ã—Ö
                print(f"   ‚ÑπÔ∏è  –¢–∏–ø –¥–∞–Ω–Ω—ã—Ö frequency_exact: {df['frequency_exact'].dtype}")
                print(f"   ‚ÑπÔ∏è  –ü—Ä–∏–º–µ—Ä—ã –∑–Ω–∞—á–µ–Ω–∏–π: {df['frequency_exact'].head(10).tolist()}")
        
        return df

