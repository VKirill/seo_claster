"""
Cluster LSI Aggregator Module
–ê–≥—Ä–µ–≥–∞—Ü–∏—è LSI —Ñ—Ä–∞–∑ –Ω–∞ —É—Ä–æ–≤–Ω–µ –∫–ª–∞—Å—Ç–µ—Ä–æ–≤
–§–∞—Å–∞–¥ –¥–ª—è –º–æ–¥—É–ª–µ–π –∞–≥—Ä–µ–≥–∞—Ü–∏–∏
"""

import pandas as pd
from typing import Dict, List, Any

from .lsi_aggregation.cluster_aggregator import ClusterAggregator
from .lsi_aggregation.phrase_extractor import PhraseExtractor
from .lsi_aggregation.frequency_calculator import FrequencyCalculator


class ClusterLSIAggregator:
    """–ê–≥—Ä–µ–≥–∞—Ç–æ—Ä LSI —Ñ—Ä–∞–∑ –¥–ª—è –∫–ª–∞—Å—Ç–µ—Ä–æ–≤"""
    
    def __init__(self, top_n_per_cluster: int = 10):
        """
        Args:
            top_n_per_cluster: –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ —Ç–æ–ø LSI —Ñ—Ä–∞–∑ –Ω–∞ –∫–ª–∞—Å—Ç–µ—Ä
        """
        self.top_n_per_cluster = top_n_per_cluster
    
    def aggregate_cluster_lsi(
        self,
        df: pd.DataFrame,
        cluster_column: str = 'semantic_cluster_id'
    ) -> Dict[int, List[Dict[str, Any]]]:
        """
        –ê–≥—Ä–µ–≥–∏—Ä–æ–≤–∞—Ç—å LSI —Ñ—Ä–∞–∑—ã –¥–ª—è –∫–∞–∂–¥–æ–≥–æ –∫–ª–∞—Å—Ç–µ—Ä–∞
        
        Args:
            df: DataFrame —Å –∫–æ–ª–æ–Ω–∫–∞–º–∏ [cluster_column, 'lsi_phrases']
            cluster_column: –ù–∞–∑–≤–∞–Ω–∏–µ –∫–æ–ª–æ–Ω–∫–∏ —Å ID –∫–ª–∞—Å—Ç–µ—Ä–∞
            
        Returns:
            Dict {cluster_id: [top_lsi_phrases]}
        """
        return ClusterAggregator.aggregate_cluster_lsi(
            df, cluster_column, self.top_n_per_cluster
        )
    
    def add_cluster_lsi_to_dataframe(
        self,
        df: pd.DataFrame,
        cluster_lsi: Dict[int, List[Dict[str, Any]]],
        cluster_column: str = 'semantic_cluster_id'
    ) -> pd.DataFrame:
        """
        –î–æ–±–∞–≤–∏—Ç—å –∞–≥—Ä–µ–≥–∏—Ä–æ–≤–∞–Ω–Ω—ã–µ LSI —Ñ—Ä–∞–∑—ã –≤ DataFrame
        
        Args:
            df: DataFrame
            cluster_lsi: –ê–≥—Ä–µ–≥–∏—Ä–æ–≤–∞–Ω–Ω—ã–µ LSI –ø–æ –∫–ª–∞—Å—Ç–µ—Ä–∞–º
            cluster_column: –ö–æ–ª–æ–Ω–∫–∞ —Å ID –∫–ª–∞—Å—Ç–µ—Ä–∞
            
        Returns:
            DataFrame —Å –Ω–æ–≤–æ–π –∫–æ–ª–æ–Ω–∫–æ–π 'cluster_lsi_phrases'
        """
        # –°–æ–∑–¥–∞–µ–º –º–∞–ø–ø–∏–Ω–≥ cluster_id -> LSI phrases
        cluster_to_lsi = {}
        cluster_to_lsi_str = {}
        
        for cluster_id, lsi_list in cluster_lsi.items():
            # –°–æ—Ö—Ä–∞–Ω—è–µ–º —Ç–æ–ø-30 –∫–∞–∫ —Å–ø–∏—Å–æ–∫ —Å–ª–æ–≤–∞—Ä–µ–π (–¥–ª—è JSON/Excel)
            cluster_to_lsi[cluster_id] = lsi_list[:30] if lsi_list else []
            
            # –¢–∞–∫–∂–µ —Å–æ–∑–¥–∞–µ–º —Å—Ç—Ä–æ–∫–æ–≤–æ–µ –ø—Ä–µ–¥—Å—Ç–∞–≤–ª–µ–Ω–∏–µ (–¥–ª—è CSV)
            top_phrases = []
            for item in lsi_list[:30]:
                if isinstance(item, dict):
                    phrase = item.get('phrase', '')
                    if phrase:
                        top_phrases.append(phrase)
                elif isinstance(item, str):
                    if item:
                        top_phrases.append(item)
            cluster_to_lsi_str[cluster_id] = ', '.join(top_phrases) if top_phrases else ''
        
        # –î–æ–±–∞–≤–ª—è–µ–º –∫–æ–ª–æ–Ω–∫—É —Å –ø–æ–ª–Ω—ã–º–∏ –¥–∞–Ω–Ω—ã–º–∏ (—Å–ø–∏—Å–æ–∫ —Å–ª–æ–≤–∞—Ä–µ–π)
        df['cluster_lsi_phrases'] = df[cluster_column].map(cluster_to_lsi)
        
        # –î–∏–∞–≥–Ω–æ—Å—Ç–∏–∫–∞: –ø—Ä–æ–≤–µ—Ä—è–µ–º —Å–∫–æ–ª—å–∫–æ –∑–∞–ø–∏—Å–µ–π –ø–æ–ª—É—á–∏–ª–∏ LSI —Ñ—Ä–∞–∑—ã
        mapped_count = df['cluster_lsi_phrases'].notna().sum()
        empty_count = (df['cluster_lsi_phrases'].isna() | (df['cluster_lsi_phrases'] == '')).sum()
        
        # –ó–∞–ø–æ–ª–Ω—è–µ–º –ø—É—Å—Ç—ã–µ –∑–Ω–∞—á–µ–Ω–∏—è –ø—É—Å—Ç—ã–º–∏ —Å–ø–∏—Å–∫–∞–º–∏
        df['cluster_lsi_phrases'] = df['cluster_lsi_phrases'].fillna('').apply(
            lambda x: x if isinstance(x, list) else []
        )
        
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Å–∫–æ–ª—å–∫–æ –∑–∞–ø–∏—Å–µ–π –∏–º–µ—é—Ç –Ω–µ–ø—É—Å—Ç—ã–µ LSI —Ñ—Ä–∞–∑—ã –ø–æ—Å–ª–µ –∑–∞–ø–æ–ª–Ω–µ–Ω–∏—è
        non_empty_count = df['cluster_lsi_phrases'].apply(lambda x: isinstance(x, list) and len(x) > 0).sum()
        
        # –î–∏–∞–≥–Ω–æ—Å—Ç–∏–∫–∞ –¥–ª—è –∫–ª–∞—Å—Ç–µ—Ä–æ–≤ –±–µ–∑ LSI
        clusters_without_lsi = []
        queries_without_cluster = 0
        queries_with_cluster_but_no_lsi = 0
        
        for cluster_id in df[cluster_column].unique():
            cluster_df = df[df[cluster_column] == cluster_id]
            cluster_lsi_data = cluster_df['cluster_lsi_phrases'].iloc[0] if len(cluster_df) > 0 else []
            
            if cluster_id == -1:
                # –ó–∞–ø—Ä–æ—Å—ã –±–µ–∑ –∫–ª–∞—Å—Ç–µ—Ä–∞
                queries_without_cluster += len(cluster_df)
            elif not isinstance(cluster_lsi_data, list) or len(cluster_lsi_data) == 0:
                clusters_without_lsi.append(cluster_id)
                queries_with_cluster_but_no_lsi += len(cluster_df)
        
        if queries_without_cluster > 0:
            print(f"‚ÑπÔ∏è  –ó–∞–ø—Ä–æ—Å–æ–≤ –±–µ–∑ –∫–ª–∞—Å—Ç–µ—Ä–∞ (semantic_cluster_id = -1): {queries_without_cluster}")
        
        if clusters_without_lsi:
            print(f"‚ö†Ô∏è  –ù–∞–π–¥–µ–Ω–æ {len(clusters_without_lsi)} –∫–ª–∞—Å—Ç–µ—Ä–æ–≤ –±–µ–∑ LSI —Ñ—Ä–∞–∑ –ø–æ—Å–ª–µ –∞–≥—Ä–µ–≥–∞—Ü–∏–∏")
            print(f"   –ó–∞–ø—Ä–æ—Å–æ–≤ –≤ —Ç–∞–∫–∏—Ö –∫–ª–∞—Å—Ç–µ—Ä–∞—Ö: {queries_with_cluster_but_no_lsi}")
            if len(clusters_without_lsi) <= 20:
                print(f"   ID –∫–ª–∞—Å—Ç–µ—Ä–æ–≤: {clusters_without_lsi[:20]}")
        
        print(f"üìä –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ LSI —Ñ—Ä–∞–∑ –∫–ª–∞—Å—Ç–µ—Ä–æ–≤:")
        print(f"   –ó–∞–ø–∏—Å–µ–π —Å –º–∞–ø–ø–∏–Ω–≥–æ–º: {mapped_count}/{len(df)}")
        print(f"   –ó–∞–ø–∏—Å–µ–π —Å –Ω–µ–ø—É—Å—Ç—ã–º–∏ LSI: {non_empty_count}/{len(df)}")
        print(f"   –ö–ª–∞—Å—Ç–µ—Ä–æ–≤ –±–µ–∑ LSI: {len(clusters_without_lsi)}")
        if queries_without_cluster > 0 or queries_with_cluster_but_no_lsi > 0:
            print(f"   –ó–∞–ø—Ä–æ—Å–æ–≤ –±–µ–∑ LSI –∫–ª–∞—Å—Ç–µ—Ä–∞: {queries_without_cluster + queries_with_cluster_but_no_lsi}")
        
        # –°—Ç—Ä–æ–∫–æ–≤–∞—è –≤–µ—Ä—Å–∏—è –¥–ª—è CSV
        df['cluster_lsi_phrases_str'] = df[cluster_column].map(cluster_to_lsi_str)
        df['cluster_lsi_phrases_str'] = df['cluster_lsi_phrases_str'].fillna('')
        
        # –¢–∞–∫–∂–µ —Å–æ—Ö—Ä–∞–Ω—è–µ–º –ø–æ–ª–Ω—ã–π —Å–ø–∏—Å–æ–∫ (–≤—Å–µ —Ñ—Ä–∞–∑—ã, –Ω–µ —Ç–æ–ª—å–∫–æ —Ç–æ–ø-30)
        df['cluster_lsi_full'] = df[cluster_column].map(
            lambda x: cluster_lsi.get(x, [])
        )
        
        return df
    
    def aggregate_cluster_serp_urls(
        self,
        df: pd.DataFrame,
        cluster_column: str = 'semantic_cluster_id',
        serp_urls_column: str = 'serp_urls',
        top_n: int = 10
    ) -> Dict[int, List[str]]:
        """
        –ê–≥—Ä–µ–≥–∏—Ä–æ–≤–∞—Ç—å –æ–±—â–∏–µ SERP URL –¥–ª—è –∫–∞–∂–¥–æ–≥–æ –∫–ª–∞—Å—Ç–µ—Ä–∞
        
        Args:
            df: DataFrame —Å –∫–æ–ª–æ–Ω–∫–∞–º–∏ [cluster_column, serp_urls_column]
            cluster_column: –ù–∞–∑–≤–∞–Ω–∏–µ –∫–æ–ª–æ–Ω–∫–∏ —Å ID –∫–ª–∞—Å—Ç–µ—Ä–∞
            serp_urls_column: –ù–∞–∑–≤–∞–Ω–∏–µ –∫–æ–ª–æ–Ω–∫–∏ —Å SERP URL
            top_n: –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ —Ç–æ–ø URL –Ω–∞ –∫–ª–∞—Å—Ç–µ—Ä
            
        Returns:
            Dict {cluster_id: [top_common_urls]}
        """
        from collections import Counter
        
        if cluster_column not in df.columns:
            print(f"‚ö†Ô∏è  –ö–æ–ª–æ–Ω–∫–∞ '{cluster_column}' –Ω–µ –Ω–∞–π–¥–µ–Ω–∞")
            return {}
        
        if serp_urls_column not in df.columns:
            print(f"‚ö†Ô∏è  –ö–æ–ª–æ–Ω–∫–∞ '{serp_urls_column}' –Ω–µ –Ω–∞–π–¥–µ–Ω–∞")
            return {}
        
        cluster_urls = {}
        
        # –ì—Ä—É–ø–ø–∏—Ä—É–µ–º –ø–æ –∫–ª–∞—Å—Ç–µ—Ä–∞–º
        for cluster_id, group in df.groupby(cluster_column):
            # –°–æ–±–∏—Ä–∞–µ–º –≤—Å–µ URL –∏–∑ –≤—Å–µ—Ö –∑–∞–ø—Ä–æ—Å–æ–≤ –∫–ª–∞—Å—Ç–µ—Ä–∞
            url_counter = Counter()
            
            for urls_list in group[serp_urls_column]:
                if isinstance(urls_list, list):
                    # –ï—Å–ª–∏ —ç—Ç–æ —Å–ø–∏—Å–æ–∫ —Å–ª–æ–≤–∞—Ä–µ–π - –∏–∑–≤–ª–µ–∫–∞–µ–º URL
                    urls = []
                    for item in urls_list:
                        if isinstance(item, dict):
                            url = item.get('url', '')
                            if url:
                                urls.append(url)
                        elif isinstance(item, str):
                            if item:
                                urls.append(item)
                    url_counter.update(urls)
            
            # –¢–æ–ø URL –ø–æ —á–∞—Å—Ç–æ—Ç–µ –≤—Å—Ç—Ä–µ—á–∞–µ–º–æ—Å—Ç–∏
            if url_counter:
                top_urls = [url for url, count in url_counter.most_common(top_n)]
                cluster_urls[cluster_id] = top_urls
            else:
                cluster_urls[cluster_id] = []
        
        return cluster_urls
    
    def add_cluster_serp_urls_to_dataframe(
        self,
        df: pd.DataFrame,
        cluster_urls: Dict[int, List[str]],
        cluster_column: str = 'semantic_cluster_id'
    ) -> pd.DataFrame:
        """
        –î–æ–±–∞–≤–∏—Ç—å –∞–≥—Ä–µ–≥–∏—Ä–æ–≤–∞–Ω–Ω—ã–µ SERP URL –≤ DataFrame
        
        Args:
            df: DataFrame
            cluster_urls: –ê–≥—Ä–µ–≥–∏—Ä–æ–≤–∞–Ω–Ω—ã–µ URL –ø–æ –∫–ª–∞—Å—Ç–µ—Ä–∞–º
            cluster_column: –ö–æ–ª–æ–Ω–∫–∞ —Å ID –∫–ª–∞—Å—Ç–µ—Ä–∞
            
        Returns:
            DataFrame —Å –Ω–æ–≤–æ–π –∫–æ–ª–æ–Ω–∫–æ–π 'cluster_common_urls'
        """
        # –°–æ–∑–¥–∞–µ–º –º–∞–ø–ø–∏–Ω–≥ cluster_id -> URL string
        cluster_to_urls = {}
        for cluster_id, urls_list in cluster_urls.items():
            # –§–æ—Ä–º–∏—Ä—É–µ–º —Å—Ç—Ä–æ–∫—É —Å —Ç–æ–ø URL
            cluster_to_urls[cluster_id] = ', '.join(urls_list)
        
        # –î–æ–±–∞–≤–ª—è–µ–º –∫–æ–ª–æ–Ω–∫—É —Å –æ–±—â–∏–º–∏ URL –∫–ª–∞—Å—Ç–µ—Ä–∞ (–Ω–µ –ø–µ—Ä–µ–∑–∞–ø–∏—Å—ã–≤–∞–µ–º –∏–Ω–¥–∏–≤–∏–¥—É–∞–ª—å–Ω—ã–µ!)
        df['cluster_common_urls'] = df[cluster_column].map(cluster_to_urls)
        df['cluster_common_urls'] = df['cluster_common_urls'].fillna('')
        
        return df
    
    def export_cluster_lsi(self, cluster_lsi: Dict[int, List[Dict[str, Any]]]) -> str:
        """
        –≠–∫—Å–ø–æ—Ä—Ç–∏—Ä–æ–≤–∞—Ç—å LSI —Ñ—Ä–∞–∑—ã –≤ —Å—Ç—Ä–æ–∫—É
        
        Args:
            cluster_lsi: –ê–≥—Ä–µ–≥–∏—Ä–æ–≤–∞–Ω–Ω—ã–µ LSI –ø–æ –∫–ª–∞—Å—Ç–µ—Ä–∞–º
            
        Returns:
            –°—Ç—Ä–æ–∫–æ–≤–æ–µ –ø—Ä–µ–¥—Å—Ç–∞–≤–ª–µ–Ω–∏–µ LSI —Ñ—Ä–∞–∑
        """
        result_lines = []
        for cluster_id, lsi_list in sorted(cluster_lsi.items()):
            phrases = []
            for item in lsi_list[:30]:
                if isinstance(item, dict):
                    phrase = item.get('phrase', '')
                    if phrase:
                        phrases.append(phrase)
                elif isinstance(item, str):
                    if item:
                        phrases.append(item)
            
            if phrases:
                result_lines.append(f"Cluster {cluster_id}: {', '.join(phrases)}")
        
        return '\n'.join(result_lines)
    
    def get_cluster_keywords_for_content(self, cluster_lsi: Dict[int, List[Dict[str, Any]]]) -> Dict[int, str]:
        """
        –ü–æ–ª—É—á–∏—Ç—å –∫–ª—é—á–µ–≤—ã–µ —Å–ª–æ–≤–∞ –¥–ª—è –∫–æ–Ω—Ç–µ–Ω—Ç–∞
        
        Args:
            cluster_lsi: –ê–≥—Ä–µ–≥–∏—Ä–æ–≤–∞–Ω–Ω—ã–µ LSI –ø–æ –∫–ª–∞—Å—Ç–µ—Ä–∞–º
            
        Returns:
            Dict {cluster_id: keywords_string}
        """
        result = {}
        for cluster_id, lsi_list in cluster_lsi.items():
            phrases = []
            for item in lsi_list[:10]:  # –¢–æ–ø-10 –¥–ª—è –∫–æ–Ω—Ç–µ–Ω—Ç–∞
                if isinstance(item, dict):
                    phrase = item.get('phrase', '')
                    if phrase:
                        phrases.append(phrase)
                elif isinstance(item, str):
                    if item:
                        phrases.append(item)
            
            result[cluster_id] = ', '.join(phrases) if phrases else ''
        
        return result
    
    def get_statistics(self, cluster_lsi: Dict[int, List[Dict[str, Any]]]) -> Dict[str, Any]:
        """
        –ü–æ–ª—É—á–∏—Ç—å —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É –ø–æ –∞–≥—Ä–µ–≥–∞—Ü–∏–∏
        
        Args:
            cluster_lsi: –ê–≥—Ä–µ–≥–∏—Ä–æ–≤–∞–Ω–Ω—ã–µ LSI –ø–æ –∫–ª–∞—Å—Ç–µ—Ä–∞–º
            
        Returns:
            –°–ª–æ–≤–∞—Ä—å —Å–æ —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–æ–π
        """
        total_clusters = len(cluster_lsi)
        clusters_with_lsi = sum(1 for lsi_list in cluster_lsi.values() if lsi_list)
        clusters_without_lsi = total_clusters - clusters_with_lsi
        
        total_phrases = sum(len(lsi_list) for lsi_list in cluster_lsi.values())
        avg_phrases_per_cluster = total_phrases / total_clusters if total_clusters > 0 else 0
        
        return {
            'total_clusters': total_clusters,
            'clusters_with_lsi': clusters_with_lsi,
            'clusters_without_lsi': clusters_without_lsi,
            'total_phrases': total_phrases,
            'total_unique_phrases': total_phrases,  # –î–ª—è —Å–æ–≤–º–µ—Å—Ç–∏–º–æ—Å—Ç–∏ —Å –∫–æ–¥–æ–º
            'avg_phrases_per_cluster': round(avg_phrases_per_cluster, 2)
        }


__all__ = ['ClusterLSIAggregator']
