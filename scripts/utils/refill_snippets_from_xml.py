"""
–ü–µ—Ä–µ–∑–∞–≥—Ä—É–∑–∫–∞ snippet –∏ passages –∏–∑ XML –¥–ª—è –∏—Å–ø—Ä–∞–≤–ª–µ–Ω–∏—è –ø—É—Å—Ç—ã—Ö –ø–æ–ª–µ–π
"""

import sqlite3
import json
from pathlib import Path
from typing import Dict, Any
import xml.etree.ElementTree as ET

# –ò–º–ø–æ—Ä—Ç–∏—Ä—É–µ–º enricher –¥–ª—è –ø—Ä–∞–≤–∏–ª—å–Ω–æ–π –æ–±—Ä–∞–±–æ—Ç–∫–∏ XML
import sys
sys.path.insert(0, str(Path(__file__).parent.parent.parent))

from seo_analyzer.core.serp_enricher.enricher import SERPDataEnricher


def refill_snippets_for_group(group_name: str):
    """
    –ü–µ—Ä–µ–∑–∞–≥—Ä—É–∑–∏—Ç—å snippet –∏ passages –∏–∑ XML –≤ master_queries.db
    
    Args:
        group_name: –ù–∞–∑–≤–∞–Ω–∏–µ –≥—Ä—É–ø–ø—ã (–Ω–∞–ø—Ä–∏–º–µ—Ä, '—Å–∫—É–¥')
    """
    serp_db_path = Path("data/databases/serp_data.db")
    master_db_path = Path("output/master_queries.db")
    
    if not serp_db_path.exists():
        print(f"‚ùå SERP –±–∞–∑–∞ –¥–∞–Ω–Ω—ã—Ö –Ω–µ –Ω–∞–π–¥–µ–Ω–∞: {serp_db_path}")
        return
    
    if not master_db_path.exists():
        print(f"‚ùå Master –±–∞–∑–∞ –¥–∞–Ω–Ω—ã—Ö –Ω–µ –Ω–∞–π–¥–µ–Ω–∞: {master_db_path}")
        return
    
    print(f"üìä –ü–µ—Ä–µ–∑–∞–≥—Ä—É–∑–∫–∞ snippet –∏ passages –¥–ª—è –≥—Ä—É–ø–ø—ã '{group_name}'...")
    print(f"   SERP DB: {serp_db_path}")
    print(f"   Master DB: {master_db_path}")
    print()
    
    # –ü–æ–¥–∫–ª—é—á–∞–µ–º—Å—è –∫ –æ–±–µ–∏–º –±–∞–∑–∞–º
    serp_conn = sqlite3.connect(serp_db_path)
    master_conn = sqlite3.connect(master_db_path)
    
    try:
        # –°–æ–∑–¥–∞—ë–º enricher –¥–ª—è –æ–±—Ä–∞–±–æ—Ç–∫–∏ XML
        enricher = SERPDataEnricher()
        
        # –ü–æ–ª—É—á–∞–µ–º –≤—Å–µ –∑–∞–ø—Ä–æ—Å—ã –≥—Ä—É–ø–ø—ã –∏–∑ master_queries
        master_cursor = master_conn.cursor()
        master_cursor.execute('''
            SELECT keyword, serp_top_urls
            FROM master_queries
            WHERE group_name = ?
            AND serp_status = 'completed'
        ''', (group_name,))
        
        queries = master_cursor.fetchall()
        total = len(queries)
        
        if total == 0:
            print(f"‚ö†Ô∏è  –ù–µ—Ç –∑–∞–≤–µ—Ä—à—ë–Ω–Ω—ã—Ö SERP –∑–∞–ø—Ä–æ—Å–æ–≤ –¥–ª—è –≥—Ä—É–ø–ø—ã '{group_name}'")
            return
        
        print(f"‚úì –ù–∞–π–¥–µ–Ω–æ {total} –∑–∞–ø—Ä–æ—Å–æ–≤ —Å SERP –¥–∞–Ω–Ω—ã–º–∏")
        print()
        
        # –°—á—ë—Ç—á–∏–∫–∏
        updated_count = 0
        skipped_count = 0
        error_count = 0
        
        for idx, (keyword, serp_top_urls_json) in enumerate(queries, 1):
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º –µ—Å—Ç—å –ª–∏ —É–∂–µ snippet –≤ JSON
            if serp_top_urls_json:
                try:
                    current_data = json.loads(serp_top_urls_json)
                    # –ü—Ä–æ–≤–µ—Ä—è–µ–º –ø–µ—Ä–≤—ã–π –¥–æ–∫—É–º–µ–Ω—Ç
                    if current_data and len(current_data) > 0:
                        first_doc = current_data[0]
                        # –ï—Å–ª–∏ snippet —É–∂–µ –µ—Å—Ç—å - –ø—Ä–æ–ø—É—Å–∫–∞–µ–º
                        if first_doc.get('snippet') and first_doc.get('passages'):
                            skipped_count += 1
                            if idx % 100 == 0:
                                print(f"   [{idx}/{total}] –ü—Ä–æ–ø—É—â–µ–Ω–æ (–¥–∞–Ω–Ω—ã–µ —É–∂–µ –µ—Å—Ç—å): {keyword[:50]}")
                            continue
                except:
                    pass
            
            # –ü–æ–ª—É—á–∞–µ–º XML –∏–∑ serp_data.db
            serp_cursor = serp_conn.cursor()
            serp_cursor.execute('''
                SELECT xml_response
                FROM serp_results
                WHERE query = ? AND query_group = ?
                LIMIT 1
            ''', (keyword, group_name))
            
            row = serp_cursor.fetchone()
            
            if not row or not row[0]:
                # XML –Ω–µ –Ω–∞–π–¥–µ–Ω - –ø—Ä–æ–ø—É—Å–∫–∞–µ–º
                skipped_count += 1
                continue
            
            xml_response = row[0]
            
            try:
                # –û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º XML —á–µ—Ä–µ–∑ enricher (—Å –Ω–æ–≤—ã–º –∫–æ–¥–æ–º fallback)
                enriched = enricher.enrich_from_serp(xml_response, keyword)
                documents = enriched.get('documents', [])
                
                if not documents:
                    skipped_count += 1
                    continue
                
                # –§–æ—Ä–º–∏—Ä—É–µ–º –æ–±–Ω–æ–≤–ª—ë–Ω–Ω—ã–π JSON –¥–ª—è serp_top_urls
                top_urls = []
                for i, doc in enumerate(documents[:20], 1):
                    top_urls.append({
                        'position': i,
                        'url': doc.get('url', ''),
                        'domain': doc.get('domain', ''),
                        'title': doc.get('title', ''),
                        'snippet': doc.get('snippet', ''),
                        'passages': doc.get('passages', ''),
                        'is_commercial': doc.get('is_commercial', False)
                    })
                
                top_urls_json = json.dumps(top_urls, ensure_ascii=False)
                
                # –û–±–Ω–æ–≤–ª—è–µ–º master_queries
                master_cursor.execute('''
                    UPDATE master_queries
                    SET serp_top_urls = ?,
                        updated_at = CURRENT_TIMESTAMP
                    WHERE group_name = ? AND keyword = ?
                ''', (top_urls_json, group_name, keyword))
                
                updated_count += 1
                
                # –õ–æ–≥–∏—Ä–æ–≤–∞–Ω–∏–µ –ø—Ä–æ–≥—Ä–µ—Å—Å–∞
                if idx % 10 == 0 or idx <= 5:
                    snippet_preview = top_urls[0]['snippet'][:60] if top_urls[0]['snippet'] else '(–ø—É—Å—Ç–æ)'
                    passages_preview = top_urls[0]['passages'][:60] if top_urls[0]['passages'] else '(–ø—É—Å—Ç–æ)'
                    print(f"   [{idx}/{total}] ‚úì {keyword[:40]}")
                    print(f"      Snippet: {snippet_preview}...")
                    print(f"      Passages: {passages_preview}...")
            
            except Exception as e:
                error_count += 1
                print(f"   [{idx}/{total}] ‚ùå –û—à–∏–±–∫–∞: {keyword[:50]} - {e}")
        
        # –°–æ—Ö—Ä–∞–Ω—è–µ–º –∏–∑–º–µ–Ω–µ–Ω–∏—è
        master_conn.commit()
        
        print()
        print("=" * 80)
        print(f"‚úÖ –û–±—Ä–∞–±–æ—Ç–∫–∞ –∑–∞–≤–µ—Ä—à–µ–Ω–∞!")
        print(f"   –û–±–Ω–æ–≤–ª–µ–Ω–æ: {updated_count}")
        print(f"   –ü—Ä–æ–ø—É—â–µ–Ω–æ (–¥–∞–Ω–Ω—ã–µ —É–∂–µ –µ—Å—Ç—å): {skipped_count}")
        print(f"   –û—à–∏–±–æ–∫: {error_count}")
        print(f"   –í—Å–µ–≥–æ: {total}")
        
    finally:
        serp_conn.close()
        master_conn.close()


if __name__ == '__main__':
    import sys
    
    if len(sys.argv) < 2:
        print("–ò—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ: python refill_snippets_from_xml.py <group_name>")
        print("–ü—Ä–∏–º–µ—Ä: python refill_snippets_from_xml.py —Å–∫—É–¥")
        sys.exit(1)
    
    group_name = sys.argv[1]
    refill_snippets_for_group(group_name)

