"""
–î–∏–∞–≥–Ω–æ—Å—Ç–∏–∫–∞ LSI —Ñ—Ä–∞–∑ –¥–ª—è –∫–æ–Ω–∫—Ä–µ—Ç–Ω–æ–≥–æ –∑–∞–ø—Ä–æ—Å–∞

–ü—Ä–æ–≤–µ—Ä—è–µ—Ç:
1. –ï—Å—Ç—å –ª–∏ LSI —Ñ—Ä–∞–∑—ã —É –∑–∞–ø—Ä–æ—Å–∞ –≤ –ë–î
2. –ï—Å—Ç—å –ª–∏ —É –∑–∞–ø—Ä–æ—Å–∞ –∫–ª–∞—Å—Ç–µ—Ä
3. –ï—Å—Ç—å –ª–∏ LSI —Ñ—Ä–∞–∑—ã —É –∫–ª–∞—Å—Ç–µ—Ä–∞ –ø–æ—Å–ª–µ –∞–≥—Ä–µ–≥–∞—Ü–∏–∏
4. –ö–∞–∫ –æ–Ω–∏ —ç–∫—Å–ø–æ—Ä—Ç–∏—Ä—É—é—Ç—Å—è –≤ Excel
"""

import sys
from pathlib import Path
import pandas as pd
import json

# –î–æ–±–∞–≤–ª—è–µ–º –∫–æ—Ä–Ω–µ–≤—É—é –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏—é –≤ –ø—É—Ç—å
root_dir = Path(__file__).parent.parent.parent
sys.path.insert(0, str(root_dir))

from seo_analyzer.core.cache.master_query_db import MasterQueryDatabase
from seo_analyzer.core.config_paths import OUTPUT_DIR


def check_query_lsi(query: str, group_name: str = None):
    """
    –ü—Ä–æ–≤–µ—Ä–∏—Ç—å LSI —Ñ—Ä–∞–∑—ã –¥–ª—è –∫–æ–Ω–∫—Ä–µ—Ç–Ω–æ–≥–æ –∑–∞–ø—Ä–æ—Å–∞
    
    Args:
        query: –ü–æ–∏—Å–∫–æ–≤—ã–π –∑–∞–ø—Ä–æ—Å
        group_name: –ù–∞–∑–≤–∞–Ω–∏–µ –≥—Ä—É–ø–ø—ã (–æ–ø—Ü–∏–æ–Ω–∞–ª—å–Ω–æ)
    """
    print("=" * 80)
    print(f"üîç –î–ò–ê–ì–ù–û–°–¢–ò–ö–ê LSI –§–†–ê–ó –î–õ–Ø –ó–ê–ü–†–û–°–ê")
    print("=" * 80)
    print(f"–ó–∞–ø—Ä–æ—Å: '{query}'")
    if group_name:
        print(f"–ì—Ä—É–ø–ø–∞: '{group_name}'")
    print()
    
    # –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä—É–µ–º Master DB
    db_path = OUTPUT_DIR / "master_queries.db"
    if not db_path.exists():
        print(f"‚ùå –ë–∞–∑–∞ –¥–∞–Ω–Ω—ã—Ö –Ω–µ –Ω–∞–π–¥–µ–Ω–∞: {db_path}")
        return
    
    master_db = MasterQueryDatabase(db_path=db_path)
    
    import sqlite3
    conn = sqlite3.connect(db_path)
    cursor = conn.cursor()
    
    # –ò—â–µ–º –∑–∞–ø—Ä–æ—Å –≤ –ë–î (semantic_cluster_id –Ω–µ —Ö—Ä–∞–Ω–∏—Ç—Å—è –≤ –ë–î, –¥–æ–±–∞–≤–ª—è–µ—Ç—Å—è –¥–∏–Ω–∞–º–∏—á–µ—Å–∫–∏)
    if group_name:
        cursor.execute('''
            SELECT keyword, group_name, serp_lsi_phrases, serp_top_urls, serp_status
            FROM master_queries
            WHERE keyword = ? AND group_name = ?
        ''', (query, group_name))
        row = cursor.fetchone()
    else:
        # –ò—â–µ–º —Ç–æ—á–Ω–æ–µ —Å–æ–≤–ø–∞–¥–µ–Ω–∏–µ
        cursor.execute('''
            SELECT keyword, group_name, serp_lsi_phrases, serp_top_urls, serp_status
            FROM master_queries
            WHERE keyword = ?
            LIMIT 1
        ''', (query,))
        row = cursor.fetchone()
        
        # –ï—Å–ª–∏ –Ω–µ –Ω–∞–π–¥–µ–Ω–æ, –∏—â–µ–º –ø–æ—Ö–æ–∂–∏–µ –∑–∞–ø—Ä–æ—Å—ã
        if not row:
            print(f"‚ö†Ô∏è  –¢–æ—á–Ω–æ–µ —Å–æ–≤–ø–∞–¥–µ–Ω–∏–µ –Ω–µ –Ω–∞–π–¥–µ–Ω–æ, –∏—â–µ–º –ø–æ—Ö–æ–∂–∏–µ –∑–∞–ø—Ä–æ—Å—ã...")
            cursor.execute('''
                SELECT keyword, group_name
                FROM master_queries
                WHERE keyword LIKE ? OR keyword LIKE ?
                LIMIT 10
            ''', (f'%{query[:20]}%', f'%{query[-20:]}%'))
            similar = cursor.fetchall()
            if similar:
                print(f"   –ù–∞–π–¥–µ–Ω–æ {len(similar)} –ø–æ—Ö–æ–∂–∏—Ö –∑–∞–ø—Ä–æ—Å–æ–≤:")
                for i, (kw, grp) in enumerate(similar[:5], 1):
                    print(f"      {i}. '{kw}' (–≥—Ä—É–ø–ø–∞: {grp})")
                print()
                print("   –ü–æ–ø—Ä–æ–±—É–π—Ç–µ –∑–∞–ø—É—Å—Ç–∏—Ç—å —Å —Ç–æ—á–Ω—ã–º –∑–∞–ø—Ä–æ—Å–æ–º:")
                print(f"   python check_query_lsi.py '{similar[0][0]}' '{similar[0][1]}'")
            else:
                # –ò—â–µ–º –ø–æ —á–∞—Å—Ç–∏ –∑–∞–ø—Ä–æ—Å–∞
                words = query.split()
                if len(words) > 1:
                    # –ü—Ä–æ–±—É–µ–º –Ω–∞–π—Ç–∏ –ø–æ —Å–ª–æ–≤—É "—Å–∫—É–¥" –∏–ª–∏ "—Å–∏—Å—Ç–µ–º–∞"
                    search_terms = []
                    for word in words:
                        if len(word) > 3:  # –ò–≥–Ω–æ—Ä–∏—Ä—É–µ–º –∫–æ—Ä–æ—Ç–∫–∏–µ —Å–ª–æ–≤–∞
                            search_terms.append(f'%{word}%')
                    
                    if search_terms:
                        # –ò—â–µ–º –≤ –≥—Ä—É–ø–ø–µ "—Å–∫—É–¥" –µ—Å–ª–∏ –µ—Å—Ç—å —Å–ª–æ–≤–æ "—Å–∫—É–¥" –≤ –∑–∞–ø—Ä–æ—Å–µ
                        if '—Å–∫—É–¥' in query.lower():
                            cursor.execute('''
                                SELECT keyword, group_name
                                FROM master_queries
                                WHERE group_name = '—Å–∫—É–¥' AND keyword LIKE ?
                                LIMIT 10
                            ''', (f'%{query[:15]}%',))
                            similar = cursor.fetchall()
                            if similar:
                                print(f"   –ù–∞–π–¥–µ–Ω–æ {len(similar)} –∑–∞–ø—Ä–æ—Å–æ–≤ –≤ –≥—Ä—É–ø–ø–µ '—Å–∫—É–¥', —Å–æ–¥–µ—Ä–∂–∞—â–∏—Ö –ø–æ—Ö–æ–∂–∏–µ —Å–ª–æ–≤–∞:")
                                for i, (kw, grp) in enumerate(similar[:5], 1):
                                    print(f"      {i}. '{kw}' (–≥—Ä—É–ø–ø–∞: {grp})")
                                print()
                                print("   –ü–æ–ø—Ä–æ–±—É–π—Ç–µ –∑–∞–ø—É—Å—Ç–∏—Ç—å —Å —Ç–æ—á–Ω—ã–º –∑–∞–ø—Ä–æ—Å–æ–º:")
                                print(f"   python check_query_lsi.py '{similar[0][0]}' '{similar[0][1]}'")
                        else:
                            # –ò—â–µ–º –ø–æ –ø–µ—Ä–≤–æ–º—É –¥–ª–∏–Ω–Ω–æ–º—É —Å–ª–æ–≤—É
                            search_term = search_terms[0]
                            cursor.execute('''
                                SELECT keyword, group_name
                                FROM master_queries
                                WHERE keyword LIKE ?
                                LIMIT 10
                            ''', (search_term,))
                            similar = cursor.fetchall()
                            if similar:
                                print(f"   –ù–∞–π–¥–µ–Ω–æ {len(similar)} –∑–∞–ø—Ä–æ—Å–æ–≤, —Å–æ–¥–µ—Ä–∂–∞—â–∏—Ö '{words[0]}':")
                                for i, (kw, grp) in enumerate(similar[:5], 1):
                                    print(f"      {i}. '{kw}' (–≥—Ä—É–ø–ø–∞: {grp})")
    
    if not row:
        print(f"‚ùå –ó–∞–ø—Ä–æ—Å '{query}' –Ω–µ –Ω–∞–π–¥–µ–Ω –≤ –±–∞–∑–µ –¥–∞–Ω–Ω—ã—Ö")
        if group_name:
            print(f"   –ì—Ä—É–ø–ø–∞: {group_name}")
            # –ò—â–µ–º –ø–æ—Ö–æ–∂–∏–µ –∑–∞–ø—Ä–æ—Å—ã –≤ —ç—Ç–æ–π –≥—Ä—É–ø–ø–µ
            print(f"\n   –ò—â–µ–º –ø–æ—Ö–æ–∂–∏–µ –∑–∞–ø—Ä–æ—Å—ã –≤ –≥—Ä—É–ø–ø–µ '{group_name}'...")
            words = query.split()
            search_queries = []
            for word in words:
                if len(word) > 3:
                    search_queries.append(f'%{word}%')
            
            if search_queries:
                # –ò—â–µ–º –∑–∞–ø—Ä–æ—Å—ã, —Å–æ–¥–µ—Ä–∂–∞—â–∏–µ –Ω–µ—Å–∫–æ–ª—å–∫–æ —Å–ª–æ–≤ –∏–∑ –∑–∞–ø—Ä–æ—Å–∞
                placeholders = ','.join(['?'] * len(search_queries))
                sql = f'''
                    SELECT keyword
                    FROM master_queries
                    WHERE group_name = ? AND ({' OR '.join(['keyword LIKE ?'] * len(search_queries))})
                    LIMIT 20
                '''
                cursor.execute(sql, (group_name,) + tuple(search_queries))
                similar = cursor.fetchall()
                if similar:
                    print(f"   –ù–∞–π–¥–µ–Ω–æ {len(similar)} –ø–æ—Ö–æ–∂–∏—Ö –∑–∞–ø—Ä–æ—Å–æ–≤:")
                    for i, (kw,) in enumerate(similar[:10], 1):
                        print(f"      {i}. '{kw}'")
                    print()
                    print("   –ü–æ–ø—Ä–æ–±—É–π—Ç–µ –∑–∞–ø—É—Å—Ç–∏—Ç—å —Å —Ç–æ—á–Ω—ã–º –∑–∞–ø—Ä–æ—Å–æ–º:")
                    print(f"   python check_query_lsi.py '{similar[0][0]}' '{group_name}'")
        else:
            print("   –ü–æ–ø—Ä–æ–±—É–π—Ç–µ —É–∫–∞–∑–∞—Ç—å –≥—Ä—É–ø–ø—É: python check_query_lsi.py '<–∑–∞–ø—Ä–æ—Å>' '<–≥—Ä—É–ø–ø–∞>'")
            # –ü–æ–∫–∞–∑—ã–≤–∞–µ–º —Å–ø–∏—Å–æ–∫ –≤—Å–µ—Ö –≥—Ä—É–ø–ø
            cursor.execute('SELECT DISTINCT group_name FROM master_queries ORDER BY group_name')
            groups = cursor.fetchall()
            if groups:
                print(f"\n   –î–æ—Å—Ç—É–ø–Ω—ã–µ –≥—Ä—É–ø–ø—ã ({len(groups)}):")
                for i, (grp,) in enumerate(groups[:10], 1):
                    print(f"      {i}. {grp}")
                if len(groups) > 10:
                    print(f"      ... –∏ –µ—â–µ {len(groups) - 10} –≥—Ä—É–ø–ø")
        conn.close()
        return
    
    keyword, found_group, lsi_phrases_json, top_urls_json, serp_status = row
    
    print(f"‚úì –ó–∞–ø—Ä–æ—Å –Ω–∞–π–¥–µ–Ω –≤ –≥—Ä—É–ø–ø–µ: '{found_group}'")
    print(f"   –°—Ç–∞—Ç—É—Å SERP: {serp_status}")
    
    # –ü—Ä–æ–≤–µ—Ä—è–µ–º –Ω–∞–ª–∏—á–∏–µ req_id
    cursor.execute('''
        SELECT serp_req_id
        FROM master_queries
        WHERE keyword = ? AND group_name = ?
    ''', (keyword, found_group))
    req_id_row = cursor.fetchone()
    req_id = req_id_row[0] if req_id_row else None
    
    if req_id:
        print(f"   SERP req_id: {req_id}")
    else:
        print(f"   ‚ö†Ô∏è  SERP req_id –æ—Ç—Å—É—Ç—Å—Ç–≤—É–µ—Ç")
    print()
    
    # –ü—Ä–æ–≤–µ—Ä—è–µ–º LSI —Ñ—Ä–∞–∑—ã –∑–∞–ø—Ä–æ—Å–∞
    print("üìã LSI —Ñ—Ä–∞–∑—ã –∑–∞–ø—Ä–æ—Å–∞ (–∏–∑ –ë–î):")
    if lsi_phrases_json:
        try:
            lsi_phrases = json.loads(lsi_phrases_json) if isinstance(lsi_phrases_json, str) else lsi_phrases_json
            if isinstance(lsi_phrases, list) and len(lsi_phrases) > 0:
                print(f"   ‚úì –ù–∞–π–¥–µ–Ω–æ {len(lsi_phrases)} LSI —Ñ—Ä–∞–∑")
                for i, item in enumerate(lsi_phrases[:5], 1):
                    if isinstance(item, dict):
                        phrase = item.get('phrase', '')
                        freq = item.get('frequency', 0)
                        source = item.get('source', 'unknown')
                        print(f"      {i}. {phrase} (—á–∞—Å—Ç–æ—Ç–∞: {freq}, –∏—Å—Ç–æ—á–Ω–∏–∫: {source})")
                if len(lsi_phrases) > 5:
                    print(f"      ... –∏ –µ—â–µ {len(lsi_phrases) - 5} —Ñ—Ä–∞–∑")
            else:
                print(f"   ‚ö†Ô∏è  LSI —Ñ—Ä–∞–∑—ã –ø—É—Å—Ç—ã–µ –∏–ª–∏ –≤ –Ω–µ–ø—Ä–∞–≤–∏–ª—å–Ω–æ–º —Ñ–æ—Ä–º–∞—Ç–µ")
                print(f"      –¢–∏–ø: {type(lsi_phrases)}, –ó–Ω–∞—á–µ–Ω–∏–µ: {str(lsi_phrases)[:100]}")
        except Exception as e:
            print(f"   ‚ùå –û—à–∏–±–∫–∞ –ø–∞—Ä—Å–∏–Ω–≥–∞ LSI —Ñ—Ä–∞–∑: {e}")
            print(f"      –°—ã—Ä—ã–µ –¥–∞–Ω–Ω—ã–µ: {str(lsi_phrases_json)[:200]}")
    else:
        print("   ‚ùå LSI —Ñ—Ä–∞–∑—ã –æ—Ç—Å—É—Ç—Å—Ç–≤—É—é—Ç –≤ –ë–î")
        if req_id and serp_status == 'completed':
            print("   ‚ö†Ô∏è  –ü–†–û–ë–õ–ï–ú–ê: –°—Ç–∞—Ç—É—Å 'completed', –Ω–æ LSI —Ñ—Ä–∞–∑—ã –æ—Ç—Å—É—Ç—Å—Ç–≤—É—é—Ç!")
            print("   ‚Üí –í–æ–∑–º–æ–∂–Ω–æ, –¥–∞–Ω–Ω—ã–µ –Ω–µ –±—ã–ª–∏ –ø–æ–ª—É—á–µ–Ω—ã –æ—Ç xmlstock")
            print("   ‚Üí –ò–ª–∏ –¥–∞–Ω–Ω—ã–µ –±—ã–ª–∏ –ø–æ–ª—É—á–µ–Ω—ã, –Ω–æ –Ω–µ —Å–æ—Ö—Ä–∞–Ω–µ–Ω—ã")
            print("   ‚Üí –†–µ—à–µ–Ω–∏–µ: –ø–µ—Ä–µ—Å–æ–±–µ—Ä–∏—Ç–µ SERP –¥–∞–Ω–Ω—ã–µ –¥–ª—è —ç—Ç–æ–≥–æ –∑–∞–ø—Ä–æ—Å–∞")
    print()
    
    # –ü—Ä–æ–≤–µ—Ä—è–µ–º URL
    print("üìã URL –¥–∞–Ω–Ω—ã–µ:")
    if top_urls_json:
        try:
            top_urls = json.loads(top_urls_json) if isinstance(top_urls_json, str) else top_urls_json
            if isinstance(top_urls, list):
                print(f"   ‚úì –ù–∞–π–¥–µ–Ω–æ {len(top_urls)} URL")
                # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Ñ–æ—Ä–º–∞—Ç
                if len(top_urls) > 0:
                    first_item = top_urls[0]
                    if isinstance(first_item, dict):
                        has_title = bool(first_item.get('title'))
                        print(f"   –§–æ—Ä–º–∞—Ç: —Å–ª–æ–≤–∞—Ä–∏ {'—Å title' if has_title else '–±–µ–∑ title'}")
                    elif isinstance(first_item, str):
                        print(f"   –§–æ—Ä–º–∞—Ç: —Ç–æ–ª—å–∫–æ —Å—Ç—Ä–æ–∫–∏ URL")
            else:
                print(f"   ‚ö†Ô∏è  URL –≤ –Ω–µ–ø—Ä–∞–≤–∏–ª—å–Ω–æ–º —Ñ–æ—Ä–º–∞—Ç–µ")
        except Exception as e:
            print(f"   ‚ùå –û—à–∏–±–∫–∞ –ø–∞—Ä—Å–∏–Ω–≥–∞ URL: {e}")
    else:
        print("   ‚ùå URL –æ—Ç—Å—É—Ç—Å—Ç–≤—É—é—Ç")
    print()
    
    # –ó–∞–≥—Ä—É–∂–∞–µ–º –¥–∞–Ω–Ω—ã–µ —á–µ—Ä–µ–∑ MasterQueryDatabase –¥–ª—è –ø–æ–ª—É—á–µ–Ω–∏—è –∫–ª–∞—Å—Ç–µ—Ä–∏–∑–∞—Ü–∏–∏
    print("üìã –ó–∞–≥—Ä—É–∑–∫–∞ –¥–∞–Ω–Ω—ã—Ö –≥—Ä—É–ø–ø—ã –¥–ª—è –ø—Ä–æ–≤–µ—Ä–∫–∏ –∫–ª–∞—Å—Ç–µ—Ä–∏–∑–∞—Ü–∏–∏...")
    try:
        df = master_db.load_queries(found_group, include_serp_urls=True)
        if df is None or len(df) == 0:
            print(f"‚ùå –ù–µ —É–¥–∞–ª–æ—Å—å –∑–∞–≥—Ä—É–∑–∏—Ç—å –¥–∞–Ω–Ω—ã–µ –≥—Ä—É–ø–ø—ã '{found_group}'")
            return
        
        # –ù–∞—Ö–æ–¥–∏–º –Ω–∞—à –∑–∞–ø—Ä–æ—Å –≤ DataFrame
        query_row = df[df['keyword'] == query]
        if len(query_row) == 0:
            print(f"‚ùå –ó–∞–ø—Ä–æ—Å '{query}' –Ω–µ –Ω–∞–π–¥–µ–Ω –≤ –∑–∞–≥—Ä—É–∂–µ–Ω–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö")
            return
        
        cluster_id = query_row['semantic_cluster_id'].iloc[0] if 'semantic_cluster_id' in query_row.columns else None
        
        if cluster_id is None or pd.isna(cluster_id):
            print("‚ö†Ô∏è  –£ –∑–∞–ø—Ä–æ—Å–∞ –Ω–µ—Ç –∫–ª–∞—Å—Ç–µ—Ä–∞ (semantic_cluster_id = NULL)")
            print("   LSI —Ñ—Ä–∞–∑—ã –∫–ª–∞—Å—Ç–µ—Ä–∞ –Ω–µ –º–æ–≥—É—Ç –±—ã—Ç—å –∑–∞–ø–æ–ª–Ω–µ–Ω—ã –±–µ–∑ –∫–ª–∞—Å—Ç–µ—Ä–∞")
            print("   ‚Üí –ó–∞–ø—É—Å—Ç–∏—Ç–µ –∫–ª–∞—Å—Ç–µ—Ä–∏–∑–∞—Ü–∏—é –¥–ª—è —ç—Ç–æ–π –≥—Ä—É–ø–ø—ã")
            return
        
        if cluster_id == -1:
            print("‚ö†Ô∏è  –ó–∞–ø—Ä–æ—Å –Ω–µ –∫–ª–∞—Å—Ç–µ—Ä–∏–∑–æ–≤–∞–Ω (semantic_cluster_id = -1)")
            print("   LSI —Ñ—Ä–∞–∑—ã –∫–ª–∞—Å—Ç–µ—Ä–∞ –Ω–µ –º–æ–≥—É—Ç –±—ã—Ç—å –∑–∞–ø–æ–ª–Ω–µ–Ω—ã –¥–ª—è –Ω–µ–∫–ª–∞—Å—Ç–µ—Ä–∏–∑–æ–≤–∞–Ω–Ω—ã—Ö –∑–∞–ø—Ä–æ—Å–æ–≤")
            return
        
        print(f"üìã –ü—Ä–æ–≤–µ—Ä–∫–∞ –∫–ª–∞—Å—Ç–µ—Ä–∞ {cluster_id}:")
        
        # –ù–∞—Ö–æ–¥–∏–º –≤—Å–µ –∑–∞–ø—Ä–æ—Å—ã –≤ —ç—Ç–æ–º –∫–ª–∞—Å—Ç–µ—Ä–µ –∏–∑ DataFrame
        cluster_df = df[df['semantic_cluster_id'] == cluster_id]
    
        print(f"   –ó–∞–ø—Ä–æ—Å–æ–≤ –≤ –∫–ª–∞—Å—Ç–µ—Ä–µ: {len(cluster_df)}")
        
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º LSI —Ñ—Ä–∞–∑—ã –≤—Å–µ—Ö –∑–∞–ø—Ä–æ—Å–æ–≤ –∫–ª–∞—Å—Ç–µ—Ä–∞
        queries_with_lsi = 0
        queries_without_lsi = 0
        all_lsi_phrases = []
        
        for idx, row in cluster_df.iterrows():
            q_lsi = row.get('lsi_phrases', [])
            if q_lsi:
                if isinstance(q_lsi, str):
                    try:
                        q_lsi = json.loads(q_lsi)
                    except:
                        queries_without_lsi += 1
                        continue
                
                if isinstance(q_lsi, list) and len(q_lsi) > 0:
                    queries_with_lsi += 1
                    all_lsi_phrases.extend(q_lsi)
                else:
                    queries_without_lsi += 1
            else:
                queries_without_lsi += 1
    
        print(f"   –ó–∞–ø—Ä–æ—Å–æ–≤ —Å LSI: {queries_with_lsi}/{len(cluster_df)}")
        print(f"   –ó–∞–ø—Ä–æ—Å–æ–≤ –±–µ–∑ LSI: {queries_without_lsi}/{len(cluster_df)}")
        
        if queries_with_lsi == 0:
            print()
            print("‚ùå –ü–†–û–ë–õ–ï–ú–ê: –£ –≤—Å–µ—Ö –∑–∞–ø—Ä–æ—Å–æ–≤ –∫–ª–∞—Å—Ç–µ—Ä–∞ –Ω–µ—Ç LSI —Ñ—Ä–∞–∑!")
            print("   –≠—Ç–æ –æ–∑–Ω–∞—á–∞–µ—Ç, —á—Ç–æ LSI —Ñ—Ä–∞–∑—ã –Ω–µ –±—ã–ª–∏ –∏–∑–≤–ª–µ—á–µ–Ω—ã –∏–∑ SERP –¥–∞–Ω–Ω—ã—Ö")
            print("   –†–µ—à–µ–Ω–∏–µ: –∑–∞–ø—É—Å—Ç–∏—Ç–µ –¥–æ—Å–æ–±–æ—Ä LSI –∏–ª–∏ –ø–µ—Ä–µ—Å–æ–±–µ—Ä–∏—Ç–µ SERP –¥–∞–Ω–Ω—ã–µ")
            conn.close()
            return
        
        if len(all_lsi_phrases) > 0:
            print(f"   –í—Å–µ–≥–æ LSI —Ñ—Ä–∞–∑ –≤ –∫–ª–∞—Å—Ç–µ—Ä–µ: {len(all_lsi_phrases)}")
            print()
            print("üìã –ü—Ä–∏–º–µ—Ä—ã LSI —Ñ—Ä–∞–∑ –∏–∑ –∫–ª–∞—Å—Ç–µ—Ä–∞ (–ø–µ—Ä–≤—ã–µ 10):")
            phrase_counter = {}
            for item in all_lsi_phrases:
                if isinstance(item, dict):
                    phrase = item.get('phrase', '')
                    if phrase:
                        phrase_counter[phrase] = phrase_counter.get(phrase, 0) + item.get('frequency', 1)
            
            sorted_phrases = sorted(phrase_counter.items(), key=lambda x: x[1], reverse=True)[:10]
            for i, (phrase, freq) in enumerate(sorted_phrases, 1):
                print(f"      {i}. {phrase} (—á–∞—Å—Ç–æ—Ç–∞: {freq})")
        
        conn.close()
        
        print()
        print("=" * 80)
        print("üí° –í–´–í–û–î–´:")
        if queries_with_lsi > 0:
            print("   ‚úì –£ –∫–ª–∞—Å—Ç–µ—Ä–∞ –µ—Å—Ç—å LSI —Ñ—Ä–∞–∑—ã –¥–ª—è –∞–≥—Ä–µ–≥–∞—Ü–∏–∏")
            print("   ‚úì –ü—Ä–æ–±–ª–µ–º–∞ –º–æ–∂–µ—Ç –±—ã—Ç—å –≤ –∞–≥—Ä–µ–≥–∞—Ü–∏–∏ –∏–ª–∏ —ç–∫—Å–ø–æ—Ä—Ç–µ")
            print("   ‚Üí –ó–∞–ø—É—Å—Ç–∏—Ç–µ –ø–µ—Ä–µ—Å–æ–∑–¥–∞–Ω–∏–µ —ç–∫—Å–ø–æ—Ä—Ç–∞: python scripts/utils/rebuild_exports.py <–≥—Ä—É–ø–ø–∞>")
        else:
            print("   ‚ùå –£ –∫–ª–∞—Å—Ç–µ—Ä–∞ –Ω–µ—Ç LSI —Ñ—Ä–∞–∑ –¥–ª—è –∞–≥—Ä–µ–≥–∞—Ü–∏–∏")
            print("   ‚Üí –ù—É–∂–Ω–æ –¥–æ—Å–æ–±—Ä–∞—Ç—å LSI —Ñ—Ä–∞–∑—ã –¥–ª—è –∑–∞–ø—Ä–æ—Å–æ–≤ –∫–ª–∞—Å—Ç–µ—Ä–∞")
        print("=" * 80)
    except Exception as e:
        print(f"‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ –∑–∞–≥—Ä—É–∑–∫–µ –¥–∞–Ω–Ω—ã—Ö: {e}")
        import traceback
        traceback.print_exc()
        conn.close()
        return


def main():
    if len(sys.argv) < 2:
        print("‚ùå –£–∫–∞–∂–∏—Ç–µ –∑–∞–ø—Ä–æ—Å: python check_query_lsi.py '<–∑–∞–ø—Ä–æ—Å>' [–≥—Ä—É–ø–ø–∞]")
        print("   –ù–∞–ø—Ä–∏–º–µ—Ä: python check_query_lsi.py '—Å–∏—Å—Ç–µ–º–∞ —Å–∫—É–¥–∞ —á—Ç–æ —ç—Ç–æ —Ç–∞–∫–æ–π'")
        print("   –ò–ª–∏: python check_query_lsi.py '—Å–∏—Å—Ç–µ–º–∞ —Å–∫—É–¥–∞ —á—Ç–æ —ç—Ç–æ —Ç–∞–∫–æ–π' '—Å–∫—É–¥'")
        sys.exit(1)
    
    query = sys.argv[1]
    group_name = sys.argv[2] if len(sys.argv) >= 3 else None
    
    # –ï—Å–ª–∏ –≥—Ä—É–ø–ø–∞ –Ω–µ —É–∫–∞–∑–∞–Ω–∞, –Ω–æ –≤ –∑–∞–ø—Ä–æ—Å–µ –µ—Å—Ç—å "—Å–∫—É–¥", –ø—Ä–æ–±—É–µ–º –≥—Ä—É–ø–ø—É "—Å–∫—É–¥"
    if not group_name and '—Å–∫—É–¥' in query.lower():
        print(f"üí° –û–±–Ω–∞—Ä—É–∂–µ–Ω–æ —Å–ª–æ–≤–æ '—Å–∫—É–¥' –≤ –∑–∞–ø—Ä–æ—Å–µ, –ø—Ä–æ–±—É–µ–º –≥—Ä—É–ø–ø—É '—Å–∫—É–¥'...")
        print()
        check_query_lsi(query, '—Å–∫—É–¥')
    else:
        check_query_lsi(query, group_name)


if __name__ == '__main__':
    main()

