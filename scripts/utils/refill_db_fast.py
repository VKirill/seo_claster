"""
–ë—ã—Å—Ç—Ä–∞—è –ø–µ—Ä–µ–æ–±—Ä–∞–±–æ—Ç–∫–∞ –ë–î —Å –ø–∞—Ä–∞–ª–ª–µ–ª—å–Ω–æ–π –æ–±—Ä–∞–±–æ—Ç–∫–æ–π XML
"""

import asyncio
import sqlite3
from pathlib import Path
from typing import Dict, Any, Optional
from concurrent.futures import ProcessPoolExecutor
import multiprocessing as mp

from seo_analyzer.core.serp_data_enricher import SERPDataEnricher
from seo_analyzer.core.lsi_extractor import LSIExtractor  # –¢–µ–ø–µ—Ä—å –≤—Å–µ —ç–∫—Å—Ç—Ä–∞–∫—Ç–æ—Ä—ã –±—ã—Å—Ç—Ä—ã–µ!


def process_xml_chunk(chunk_data: list[tuple]) -> list[Dict[str, Any]]:
    """
    –û–±—Ä–∞–±–æ—Ç–∞—Ç—å –ø–∞–∫–µ—Ç XML –≤ –æ—Ç–¥–µ–ª—å–Ω–æ–º –ø—Ä–æ—Ü–µ—Å—Å–µ
    
    Args:
        chunk_data: –°–ø–∏—Å–æ–∫ (record_id, query, lr, xml_response)
        
    Returns:
        –°–ø–∏—Å–æ–∫ –æ–±—Ä–∞–±–æ—Ç–∞–Ω–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö
    """
    enricher = SERPDataEnricher()
    lsi_extractor = LSIExtractor()  # –¢–µ–ø–µ—Ä—å –≤—Å–µ –∏—Å–ø–æ–ª—å–∑—É—é—Ç –∫—ç—à–∏—Ä–æ–≤–∞–Ω–Ω—É—é –ª–µ–º–º–∞—Ç–∏–∑–∞—Ü–∏—é!
    
    results = []
    
    for record_id, query, lr, xml_response in chunk_data:
        try:
            # –û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º XML
            enriched = enricher.enrich_from_serp(xml_response, query)
            
            if enriched.get('error'):
                results.append({
                    'record_id': record_id,
                    'query': query,
                    'success': False,
                    'error': enriched['error']
                })
                continue
            
            # –ò–∑–≤–ª–µ–∫–∞–µ–º LSI —Å –∫—ç—à–∏—Ä–æ–≤–∞–Ω–∏–µ–º
            lsi_phrases = lsi_extractor.extract_from_serp_documents(
                enriched['documents'],
                query
            )
            
            results.append({
                'record_id': record_id,
                'query': query,
                'success': True,
                'metrics': enriched['metrics'],
                'documents': enriched['documents'],
                'lsi_phrases': lsi_phrases
            })
            
        except Exception as e:
            results.append({
                'record_id': record_id,
                'query': query,
                'success': False,
                'error': str(e)
            })
    
    return results


def get_all_queries_with_xml(limit: Optional[int] = None) -> list[tuple]:
    """–ü–æ–ª—É—á–∏—Ç—å –≤—Å–µ –∑–∞–ø—Ä–æ—Å—ã —Å XML –∏–∑ –ë–î"""
    db_path = Path("output/serp_data.db")
    
    if not db_path.exists():
        return []
    
    with sqlite3.connect(db_path) as conn:
        cursor = conn.cursor()
        
        if limit:
            cursor.execute("""
                SELECT id, query, lr, xml_response
                FROM serp_results
                WHERE xml_response IS NOT NULL AND xml_response != ''
                ORDER BY created_at DESC
                LIMIT ?
            """, (limit,))
        else:
            cursor.execute("""
                SELECT id, query, lr, xml_response
                FROM serp_results
                WHERE xml_response IS NOT NULL AND xml_response != ''
                ORDER BY created_at DESC
            """)
        return cursor.fetchall()


def chunk_list(lst: list, chunk_size: int):
    """–†–∞–∑–±–∏—Ç—å —Å–ø–∏—Å–æ–∫ –Ω–∞ —á–∞–Ω–∫–∏"""
    for i in range(0, len(lst), chunk_size):
        yield lst[i:i + chunk_size]


async def refill_database_fast(test_mode: bool = False, workers: int = None):
    """
    –ë—ã—Å—Ç—Ä–∞—è –ø–µ—Ä–µ–æ–±—Ä–∞–±–æ—Ç–∫–∞ —Å –ø–∞—Ä–∞–ª–ª–µ–ª—å–Ω–æ–π –æ–±—Ä–∞–±–æ—Ç–∫–æ–π
    
    Args:
        test_mode: –û–±—Ä–∞–±–æ—Ç–∞—Ç—å —Ç–æ–ª—å–∫–æ 100 –∑–∞–ø–∏—Å–µ–π
        workers: –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –ø—Ä–æ—Ü–µ—Å—Å–æ–≤ (–ø–æ —É–º–æ–ª—á–∞–Ω–∏—é = CPU cores)
    """
    
    print("=" * 80)
    print("–ë–´–°–¢–†–ê–Ø –ü–ï–†–ï–û–ë–†–ê–ë–û–¢–ö–ê –î–ê–ù–ù–´–• –í –ë–î (–ü–ê–†–ê–õ–õ–ï–õ–¨–ù–ê–Ø)")
    print("=" * 80)
    print()
    
    # –û–ø—Ä–µ–¥–µ–ª—è–µ–º –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –≤–æ—Ä–∫–µ—Ä–æ–≤
    if workers is None:
        workers = max(1, mp.cpu_count() - 1)  # –û—Å—Ç–∞–≤–ª—è–µ–º 1 —è–¥—Ä–æ —Å–≤–æ–±–æ–¥–Ω—ã–º
    
    print(f"üöÄ –ò—Å–ø–æ–ª—å–∑—É–µ–º {workers} –ø–∞—Ä–∞–ª–ª–µ–ª—å–Ω—ã—Ö –ø—Ä–æ—Ü–µ—Å—Å–æ–≤")
    print()
    
    # –ü–æ–ª—É—á–∞–µ–º –≤—Å–µ –∑–∞–ø—Ä–æ—Å—ã —Å XML –∏–∑ –ë–î
    limit = 100 if test_mode else None
    queries_with_xml = get_all_queries_with_xml(limit)
    
    if not queries_with_xml:
        print("‚ùå –í –ë–î –Ω–µ—Ç –∑–∞–ø–∏—Å–µ–π —Å XML –¥–ª—è –ø–µ—Ä–µ–æ–±—Ä–∞–±–æ—Ç–∫–∏")
        return
    
    print(f"‚úì –ù–∞–π–¥–µ–Ω–æ –∑–∞–ø–∏—Å–µ–π —Å XML: {len(queries_with_xml)}")
    print()
    
    # –†–∞–∑–±–∏–≤–∞–µ–º –Ω–∞ —á–∞–Ω–∫–∏ –¥–ª—è –ø–∞—Ä–∞–ª–ª–µ–ª—å–Ω–æ–π –æ–±—Ä–∞–±–æ—Ç–∫–∏
    chunk_size = 50  # –û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º –ø–æ 50 –∑–∞–ø–∏—Å–µ–π –≤ –∫–∞–∂–¥–æ–º –ø—Ä–æ—Ü–µ—Å—Å–µ
    chunks = list(chunk_list(queries_with_xml, chunk_size))
    
    print(f"üì¶ –†–∞–∑–±–∏—Ç–æ –Ω–∞ {len(chunks)} –ø–∞–∫–µ—Ç–æ–≤ –ø–æ {chunk_size} –∑–∞–ø–∏—Å–µ–π")
    print()
    
    # –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞
    stats = {
        'total': len(queries_with_xml),
        'processed': 0,
        'updated': 0,
        'errors': 0
    }
    
    print("üîÑ –ù–∞—á–∏–Ω–∞–µ–º –ø–∞—Ä–∞–ª–ª–µ–ª—å–Ω—É—é –æ–±—Ä–∞–±–æ—Ç–∫—É...")
    print()
    
    # –û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º –ø–∞–∫–µ—Ç—ã –ø–∞—Ä–∞–ª–ª–µ–ª—å–Ω–æ
    with ProcessPoolExecutor(max_workers=workers) as executor:
        # –ó–∞–ø—É—Å–∫–∞–µ–º –æ–±—Ä–∞–±–æ—Ç–∫—É –≤—Å–µ—Ö —á–∞–Ω–∫–æ–≤
        loop = asyncio.get_event_loop()
        
        for chunk_idx, chunk in enumerate(chunks):
            # –û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º —á–∞–Ω–∫ –≤ –æ—Ç–¥–µ–ª—å–Ω–æ–º –ø—Ä–æ—Ü–µ—Å—Å–µ
            future = loop.run_in_executor(executor, process_xml_chunk, chunk)
            processed_results = await future
            
            # –û–±–Ω–æ–≤–ª—è–µ–º –ë–î
            db_path = Path("output/serp_data.db")
            with sqlite3.connect(db_path) as conn:
                cursor = conn.cursor()
                
                for result in processed_results:
                    if not result['success']:
                        stats['errors'] += 1
                        print(f"   ‚ö†Ô∏è  –û—à–∏–±–∫–∞ '{result['query']}': {result.get('error', 'Unknown')}")
                        continue
                    
                    try:
                        record_id = result['record_id']
                        
                        # –£–¥–∞–ª—è–µ–º —Å—Ç–∞—Ä—ã–µ –¥–∞–Ω–Ω—ã–µ
                        cursor.execute("DELETE FROM serp_documents WHERE serp_result_id = ?", (record_id,))
                        cursor.execute("DELETE FROM serp_lsi_mapping WHERE serp_result_id = ?", (record_id,))
                        
                        # –û–±–Ω–æ–≤–ª—è–µ–º –º–µ—Ç—Ä–∏–∫–∏
                        cursor.execute("""
                            UPDATE serp_results
                            SET found_docs = ?,
                                main_pages_count = ?,
                                titles_with_keyword = ?,
                                commercial_domains = ?,
                                info_domains = ?,
                                yandex_ads = ?
                            WHERE id = ?
                        """, (
                            result['metrics'].get('found_docs', 0),
                            result['metrics'].get('main_pages_count', 0),
                            result['metrics'].get('titles_with_keyword', 0),
                            result['metrics'].get('commercial_domains', 0),
                            result['metrics'].get('info_domains', 0),
                            result['metrics'].get('yandex_ads', 0),
                            record_id
                        ))
                        
                        # Batch insert –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤
                        docs_data = [
                            (
                                record_id,
                                doc.get('position', 0),
                                doc.get('url', ''),
                                doc.get('domain', ''),
                                doc.get('title', ''),
                                doc.get('snippet', ''),
                                doc.get('passages', ''),
                                1 if doc.get('is_commercial', False) else 0
                            )
                            for doc in result['documents']
                        ]
                        
                        if docs_data:
                            cursor.executemany("""
                                INSERT INTO serp_documents 
                                (serp_result_id, position, url, domain, title, snippet, passages, is_commercial)
                                VALUES (?, ?, ?, ?, ?, ?, ?, ?)
                            """, docs_data)
                        
                        # Batch insert LSI —Ñ—Ä–∞–∑ (–ù–û–í–ê–Ø –ù–û–†–ú–ê–õ–ò–ó–û–í–ê–ù–ù–ê–Ø –°–•–ï–ú–ê)
                        for phrase_data in result['lsi_phrases']:
                            phrase_text = phrase_data.get('phrase', '')
                            frequency = phrase_data.get('frequency', 1)
                            source = phrase_data.get('source', 'unknown')
                            
                            # 1. –í—Å—Ç–∞–≤–ª—è–µ–º –∏–ª–∏ –ø–æ–ª—É—á–∞–µ–º phrase_id –∏–∑ unique_lsi_phrases
                            cursor.execute("""
                                INSERT OR IGNORE INTO unique_lsi_phrases (phrase, total_frequency)
                                VALUES (?, 0)
                            """, (phrase_text,))
                            
                            cursor.execute("""
                                SELECT id FROM unique_lsi_phrases WHERE phrase = ?
                            """, (phrase_text,))
                            
                            phrase_id = cursor.fetchone()[0]
                            
                            # 2. –û–±–Ω–æ–≤–ª—è–µ–º total_frequency
                            cursor.execute("""
                                UPDATE unique_lsi_phrases 
                                SET total_frequency = total_frequency + ?
                                WHERE id = ?
                            """, (frequency, phrase_id))
                            
                            # 3. –°–æ–∑–¥–∞–µ–º —Å–≤—è–∑—å –≤ serp_lsi_mapping
                            cursor.execute("""
                                INSERT OR REPLACE INTO serp_lsi_mapping (
                                    serp_result_id, phrase_id, frequency, source
                                ) VALUES (?, ?, ?, ?)
                            """, (record_id, phrase_id, frequency, source))
                        
                        stats['updated'] += 1
                        
                    except Exception as e:
                        print(f"   ‚ö†Ô∏è  –û—à–∏–±–∫–∞ –ë–î –¥–ª—è '{result['query']}': {e}")
                        stats['errors'] += 1
                
                # Commit –ø–æ—Å–ª–µ –∫–∞–∂–¥–æ–≥–æ —á–∞–Ω–∫–∞
                conn.commit()
                stats['processed'] += len(chunk)
            
            # –ü–æ–∫–∞–∑—ã–≤–∞–µ–º –ø—Ä–æ–≥—Ä–µ—Å—Å
            progress_pct = (stats['processed'] / stats['total']) * 100
            print(f"   –û–±—Ä–∞–±–æ—Ç–∞–Ω–æ: {stats['processed']}/{stats['total']} "
                  f"({progress_pct:.1f}%) | –û–±–Ω–æ–≤–ª–µ–Ω–æ: {stats['updated']} | –û—à–∏–±–æ–∫: {stats['errors']}")
    
    print()
    print("=" * 80)
    print("–ü–ï–†–ï–û–ë–†–ê–ë–û–¢–ö–ê –ó–ê–í–ï–†–®–ï–ù–ê")
    print("=" * 80)
    print()
    print(f"üìä –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞:")
    print(f"   –í—Å–µ–≥–æ –∑–∞–ø–∏—Å–µ–π: {stats['total']}")
    print(f"   –û–±—Ä–∞–±–æ—Ç–∞–Ω–æ —É—Å–ø–µ—à–Ω–æ: {stats['processed']}")
    print(f"   –û–±–Ω–æ–≤–ª–µ–Ω–æ –≤ –ë–î: {stats['updated']}")
    print(f"   –û—à–∏–±–æ–∫: {stats['errors']}")
    print()


if __name__ == '__main__':
    import sys
    
    # –ü—Ä–æ–≤–µ—Ä—è–µ–º –∞—Ä–≥—É–º–µ–Ω—Ç—ã
    test_mode = '--test' in sys.argv or '-t' in sys.argv
    
    # –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –≤–æ—Ä–∫–µ—Ä–æ–≤
    workers = None
    for arg in sys.argv:
        if arg.startswith('--workers='):
            workers = int(arg.split('=')[1])
    
    if test_mode:
        print("üß™ –¢–ï–°–¢–û–í–´–ô –†–ï–ñ–ò–ú: –±—É–¥–µ—Ç –æ–±—Ä–∞–±–æ—Ç–∞–Ω–æ —Ç–æ–ª—å–∫–æ 100 –∑–∞–ø–∏—Å–µ–π")
        print()
    
    asyncio.run(refill_database_fast(test_mode, workers))

