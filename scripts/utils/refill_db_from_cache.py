"""
–°–∫—Ä–∏–ø—Ç –¥–ª—è –¥–æ–∑–∞–ø–æ–ª–Ω–µ–Ω–∏—è –ë–î —Å –ø–µ—Ä–µ–æ–±—Ä–∞–±–æ—Ç–∫–æ–π XML
–ò—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è –∫–æ–≥–¥–∞ –æ–±–Ω–æ–≤–∏–ª—Å—è –∫–æ–¥ –æ–±—Ä–∞–±–æ—Ç–∫–∏ –∏ –Ω—É–∂–Ω–æ –æ–±–Ω–æ–≤–∏—Ç—å –¥–∞–Ω–Ω—ã–µ –≤ –ë–î
"""

import asyncio
import sqlite3
from pathlib import Path
from typing import Dict, Any, Optional

from seo_analyzer.core.serp_database import SERPDatabase
from seo_analyzer.core.serp_data_enricher import SERPDataEnricher
from seo_analyzer.core.lsi_extractor import LSIExtractor


def get_all_queries_with_xml(limit: Optional[int] = None) -> list[tuple]:
    """–ü–æ–ª—É—á–∏—Ç—å –≤—Å–µ –∑–∞–ø—Ä–æ—Å—ã —Å XML –∏–∑ –ë–î"""
    db_path = Path("output/serp_data.db")
    
    if not db_path.exists():
        return []
    
    with sqlite3.connect(db_path) as conn:
        cursor = conn.cursor()
        
        if limit:
            cursor.execute("""
                SELECT id, query, lr, xml_response
                FROM serp_results
                WHERE xml_response IS NOT NULL AND xml_response != ''
                ORDER BY created_at DESC
                LIMIT ?
            """, (limit,))
        else:
            cursor.execute("""
                SELECT id, query, lr, xml_response
                FROM serp_results
                WHERE xml_response IS NOT NULL AND xml_response != ''
                ORDER BY created_at DESC
            """)
        return cursor.fetchall()


def reprocess_xml_data(xml_response: str, query: str) -> Dict[str, Any]:
    """
    –ü–æ–≤—Ç–æ—Ä–Ω–æ –æ–±—Ä–∞–±–æ—Ç–∞—Ç—å XML —Å –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ–º –æ–±–Ω–æ–≤–ª–µ–Ω–Ω–æ–≥–æ –∫–æ–¥–∞
    
    Args:
        xml_response: –ò—Å—Ö–æ–¥–Ω—ã–π XML –æ—Ç xmlstock
        query: –ü–æ–∏—Å–∫–æ–≤—ã–π –∑–∞–ø—Ä–æ—Å
        
    Returns:
        Dict —Å –æ–±—Ä–∞–±–æ—Ç–∞–Ω–Ω—ã–º–∏ –¥–∞–Ω–Ω—ã–º–∏
    """
    enricher = SERPDataEnricher()
    lsi_extractor = LSIExtractor()
    
    # –û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º XML
    enriched = enricher.enrich_from_serp(xml_response, query)
    
    if enriched.get('error'):
        return None
    
    # –ò–∑–≤–ª–µ–∫–∞–µ–º LSI
    lsi_phrases = lsi_extractor.extract_from_serp_documents(
        enriched['documents'],
        query
    )
    
    return {
        'metrics': enriched['metrics'],
        'documents': enriched['documents'],
        'lsi_phrases': lsi_phrases
    }


async def refill_database(test_mode: bool = False):
    """–ü–µ—Ä–µ–æ–±—Ä–∞–±–æ—Ç–∞—Ç—å XML –∏–∑ –ë–î —Å –æ–±–Ω–æ–≤–ª–µ–Ω–Ω—ã–º –∫–æ–¥–æ–º"""
    
    print("=" * 80)
    print("–ü–ï–†–ï–û–ë–†–ê–ë–û–¢–ö–ê –î–ê–ù–ù–´–• –í –ë–î –° –û–ë–ù–û–í–õ–ï–ù–ù–´–ú –ö–û–î–û–ú")
    print("=" * 80)
    print()
    
    # –ü–æ–ª—É—á–∞–µ–º –≤—Å–µ –∑–∞–ø—Ä–æ—Å—ã —Å XML –∏–∑ –ë–î
    limit = 100 if test_mode else None
    queries_with_xml = get_all_queries_with_xml(limit)
    
    if not queries_with_xml:
        print("‚ùå –í –ë–î –Ω–µ—Ç –∑–∞–ø–∏—Å–µ–π —Å XML –¥–ª—è –ø–µ—Ä–µ–æ–±—Ä–∞–±–æ—Ç–∫–∏")
        return
    
    print(f"‚úì –ù–∞–π–¥–µ–Ω–æ –∑–∞–ø–∏—Å–µ–π —Å XML: {len(queries_with_xml)}")
    print()
    
    # –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä—É–µ–º –ë–î
    db = SERPDatabase()
    
    # –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞
    stats = {
        'total': len(queries_with_xml),
        'processed': 0,
        'updated': 0,
        'errors': 0
    }
    
    print("üîÑ –ù–∞—á–∏–Ω–∞–µ–º –ø–µ—Ä–µ–æ–±—Ä–∞–±–æ—Ç–∫—É...")
    print()
    
    # –û—Ç–∫—Ä—ã–≤–∞–µ–º –æ–¥–Ω–æ —Å–æ–µ–¥–∏–Ω–µ–Ω–∏–µ –¥–ª—è –≤—Å–µ—Ö –æ–ø–µ—Ä–∞—Ü–∏–π
    db_path = Path("output/serp_data.db")
    with sqlite3.connect(db_path) as conn:
        cursor = conn.cursor()
        
        for i, (record_id, query, lr, xml_response) in enumerate(queries_with_xml, 1):
            # –ü–æ–∫–∞–∑—ã–≤–∞–µ–º –ø—Ä–æ–≥—Ä–µ—Å—Å –∫–∞–∂–¥—ã–µ 100 –∑–∞–ø–∏—Å–µ–π
            if i % 100 == 0:
                print(f"   –û–±—Ä–∞–±–æ—Ç–∞–Ω–æ: {i}/{stats['total']} "
                      f"(–æ–±–Ω–æ–≤–ª–µ–Ω–æ: {stats['updated']}, –æ—à–∏–±–æ–∫: {stats['errors']})")
                # Commit –∫–∞–∂–¥—ã–µ 100 –∑–∞–ø–∏—Å–µ–π
                conn.commit()
            
            # –ü–µ—Ä–µ–æ–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º XML —Å –Ω–æ–≤—ã–º –∫–æ–¥–æ–º
            try:
                reprocessed = reprocess_xml_data(xml_response, query)
                
                if not reprocessed:
                    stats['errors'] += 1
                    print(f"   ‚ö†Ô∏è  –û—à–∏–±–∫–∞ –ø–µ—Ä–µ–æ–±—Ä–∞–±–æ—Ç–∫–∏ '{query}' - —Ä–µ–∑—É–ª—å—Ç–∞—Ç None")
                    continue
            except Exception as e:
                stats['errors'] += 1
                print(f"   ‚ö†Ô∏è  –ò—Å–∫–ª—é—á–µ–Ω–∏–µ –ø—Ä–∏ –ø–µ—Ä–µ–æ–±—Ä–∞–±–æ—Ç–∫–µ '{query}': {e}")
                continue
            
            # –û–±–Ω–æ–≤–ª—è–µ–º –∑–∞–ø–∏—Å—å –≤ –ë–î (—É–¥–∞–ª—è–µ–º —Å—Ç–∞—Ä—É—é –∏ —Å–æ–∑–¥–∞–µ–º –Ω–æ–≤—É—é)
            try:
                # –£–¥–∞–ª—è–µ–º —Å—Ç–∞—Ä—ã–µ –¥–æ–∫—É–º–µ–Ω—Ç—ã
                cursor.execute("DELETE FROM serp_documents WHERE serp_result_id = ?", (record_id,))
                
                # –£–¥–∞–ª—è–µ–º —Å—Ç–∞—Ä—ã–µ LSI —Ñ—Ä–∞–∑—ã
                cursor.execute("DELETE FROM lsi_phrases WHERE serp_result_id = ?", (record_id,))
                
                # –û–±–Ω–æ–≤–ª—è–µ–º –º–µ—Ç—Ä–∏–∫–∏
                cursor.execute("""
                    UPDATE serp_results
                    SET found_docs = ?,
                        main_pages_count = ?,
                        titles_with_keyword = ?,
                        commercial_domains = ?,
                        info_domains = ?,
                        yandex_ads = ?
                    WHERE id = ?
                """, (
                    reprocessed['metrics'].get('found_docs', 0),
                    reprocessed['metrics'].get('main_pages_count', 0),
                    reprocessed['metrics'].get('titles_with_keyword', 0),
                    reprocessed['metrics'].get('commercial_domains', 0),
                    reprocessed['metrics'].get('info_domains', 0),
                    reprocessed['metrics'].get('yandex_ads', 0),
                    record_id
                ))
                
                # –í—Å—Ç–∞–≤–ª—è–µ–º –Ω–æ–≤—ã–µ –¥–æ–∫—É–º–µ–Ω—Ç—ã
                for doc in reprocessed['documents']:
                    cursor.execute("""
                        INSERT INTO serp_documents 
                        (serp_result_id, position, url, domain, title, snippet, passages, is_commercial)
                        VALUES (?, ?, ?, ?, ?, ?, ?, ?)
                    """, (
                        record_id,
                        doc.get('position', 0),
                        doc.get('url', ''),
                        doc.get('domain', ''),
                        doc.get('title', ''),
                        doc.get('snippet', ''),
                        doc.get('passages', ''),
                        1 if doc.get('is_commercial', False) else 0
                    ))
                
                # –í—Å—Ç–∞–≤–ª—è–µ–º –Ω–æ–≤—ã–µ LSI —Ñ—Ä–∞–∑—ã
                for phrase in reprocessed['lsi_phrases']:
                    cursor.execute("""
                        INSERT INTO lsi_phrases (serp_result_id, phrase, frequency, source)
                        VALUES (?, ?, ?, ?)
                    """, (
                        record_id,
                        phrase.get('phrase', ''),
                        phrase.get('frequency', 0),
                        phrase.get('source', '')
                    ))
                
                stats['updated'] += 1
                stats['processed'] += 1
                
            except Exception as e:
                print(f"   ‚ö†Ô∏è  –û—à–∏–±–∫–∞ –æ–±–Ω–æ–≤–ª–µ–Ω–∏—è –ë–î –¥–ª—è '{query}': {e}")
                stats['errors'] += 1
        
        # –§–∏–Ω–∞–ª—å–Ω—ã–π commit
        conn.commit()
    
    print()
    print("=" * 80)
    print("–ü–ï–†–ï–û–ë–†–ê–ë–û–¢–ö–ê –ó–ê–í–ï–†–®–ï–ù–ê")
    print("=" * 80)
    print()
    print(f"üìä –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞:")
    print(f"   –í—Å–µ–≥–æ –∑–∞–ø–∏—Å–µ–π: {stats['total']}")
    print(f"   –û–±—Ä–∞–±–æ—Ç–∞–Ω–æ —É—Å–ø–µ—à–Ω–æ: {stats['processed']}")
    print(f"   –û–±–Ω–æ–≤–ª–µ–Ω–æ –≤ –ë–î: {stats['updated']}")
    print(f"   –û—à–∏–±–æ–∫: {stats['errors']}")
    print()
    
    # –ü–æ–∫–∞–∑—ã–≤–∞–µ–º —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É –ë–î
    db_stats = db.get_statistics()
    print(f"üíæ –ë–∞–∑–∞ –¥–∞–Ω–Ω—ã—Ö –ø–æ—Å–ª–µ –æ–±–Ω–æ–≤–ª–µ–Ω–∏—è:")
    print(f"   –í—Å–µ–≥–æ –∑–∞–ø—Ä–æ—Å–æ–≤: {db_stats.get('total_queries', 0)}")
    print(f"   –í—Å–µ–≥–æ –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤: {db_stats.get('total_documents', 0)}")
    print(f"   –†–∞–∑–º–µ—Ä –ë–î: {db_stats.get('db_size_mb', 0):.2f} MB")
    print()


if __name__ == '__main__':
    import sys
    
    # –ü—Ä–æ–≤–µ—Ä—è–µ–º –∞—Ä–≥—É–º–µ–Ω—Ç—ã –∫–æ–º–∞–Ω–¥–Ω–æ–π —Å—Ç—Ä–æ–∫–∏
    test_mode = '--test' in sys.argv or '-t' in sys.argv
    
    if test_mode:
        print("üß™ –¢–ï–°–¢–û–í–´–ô –†–ï–ñ–ò–ú: –±—É–¥–µ—Ç –æ–±—Ä–∞–±–æ—Ç–∞–Ω–æ —Ç–æ–ª—å–∫–æ 100 –∑–∞–ø–∏—Å–µ–π")
        print()
    
    asyncio.run(refill_database(test_mode))

