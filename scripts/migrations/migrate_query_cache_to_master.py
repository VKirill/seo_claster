"""
–ú–∏–≥—Ä–∞—Ü–∏—è –¥–∞–Ω–Ω—ã—Ö –∏–∑ query_cache.db –≤ master_queries.db

–ü–µ—Ä–µ–Ω–æ—Å–∏—Ç:
- normalized, lemmatized
- main_words, key_phrase
- ner_entities, ner_locations
- intent –¥–∞–Ω–Ω—ã–µ (–µ—Å–ª–∏ –µ—Å—Ç—å)

–ü–æ—Å–ª–µ –º–∏–≥—Ä–∞—Ü–∏–∏ query_cache.db —Å—Ç–∞–Ω–æ–≤–∏—Ç—Å—è –Ω–µ–æ–±—è–∑–∞—Ç–µ–ª—å–Ω–æ–π (legacy fallback).
"""

import sqlite3
import json
from pathlib import Path
from datetime import datetime


def migrate_query_cache_to_master():
    """
    –ú–∏–≥—Ä–∞—Ü–∏—è –≤—Å–µ—Ö –¥–∞–Ω–Ω—ã—Ö –∏–∑ query_cache –≤ Master DB
    """
    query_cache_path = Path("output/query_cache.db")
    master_db_path = Path("output/master_queries.db")
    
    if not query_cache_path.exists():
        print("‚ùå query_cache.db –Ω–µ –Ω–∞–π–¥–µ–Ω")
        return
    
    if not master_db_path.exists():
        print("‚ùå master_queries.db –Ω–µ –Ω–∞–π–¥–µ–Ω - —Å–æ–∑–¥–∞–π—Ç–µ –µ–≥–æ —Å–Ω–∞—á–∞–ª–∞")
        return
    
    print("=" * 80)
    print("–ú–ò–ì–†–ê–¶–ò–Ø: query_cache.db ‚Üí master_queries.db")
    print("=" * 80)
    print()
    
    # –ü–æ–¥–∫–ª—é—á–∞–µ–º—Å—è
    cache_conn = sqlite3.connect(query_cache_path)
    cache_conn.row_factory = sqlite3.Row
    master_conn = sqlite3.connect(master_db_path)
    
    try:
        # –ü–æ–ª—É—á–∞–µ–º —Å–ø–∏—Å–æ–∫ –≥—Ä—É–ø–ø –∏–∑ query_cache
        cache_cursor = cache_conn.cursor()
        cache_cursor.execute("SELECT DISTINCT group_name FROM cached_queries")
        groups = [row[0] for row in cache_cursor.fetchall()]
        
        print(f"üì¶ –ù–∞–π–¥–µ–Ω–æ –≥—Ä—É–ø–ø –≤ query_cache: {len(groups)}")
        print()
        
        total_migrated = 0
        total_updated = 0
        total_skipped = 0
        
        for group_name in groups:
            print(f"üîÑ –ì—Ä—É–ø–ø–∞: {group_name}")
            
            # –ü–æ–ª—É—á–∞–µ–º –≤—Å–µ –∑–∞–ø—Ä–æ—Å—ã –∏–∑ query_cache
            cache_cursor.execute("""
                SELECT 
                    keyword,
                    normalized,
                    lemmatized,
                    main_words,
                    key_phrase,
                    entities_json,
                    main_intent,
                    commercial_score,
                    informational_score,
                    navigational_score,
                    is_commercial,
                    is_wholesale,
                    is_urgent,
                    is_diy,
                    is_review,
                    is_brand_query,
                    has_geo,
                    geo_type,
                    geo_country,
                    geo_city
                FROM cached_queries
                WHERE group_name = ?
            """, (group_name,))
            
            cached_queries = cache_cursor.fetchall()
            print(f"   –ó–∞–ø—Ä–æ—Å–æ–≤ –≤ –∫—ç—à–µ: {len(cached_queries)}")
            
            master_cursor = master_conn.cursor()
            
            migrated = 0
            updated = 0
            skipped = 0
            
            for row in cached_queries:
                keyword = row['keyword']
                
                # –ü—Ä–æ–≤–µ—Ä—è–µ–º –µ—Å—Ç—å –ª–∏ —É–∂–µ –≤ Master DB
                master_cursor.execute("""
                    SELECT id, normalized, lemmatized, main_intent
                    FROM master_queries
                    WHERE group_name = ? AND keyword = ?
                """, (group_name, keyword))
                
                existing = master_cursor.fetchone()
                
                if existing:
                    # –ó–∞–ø—Ä–æ—Å —É–∂–µ –µ—Å—Ç—å - –ø—Ä–æ–≤–µ—Ä—è–µ–º –Ω—É–∂–Ω–æ –ª–∏ –æ–±–Ω–æ–≤–∏—Ç—å
                    existing_id = existing[0]
                    existing_normalized = existing[1]
                    existing_lemmatized = existing[2]
                    existing_intent = existing[3]
                    
                    # –û–±–Ω–æ–≤–ª—è–µ–º —Ç–æ–ª—å–∫–æ –µ—Å–ª–∏ –¥–∞–Ω–Ω—ã—Ö –Ω–µ—Ç
                    needs_update = False
                    
                    if not existing_normalized and row['normalized']:
                        needs_update = True
                    if not existing_lemmatized and row['lemmatized']:
                        needs_update = True
                    if not existing_intent and row['main_intent']:
                        needs_update = True
                    
                    if needs_update:
                        # –û–±–Ω–æ–≤–ª—è–µ–º
                        master_cursor.execute("""
                            UPDATE master_queries
                            SET
                                normalized = COALESCE(normalized, ?),
                                lemmatized = COALESCE(lemmatized, ?),
                                main_words = COALESCE(main_words, ?),
                                key_phrase = COALESCE(key_phrase, ?),
                                ner_entities = COALESCE(ner_entities, ?),
                                main_intent = COALESCE(main_intent, ?),
                                commercial_score = COALESCE(commercial_score, ?),
                                informational_score = COALESCE(informational_score, ?),
                                navigational_score = COALESCE(navigational_score, ?),
                                is_commercial = COALESCE(is_commercial, ?),
                                is_wholesale = COALESCE(is_wholesale, ?),
                                is_urgent = COALESCE(is_urgent, ?),
                                is_diy = COALESCE(is_diy, ?),
                                is_review = COALESCE(is_review, ?),
                                is_brand_query = COALESCE(is_brand_query, ?),
                                has_geo = COALESCE(has_geo, ?),
                                geo_type = COALESCE(geo_type, ?),
                                geo_country = COALESCE(geo_country, ?),
                                geo_city = COALESCE(geo_city, ?)
                            WHERE id = ?
                        """, (
                            row['normalized'],
                            row['lemmatized'],
                            row['main_words'],
                            row['key_phrase'],
                            row['entities_json'],
                            row['main_intent'],
                            row['commercial_score'],
                            row['informational_score'],
                            row['navigational_score'],
                            row['is_commercial'],
                            row['is_wholesale'],
                            row['is_urgent'],
                            row['is_diy'],
                            row['is_review'],
                            row['is_brand_query'],
                            row['has_geo'],
                            row['geo_type'],
                            row['geo_country'],
                            row['geo_city'],
                            existing_id
                        ))
                        updated += 1
                    else:
                        skipped += 1
                
                else:
                    # –ó–∞–ø—Ä–æ—Å–∞ –Ω–µ—Ç - –¥–æ–±–∞–≤–ª—è–µ–º
                    master_cursor.execute("""
                        INSERT INTO master_queries (
                            group_name, keyword,
                            normalized, lemmatized, main_words, key_phrase,
                            ner_entities,
                            main_intent, commercial_score, informational_score, navigational_score,
                            is_commercial, is_wholesale, is_urgent, is_diy, is_review, is_brand_query,
                            has_geo, geo_type, geo_country, geo_city
                        ) VALUES (?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?)
                    """, (
                        group_name, keyword,
                        row['normalized'],
                        row['lemmatized'],
                        row['main_words'],
                        row['key_phrase'],
                        row['entities_json'],
                        row['main_intent'],
                        row['commercial_score'],
                        row['informational_score'],
                        row['navigational_score'],
                        row['is_commercial'],
                        row['is_wholesale'],
                        row['is_urgent'],
                        row['is_diy'],
                        row['is_review'],
                        row['is_brand_query'],
                        row['has_geo'],
                        row['geo_type'],
                        row['geo_country'],
                        row['geo_city']
                    ))
                    migrated += 1
            
            master_conn.commit()
            
            print(f"   ‚úì –ú–∏–≥—Ä–∏—Ä–æ–≤–∞–Ω–æ: {migrated}")
            print(f"   ‚úì –û–±–Ω–æ–≤–ª–µ–Ω–æ: {updated}")
            print(f"   ‚ö†Ô∏è  –ü—Ä–æ–ø—É—â–µ–Ω–æ (—É–∂–µ –µ—Å—Ç—å): {skipped}")
            print()
            
            total_migrated += migrated
            total_updated += updated
            total_skipped += skipped
        
        print("=" * 80)
        print("–ò–¢–û–ì–û:")
        print(f"  –ì—Ä—É–ø–ø –æ–±—Ä–∞–±–æ—Ç–∞–Ω–æ: {len(groups)}")
        print(f"  –ó–∞–ø–∏—Å–µ–π –¥–æ–±–∞–≤–ª–µ–Ω–æ: {total_migrated}")
        print(f"  –ó–∞–ø–∏—Å–µ–π –æ–±–Ω–æ–≤–ª–µ–Ω–æ: {total_updated}")
        print(f"  –ó–∞–ø–∏—Å–µ–π –ø—Ä–æ–ø—É—â–µ–Ω–æ: {total_skipped}")
        print("=" * 80)
        print()
        
        if total_migrated > 0 or total_updated > 0:
            print("‚úÖ –ú–∏–≥—Ä–∞—Ü–∏—è –∑–∞–≤–µ—Ä—à–µ–Ω–∞ —É—Å–ø–µ—à–Ω–æ!")
            print()
            print("üìù –ß—Ç–æ –¥–∞–ª—å—à–µ:")
            print("   1. –ü—Ä–æ–≤–µ—Ä—å –¥–∞–Ω–Ω—ã–µ: python -c \"from seo_analyzer.core.cache.master_query_db import MasterQueryDatabase; db = MasterQueryDatabase(); print(db.get_all_statistics())\"")
            print("   2. query_cache.db —Ç–µ–ø–µ—Ä—å –Ω–µ–æ–±—è–∑–∞—Ç–µ–ª—å–Ω–∞ (legacy fallback)")
            print("   3. –ú–æ–∂–µ—à—å —É–¥–∞–ª–∏—Ç—å query_cache.db –µ—Å–ª–∏ —É–≤–µ—Ä–µ–Ω —á—Ç–æ –≤—Å—ë —Ä–∞–±–æ—Ç–∞–µ—Ç")
            print()
        else:
            print("‚ÑπÔ∏è  –ú–∏–≥—Ä–∞—Ü–∏—è –Ω–µ —Ç—Ä–µ–±—É–µ—Ç—Å—è - –≤—Å–µ –¥–∞–Ω–Ω—ã–µ —É–∂–µ –≤ Master DB")
    
    except Exception as e:
        print(f"‚ùå –û—à–∏–±–∫–∞ –º–∏–≥—Ä–∞—Ü–∏–∏: {e}")
        import traceback
        traceback.print_exc()
    
    finally:
        cache_conn.close()
        master_conn.close()


if __name__ == "__main__":
    migrate_query_cache_to_master()

