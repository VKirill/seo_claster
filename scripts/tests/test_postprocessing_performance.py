"""
–¢–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏ –æ–ø—Ç–∏–º–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω–æ–π –ø–æ—Å—Ç-–æ–±—Ä–∞–±–æ—Ç–∫–∏ –∫–ª–∞—Å—Ç–µ—Ä–æ–≤.

–°–æ–∑–¥–∞–µ—Ç —Å–∏–Ω—Ç–µ—Ç–∏—á–µ—Å–∫–∏–µ –¥–∞–Ω–Ω—ã–µ –∏ –∏–∑–º–µ—Ä—è–µ—Ç –≤—Ä–µ–º—è –≤—ã–ø–æ–ª–Ω–µ–Ω–∏—è.
"""

import time
import pandas as pd
import sys
from typing import Dict, List

# –û—á–∏—â–∞–µ–º –∫—ç—à –º–æ–¥—É–ª–µ–π –¥–ª—è –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è —Å–≤–µ–∂–µ–≥–æ –∫–æ–¥–∞
for module_name in list(sys.modules.keys()):
    if 'seo_analyzer.clustering' in module_name:
        del sys.modules[module_name]

from seo_analyzer.clustering.cluster_postprocessor import ClusterPostprocessor


def generate_test_data(num_queries: int = 1000, urls_per_query: int = 20) -> pd.DataFrame:
    """
    –ì–µ–Ω–µ—Ä–∏—Ä—É–µ—Ç —Ç–µ—Å—Ç–æ–≤—ã–µ –¥–∞–Ω–Ω—ã–µ –¥–ª—è –∫–ª–∞—Å—Ç–µ—Ä–∏–∑–∞—Ü–∏–∏.
    
    Args:
        num_queries: –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –∑–∞–ø—Ä–æ—Å–æ–≤
        urls_per_query: –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ URL –Ω–∞ –∑–∞–ø—Ä–æ—Å
    
    Returns:
        DataFrame —Å —Ç–µ—Å—Ç–æ–≤—ã–º–∏ –∑–∞–ø—Ä–æ—Å–∞–º–∏
    """
    print(f"üîß –ì–µ–Ω–µ—Ä–∞—Ü–∏—è —Ç–µ—Å—Ç–æ–≤—ã—Ö –¥–∞–Ω–Ω—ã—Ö: {num_queries} –∑–∞–ø—Ä–æ—Å–æ–≤...")
    
    data = []
    # –°–æ–∑–¥–∞–µ–º –ø—É–ª URL (–∏–º–∏—Ç–∏—Ä—É–µ–º —Ä–µ–∞–ª—å–Ω–æ–µ —Ä–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ)
    url_pool = [f"https://example{i}.com" for i in range(100)]
    
    import random
    random.seed(42)  # –§–∏–∫—Å–∏—Ä—É–µ–º seed –¥–ª—è –≤–æ—Å–ø—Ä–æ–∏–∑–≤–æ–¥–∏–º–æ—Å—Ç–∏
    
    for i in range(num_queries):
        # –ò–º–∏—Ç–∏—Ä—É–µ–º –∫–ª–∞—Å—Ç–µ—Ä—ã - –≥—Ä—É–ø–ø—ã –∑–∞–ø—Ä–æ—Å–æ–≤ —Å –ø–æ—Ö–æ–∂–∏–º–∏ URL
        cluster_id = i // 10  # –ü—Ä–∏–º–µ—Ä–Ω–æ 10 –∑–∞–ø—Ä–æ—Å–æ–≤ –Ω–∞ –∫–ª–∞—Å—Ç–µ—Ä
        
        # –ì–µ–Ω–µ—Ä–∏—Ä—É–µ–º URL –¥–ª—è –∑–∞–ø—Ä–æ—Å–∞ (—á–∞—Å—Ç—å –æ–±—â–∏—Ö, —á–∞—Å—Ç—å —É–Ω–∏–∫–∞–ª—å–Ω—ã—Ö)
        if cluster_id < len(url_pool):
            # –ë–µ—Ä–µ–º –±–∞–∑–æ–≤—ã–µ URL –∫–ª–∞—Å—Ç–µ—Ä–∞
            base_urls = url_pool[cluster_id:min(cluster_id + 10, len(url_pool))]
            # –î–æ–±–∞–≤–ª—è–µ–º –Ω–µ–º–Ω–æ–≥–æ —Å–ª—É—á–∞–π–Ω—ã—Ö URL
            random_urls = random.sample(url_pool, min(10, len(url_pool)))
            urls = base_urls + random_urls
        else:
            urls = random.sample(url_pool, min(urls_per_query, len(url_pool)))
        
        data.append({
            'keyword': f'–∑–∞–ø—Ä–æ—Å {i}',
            'semantic_cluster_id': cluster_id,
            'serp_urls': '|'.join(urls[:urls_per_query]),
            'frequency_world': 100 - i % 100,
        })
    
    df = pd.DataFrame(data)
    print(f"‚úÖ –°–æ–∑–¥–∞–Ω–æ {len(df)} –∑–∞–ø—Ä–æ—Å–æ–≤ –≤ {df['semantic_cluster_id'].nunique()} –∫–ª–∞—Å—Ç–µ—Ä–∞—Ö")
    return df


def test_performance(df: pd.DataFrame, skip_reattach: bool = False):
    """
    –¢–µ—Å—Ç–∏—Ä—É–µ—Ç –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç—å –ø–æ—Å—Ç-–æ–±—Ä–∞–±–æ—Ç–∫–∏.
    
    Args:
        df: DataFrame —Å –¥–∞–Ω–Ω—ã–º–∏
        skip_reattach: –ü—Ä–æ–ø—É—Å—Ç–∏—Ç—å –ø—Ä–∏–∫—Ä–µ–ø–ª–µ–Ω–∏–µ –æ–¥–∏–Ω–æ—á–µ–∫
    """
    mode = "–ë–ï–ó –ø—Ä–∏–∫—Ä–µ–ø–ª–µ–Ω–∏—è –æ–¥–∏–Ω–æ—á–µ–∫" if skip_reattach else "–° –ø—Ä–∏–∫—Ä–µ–ø–ª–µ–Ω–∏–µ–º –æ–¥–∏–Ω–æ—á–µ–∫"
    print(f"\n{'='*60}")
    print(f"‚ö° –¢–µ—Å—Ç –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏ ({mode})")
    print(f"{'='*60}")
    
    start_time = time.time()
    
    try:
        processor = ClusterPostprocessor(
            base_threshold=7,
            top_positions=30,
            max_cluster_size=12,
            threshold_step=1,
            skip_singleton_reattach=skip_reattach,
        )
        
        result_df = processor.process(df.copy())
        
        elapsed = time.time() - start_time
        
        stats = processor.get_stats()
        
        print(f"‚è±Ô∏è  –í—Ä–µ–º—è –≤—ã–ø–æ–ª–Ω–µ–Ω–∏—è: {elapsed:.2f} —Å–µ–∫—É–Ω–¥")
        print(f"üìä –†–µ–∑—É–ª—å—Ç–∞—Ç—ã:")
        print(f"   ‚Ä¢ –ö–ª–∞—Å—Ç–µ—Ä–æ–≤: {stats['total_clusters']}")
        print(f"   ‚Ä¢ –ú–∞–∫—Å–∏–º–∞–ª—å–Ω—ã–π —Ä–∞–∑–º–µ—Ä: {stats['max_cluster_size']}")
        print(f"   ‚Ä¢ –û–¥–∏–Ω–æ—á–Ω—ã—Ö –∫–ª–∞—Å—Ç–µ—Ä–æ–≤: {stats['singleton_clusters']}")
        print(f"   ‚Ä¢ –û–±—Ä–∞–±–æ—Ç–∞–Ω–æ –∑–∞–ø—Ä–æ—Å–æ–≤: {len(result_df)}")
        
        return elapsed, stats
        
    except Exception as e:
        print(f"‚ùå –û–®–ò–ë–ö–ê: {e}")
        import traceback
        traceback.print_exc()
        return None, None


def main():
    """–ó–∞–ø—É—Å–∫ —Ç–µ—Å—Ç–æ–≤ –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏."""
    print("üöÄ –¢–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ –æ–ø—Ç–∏–º–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω–æ–π –ø–æ—Å—Ç-–æ–±—Ä–∞–±–æ—Ç–∫–∏ –∫–ª–∞—Å—Ç–µ—Ä–æ–≤")
    print()
    
    # –¢–µ—Å—Ç 1: –ú–∞–ª–µ–Ω—å–∫–∏–π –Ω–∞–±–æ—Ä –¥–∞–Ω–Ω—ã—Ö
    print("="*60)
    print("üì¶ –¢–µ—Å—Ç 1: –ú–∞–ª–µ–Ω—å–∫–∏–π –Ω–∞–±–æ—Ä (500 –∑–∞–ø—Ä–æ—Å–æ–≤)")
    print("="*60)
    df_small = generate_test_data(num_queries=500)
    
    time_without, stats_without = test_performance(df_small.copy(), skip_reattach=True)
    time_with, stats_with = test_performance(df_small.copy(), skip_reattach=False)
    
    if time_with and time_without:
        speedup = time_with / time_without if time_without > 0 else 0
        print(f"\n‚ö° –ó–∞–º–µ–¥–ª–µ–Ω–∏–µ –ø—Ä–∏ –ø—Ä–∏–∫—Ä–µ–ø–ª–µ–Ω–∏–∏ –æ–¥–∏–Ω–æ—á–µ–∫: {speedup:.2f}x")
        print(f"   (–ø—Ä–∏–∫—Ä–µ–ø–ª–µ–Ω–∏–µ –æ–¥–∏–Ω–æ—á–µ–∫ –∑–∞–Ω–∏–º–∞–µ—Ç {time_with - time_without:.2f} —Å–µ–∫)")
    
    # –¢–µ—Å—Ç 2: –°—Ä–µ–¥–Ω–∏–π –Ω–∞–±–æ—Ä –¥–∞–Ω–Ω—ã—Ö
    print("\n" + "="*60)
    print("üì¶ –¢–µ—Å—Ç 2: –°—Ä–µ–¥–Ω–∏–π –Ω–∞–±–æ—Ä (2000 –∑–∞–ø—Ä–æ—Å–æ–≤)")
    print("="*60)
    df_medium = generate_test_data(num_queries=2000)
    
    time_without, stats_without = test_performance(df_medium.copy(), skip_reattach=True)
    time_with, stats_with = test_performance(df_medium.copy(), skip_reattach=False)
    
    if time_with and time_without:
        speedup = time_with / time_without if time_without > 0 else 0
        print(f"\n‚ö° –ó–∞–º–µ–¥–ª–µ–Ω–∏–µ –ø—Ä–∏ –ø—Ä–∏–∫—Ä–µ–ø–ª–µ–Ω–∏–∏ –æ–¥–∏–Ω–æ—á–µ–∫: {speedup:.2f}x")
        print(f"   (–ø—Ä–∏–∫—Ä–µ–ø–ª–µ–Ω–∏–µ –æ–¥–∏–Ω–æ—á–µ–∫ –∑–∞–Ω–∏–º–∞–µ—Ç {time_with - time_without:.2f} —Å–µ–∫)")
    
    # –¢–µ—Å—Ç 3: –ë–æ–ª—å—à–æ–π –Ω–∞–±–æ—Ä –¥–∞–Ω–Ω—ã—Ö
    print("\n" + "="*60)
    print("üì¶ –¢–µ—Å—Ç 3: –ë–æ–ª—å—à–æ–π –Ω–∞–±–æ—Ä (5000 –∑–∞–ø—Ä–æ—Å–æ–≤)")
    print("="*60)
    df_large = generate_test_data(num_queries=5000)
    
    time_without, stats_without = test_performance(df_large.copy(), skip_reattach=True)
    time_with, stats_with = test_performance(df_large.copy(), skip_reattach=False)
    
    if time_with and time_without:
        speedup = time_with / time_without if time_without > 0 else 0
        print(f"\n‚ö° –ó–∞–º–µ–¥–ª–µ–Ω–∏–µ –ø—Ä–∏ –ø—Ä–∏–∫—Ä–µ–ø–ª–µ–Ω–∏–∏ –æ–¥–∏–Ω–æ—á–µ–∫: {speedup:.2f}x")
        print(f"   (–ø—Ä–∏–∫—Ä–µ–ø–ª–µ–Ω–∏–µ –æ–¥–∏–Ω–æ—á–µ–∫ –∑–∞–Ω–∏–º–∞–µ—Ç {time_with - time_without:.2f} —Å–µ–∫)")
    
    print("\n" + "="*60)
    print("‚úÖ –í—Å–µ —Ç–µ—Å—Ç—ã –∑–∞–≤–µ—Ä—à–µ–Ω—ã!")
    print("="*60)
    print("\nüí° –†–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏—è:")
    print("   –ï—Å–ª–∏ –æ–¥–∏–Ω–æ—á–Ω—ã—Ö –∫–ª–∞—Å—Ç–µ—Ä–æ–≤ –º–Ω–æ–≥–æ (>500), –∏—Å–ø–æ–ª—å–∑—É–π—Ç–µ --skip-singleton-reattach")
    print("   –¥–ª—è —É—Å–∫–æ—Ä–µ–Ω–∏—è –ø–æ—Å—Ç-–æ–±—Ä–∞–±–æ—Ç–∫–∏ –≤ 2-5 —Ä–∞–∑!")


if __name__ == "__main__":
    main()

