"""
–¢–µ—Å—Ç–æ–≤—ã–π —Å–∫—Ä–∏–ø—Ç –¥–ª—è –ø—Ä–æ–≤–µ—Ä–∫–∏ –ø–µ—Ä–µ—Å–µ—á–µ–Ω–∏—è URL –º–µ–∂–¥—É –∑–∞–ø—Ä–æ—Å–∞–º–∏
–ü—Ä–æ–≤–µ—Ä—è–µ—Ç –ø–æ—á–µ–º—É "—Å–∫—É–¥ –æ–±–æ–∏" –ø–æ–ø–∞–ª –≤ –∫–ª–∞—Å—Ç–µ—Ä —Å –∑–∞–ø—Ä–æ—Å–∞–º–∏ –ø—Ä–æ –°–ö–£–î
"""

import json
import sqlite3
from pathlib import Path
from typing import List, Dict, Set, Tuple
from collections import defaultdict

# –°–ø–∏—Å–æ–∫ –∑–∞–ø—Ä–æ—Å–æ–≤ –∏–∑ –∫–ª–∞—Å—Ç–µ—Ä–∞
QUERIES = [
    "—Å–∏—Å—Ç–µ–º–∞ —Å–∫—É–¥",
    "–∫–æ–Ω—Ç—Ä–æ–ª—å –¥–æ—Å—Ç—É–ø–∞ —Å–∫—É–¥",
    "—Å–∫—É–¥ —Å–∏—Å—Ç–µ–º–∞ –∫–æ–Ω—Ç—Ä–æ–ª—è",
    "—Å–∏—Å—Ç–µ–º–∞ –∫–æ–Ω—Ç—Ä–æ–ª—è –¥–æ—Å—Ç—É–ø–∞ —Å–∫—É–¥",
    "—Å–∫—É–¥ —Å–∏—Å—Ç–µ–º–∞ –∫–æ–Ω—Ç—Ä–æ–ª—è –∏ —É–ø—Ä–∞–≤–ª–µ–Ω–∏—è –¥–æ—Å—Ç—É–ø–æ–º",
    "–æ–±–æ—Ä—É–¥–æ–≤–∞–Ω–∏–µ —Å–∫—É–¥",
    "—Å–∫—É–¥ –≤ –æ—Ñ–∏—Å",
    "—Å–∫—É–¥ –æ—Ö—Ä–∞–Ω–Ω–∞—è —Å–∏–≥–Ω–∞–ª–∏–∑–∞—Ü–∏—è",
    "—Å–∏—Å—Ç–µ–º—ã –±–µ–∑–æ–ø–∞—Å–Ω–æ—Å—Ç–∏ —Å–∫—É–¥",
    "—Å–∫—É–¥ –Ω–∞–∫–ª–∞–¥–Ω–æ–π",
    "—Å–æ–≤—Ä–µ–º–µ–Ω–Ω—ã–π —Å–∫—É–¥",
    "—Å–∏—Å—Ç–µ–º–∞ —Å–∫—É–¥ –¥–ª—è –¥–≤–µ—Ä–µ–π",
    "–∞–≤—Ç–æ–º–∞—Ç–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω–∞—è —Å–∫—É–¥",
    "–æ—Å–Ω–∞—â–µ–Ω–∏–µ —Å–∫—É–¥",
    "—Å–∏—Å—Ç–µ–º–∞ —Å–∫—É–¥ –≤ –æ—Ñ–∏—Å",
    "—Å–∫—É–¥ —Å–æ–≤–∞",
    "—Å—Ç–∞–Ω—Ü–∏—è —Å–∫—É–¥",
    "—Å–∏—Å—Ç–µ–º–∞ —É—á–µ—Ç–∞ –∫–æ–Ω—Ç—Ä–æ–ª—è —Å–∫—É–¥",
    "—Å–∏—Å—Ç–µ–º–∞ –∫–æ–Ω—Ç—Ä–æ–ª—è —É—á–µ—Ç–∞ –¥–æ—Å—Ç—É–ø–∞ —Å–∫—É–¥",
    "—Å–∏—Å—Ç–µ–º–∞ –∫–æ–Ω—Ç—Ä–æ–ª—è —É–¥–∞–ª–µ–Ω–Ω–æ–≥–æ –¥–æ—Å—Ç—É–ø–∞ —Å–∫—É–¥",
    "—Å–∏—Å—Ç–µ–º—ã —Å–∫—É–¥ –¥–ª—è –ø—Ä–µ–¥–ø—Ä–∏—è—Ç–∏–π",
    "—Ä–æ—Å—Ç–∞–± —Å–∫—É–¥",
    "—ç–ª–µ–∫—Ç—Ä–æ–Ω–∏–∫–∞ —Å–∫—É–¥",
    "—Ä–µ–¥ —Å–∫—É–¥",
    "—Å–∫—É–¥ –æ–±–æ–∏",  # –ü—Ä–æ–±–ª–µ–º–Ω—ã–π –∑–∞–ø—Ä–æ—Å
    "—Å–∫—É–¥ —Ä–∏–º",
]

# –ü—É—Ç—å –∫ –±–∞–∑–µ –¥–∞–Ω–Ω—ã—Ö
DB_PATH = Path("output/master_queries.db")
GROUP_NAME = "—Å–∫—É–¥"  # –ù–∞–∑–≤–∞–Ω–∏–µ –≥—Ä—É–ø–ø—ã (–±–µ–∑ –ø–æ–¥—á–µ—Ä–∫–∏–≤–∞–Ω–∏—è)


def normalize_url(url: str) -> str:
    """–ù–æ—Ä–º–∞–ª–∏–∑—É–µ—Ç URL –¥–ª—è —Å—Ä–∞–≤–Ω–µ–Ω–∏—è"""
    if not url:
        return ""
    # –£–±–∏—Ä–∞–µ–º –ø—Ä–æ—Ç–æ–∫–æ–ª
    url = url.replace("https://", "").replace("http://", "")
    url = url.replace("www.", "")
    # –£–±–∏—Ä–∞–µ–º –ø–∞—Ä–∞–º–µ—Ç—Ä—ã –∏ —è–∫–æ—Ä—è
    url = url.split("?")[0].split("#")[0]
    # –£–±–∏—Ä–∞–µ–º trailing slash
    url = url.rstrip("/")
    return url.lower()


def extract_urls_from_json(serp_top_urls_json: str) -> List[str]:
    """–ò–∑–≤–ª–µ–∫–∞–µ—Ç URL –∏–∑ JSON —Å—Ç—Ä–æ–∫–∏"""
    if not serp_top_urls_json:
        return []
    
    try:
        data = json.loads(serp_top_urls_json)
        if isinstance(data, list):
            urls = []
            for item in data:
                if isinstance(item, dict):
                    url = item.get('url', '')
                elif isinstance(item, str):
                    url = item
                else:
                    continue
                if url:
                    urls.append(normalize_url(url))
            return urls
        return []
    except (json.JSONDecodeError, TypeError):
        return []


def get_query_urls(db_path: Path, group_name: str, query: str) -> List[str]:
    """–ü–æ–ª—É—á–∞–µ—Ç URL –¥–ª—è –∑–∞–ø—Ä–æ—Å–∞ –∏–∑ –±–∞–∑—ã –¥–∞–Ω–Ω—ã—Ö"""
    conn = sqlite3.connect(db_path)
    cursor = conn.cursor()
    
    cursor.execute('''
        SELECT serp_top_urls
        FROM master_queries
        WHERE group_name = ? AND keyword = ?
    ''', (group_name, query))
    
    row = cursor.fetchone()
    conn.close()
    
    if row and row[0]:
        return extract_urls_from_json(row[0])
    return []


def calculate_url_overlap(urls1: List[str], urls2: List[str], top_n: int = 20) -> Tuple[int, Set[str]]:
    """–í—ã—á–∏—Å–ª—è–µ—Ç –ø–µ—Ä–µ—Å–µ—á–µ–Ω–∏–µ URL –º–µ–∂–¥—É –¥–≤—É–º—è –∑–∞–ø—Ä–æ—Å–∞–º–∏"""
    set1 = set(urls1[:top_n])
    set2 = set(urls2[:top_n])
    common = set1 & set2
    return len(common), common


def main():
    print("=" * 80)
    print("–ü–†–û–í–ï–†–ö–ê –ü–ï–†–ï–°–ï–ß–ï–ù–ò–Ø URL –ú–ï–ñ–î–£ –ó–ê–ü–†–û–°–ê–ú–ò")
    print("=" * 80)
    print(f"\n–ë–∞–∑–∞ –¥–∞–Ω–Ω—ã—Ö: {DB_PATH}")
    print(f"–ì—Ä—É–ø–ø–∞: {GROUP_NAME}")
    print(f"–í—Å–µ–≥–æ –∑–∞–ø—Ä–æ—Å–æ–≤ –¥–ª—è –ø—Ä–æ–≤–µ—Ä–∫–∏: {len(QUERIES)}")
    print()
    
    if not DB_PATH.exists():
        print(f"‚ùå –û—à–∏–±–∫–∞: –ë–∞–∑–∞ –¥–∞–Ω–Ω—ã—Ö –Ω–µ –Ω–∞–π–¥–µ–Ω–∞: {DB_PATH}")
        return
    
    # –ó–∞–≥—Ä—É–∂–∞–µ–º URL –¥–ª—è –≤—Å–µ—Ö –∑–∞–ø—Ä–æ—Å–æ–≤
    print("üì• –ó–∞–≥—Ä—É–∑–∫–∞ URL –∏–∑ –±–∞–∑—ã –¥–∞–Ω–Ω—ã—Ö...")
    query_urls_dict = {}
    queries_without_data = []
    
    for query in QUERIES:
        urls = get_query_urls(DB_PATH, GROUP_NAME, query)
        if urls:
            query_urls_dict[query] = urls
            print(f"  ‚úì {query}: {len(urls)} URL")
        else:
            queries_without_data.append(query)
            print(f"  ‚ö†Ô∏è  {query}: –Ω–µ—Ç –¥–∞–Ω–Ω—ã—Ö –≤ –ë–î")
    
    print(f"\n‚úì –ó–∞–≥—Ä—É–∂–µ–Ω–æ: {len(query_urls_dict)} –∑–∞–ø—Ä–æ—Å–æ–≤ —Å –¥–∞–Ω–Ω—ã–º–∏")
    if queries_without_data:
        print(f"‚ö†Ô∏è  –ë–µ–∑ –¥–∞–Ω–Ω—ã—Ö: {len(queries_without_data)} –∑–∞–ø—Ä–æ—Å–æ–≤")
        for q in queries_without_data:
            print(f"     - {q}")
    
    if "—Å–∫—É–¥ –æ–±–æ–∏" not in query_urls_dict:
        print("\n‚ùå –û—à–∏–±–∫–∞: –ó–∞–ø—Ä–æ—Å '—Å–∫—É–¥ –æ–±–æ–∏' –Ω–µ –Ω–∞–π–¥–µ–Ω –≤ –±–∞–∑–µ –¥–∞–Ω–Ω—ã—Ö!")
        return
    
    # –ü—Ä–æ–≤–µ—Ä—è–µ–º –ø–µ—Ä–µ—Å–µ—á–µ–Ω–∏–µ "—Å–∫—É–¥ –æ–±–æ–∏" —Å –æ—Å—Ç–∞–ª—å–Ω—ã–º–∏ –∑–∞–ø—Ä–æ—Å–∞–º–∏
    target_query = "—Å–∫—É–¥ –æ–±–æ–∏"
    target_urls = query_urls_dict[target_query]
    
    print("\n" + "=" * 80)
    print(f"–ê–ù–ê–õ–ò–ó –ü–ï–†–ï–°–ï–ß–ï–ù–ò–Ø: '{target_query}' —Å –æ—Å—Ç–∞–ª—å–Ω—ã–º–∏ –∑–∞–ø—Ä–æ—Å–∞–º–∏")
    print("=" * 80)
    print(f"\nURL –¥–ª—è '{target_query}': {len(target_urls)}")
    if target_urls:
        print("–ü–µ—Ä–≤—ã–µ 10 URL:")
        for i, url in enumerate(target_urls[:10], 1):
            print(f"  {i}. {url}")
    
    # –ü–æ—Ä–æ–≥ –¥–ª—è –∫–ª–∞—Å—Ç–µ—Ä–∏–∑–∞—Ü–∏–∏ (–∏–∑ –∫–æ–Ω—Ñ–∏–≥–∞)
    MIN_COMMON_URLS = 7  # –ò–∑–º–µ–Ω–µ–Ω–æ —Å 8 –Ω–∞ 7 –¥–ª—è —Ç–µ—Å—Ç–∞
    
    print(f"\n–ü–æ—Ä–æ–≥ –¥–ª—è –∫–ª–∞—Å—Ç–µ—Ä–∏–∑–∞—Ü–∏–∏: {MIN_COMMON_URLS} –æ–±—â–∏—Ö URL")
    print(f"\n{'–ó–∞–ø—Ä–æ—Å':<50} {'–û–±—â–∏—Ö URL':<12} {'–°—Ç–∞—Ç—É—Å':<15} {'–û–±—â–∏–µ URL'}")
    print("-" * 120)
    
    results = []
    for query in QUERIES:
        if query == target_query:
            continue
        
        if query not in query_urls_dict:
            print(f"{query:<50} {'N/A':<12} {'–ù–µ—Ç –¥–∞–Ω–Ω—ã—Ö':<15}")
            continue
        
        urls = query_urls_dict[query]
        common_count, common_urls = calculate_url_overlap(target_urls, urls, top_n=20)
        
        status = "‚úÖ –í –∫–ª–∞—Å—Ç–µ—Ä–µ" if common_count >= MIN_COMMON_URLS else "‚ùå –ù–µ –≤ –∫–ª–∞—Å—Ç–µ—Ä–µ"
        
        results.append({
            'query': query,
            'common_count': common_count,
            'common_urls': common_urls,
            'status': status
        })
        
        # –ü–æ–∫–∞–∑—ã–≤–∞–µ–º –ø–µ—Ä–≤—ã–µ 3 –æ–±—â–∏—Ö URL
        common_preview = ", ".join(list(common_urls)[:3]) if common_urls else "-"
        if len(common_urls) > 3:
            common_preview += f" ... (+{len(common_urls) - 3} –µ—â–µ)"
        
        print(f"{query:<50} {common_count:<12} {status:<15} {common_preview}")
    
    # –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞
    print("\n" + "=" * 80)
    print("–°–¢–ê–¢–ò–°–¢–ò–ö–ê")
    print("=" * 80)
    
    in_cluster = [r for r in results if r['common_count'] >= MIN_COMMON_URLS]
    not_in_cluster = [r for r in results if r['common_count'] < MIN_COMMON_URLS]
    
    print(f"\n‚úÖ –ó–∞–ø—Ä–æ—Å–æ–≤ —Å >= {MIN_COMMON_URLS} –æ–±—â–∏—Ö URL: {len(in_cluster)}")
    print(f"‚ùå –ó–∞–ø—Ä–æ—Å–æ–≤ —Å < {MIN_COMMON_URLS} –æ–±—â–∏—Ö URL: {len(not_in_cluster)}")
    
    if in_cluster:
        print(f"\nüìä –¢–æ–ø-5 –∑–∞–ø—Ä–æ—Å–æ–≤ —Å –Ω–∞–∏–±–æ–ª—å—à–∏–º –ø–µ—Ä–µ—Å–µ—á–µ–Ω–∏–µ–º:")
        sorted_results = sorted(results, key=lambda x: x['common_count'], reverse=True)
        for i, r in enumerate(sorted_results[:5], 1):
            print(f"  {i}. {r['query']}: {r['common_count']} –æ–±—â–∏—Ö URL")
            if r['common_urls']:
                print(f"     –ü—Ä–∏–º–µ—Ä—ã: {', '.join(list(r['common_urls'])[:3])}")
    
    # –î–µ—Ç–∞–ª—å–Ω—ã–π –∞–Ω–∞–ª–∏–∑ –¥–ª—è –∑–∞–ø—Ä–æ—Å–æ–≤ —Å –≤—ã—Å–æ–∫–∏–º –ø–µ—Ä–µ—Å–µ—á–µ–Ω–∏–µ–º
    print("\n" + "=" * 80)
    print("–î–ï–¢–ê–õ–¨–ù–´–ô –ê–ù–ê–õ–ò–ó: –û–±—â–∏–µ URL –º–µ–∂–¥—É '—Å–∫—É–¥ –æ–±–æ–∏' –∏ –∑–∞–ø—Ä–æ—Å–∞–º–∏ —Å –≤—ã—Å–æ–∫–∏–º –ø–µ—Ä–µ—Å–µ—á–µ–Ω–∏–µ–º")
    print("=" * 80)
    
    high_overlap = [r for r in results if r['common_count'] >= MIN_COMMON_URLS]
    if high_overlap:
        for r in sorted(high_overlap, key=lambda x: x['common_count'], reverse=True)[:5]:
            print(f"\nüìå {r['query']} ({r['common_count']} –æ–±—â–∏—Ö URL):")
            for url in list(r['common_urls'])[:10]:
                print(f"   ‚Ä¢ {url}")
    else:
        print("\n‚ö†Ô∏è  –ù–µ—Ç –∑–∞–ø—Ä–æ—Å–æ–≤ —Å –¥–æ—Å—Ç–∞—Ç–æ—á–Ω—ã–º –ø–µ—Ä–µ—Å–µ—á–µ–Ω–∏–µ–º –¥–ª—è –ø–æ–ø–∞–¥–∞–Ω–∏—è –≤ –∫–ª–∞—Å—Ç–µ—Ä")
        print("   –≠—Ç–æ –æ–∑–Ω–∞—á–∞–µ—Ç, —á—Ç–æ '—Å–∫—É–¥ –æ–±–æ–∏' –ù–ï –¥–æ–ª–∂–µ–Ω –±—ã–ª –ø–æ–ø–∞—Å—Ç—å –≤ —ç—Ç–æ—Ç –∫–ª–∞—Å—Ç–µ—Ä!")
        print("\n   –í–æ–∑–º–æ–∂–Ω—ã–µ –ø—Ä–∏—á–∏–Ω—ã:")
        print("   1. –î–∞–Ω–Ω—ã–µ –≤ –ë–î —É—Å—Ç–∞—Ä–µ–ª–∏")
        print("   2. –ò—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è –¥—Ä—É–≥–æ–π –∞–ª–≥–æ—Ä–∏—Ç–º –∫–ª–∞—Å—Ç–µ—Ä–∏–∑–∞—Ü–∏–∏")
        print("   3. –ü–∞—Ä–∞–º–µ—Ç—Ä—ã –∫–ª–∞—Å—Ç–µ—Ä–∏–∑–∞—Ü–∏–∏ –∏–∑–º–µ–Ω–∏–ª–∏—Å—å")


if __name__ == "__main__":
    main()

